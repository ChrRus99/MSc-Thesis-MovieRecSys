################################ <<<<<<<<<<<<<<<<<<<<<<<<<<---------------------------------------------- DA QUI <<<<<--------
# DA FARE ALLA FINE:

# TODO: riscrivi TUTTI i commenti e documentazione (guardando da codice originale), di OGNI singolo 
# file che sono tutti sbagliati!!!!!

# TODO: da rivedere bene problema sign_up chiamate 2 tools per capire perchè genera errore.
# vedi con notebook iniziando da versione originale e man mano modificando fino a ottenere versione attuale, 
# vedi a che punto delle modifiche genera errore.

# TODO: in greeting e in sign_in usare react_agent per fare le varie operazioni
# crea prompt per entrambi per eseguire più steps con stesso react_agent.
# per greeting dato che a un certo punto fa output strutturato meglio creare una chain 
# andando a estendere quella già esistente in modo da fare più passaggi con stesso model
# e di volta in volta passare output di uno stadio a stadio successivo.

# TODO: main_graph e rag_graph hanno dei file in comune che al momento sono duplicati
# e.g. parte di shared/config.py, state.py, debug_utils.py, graph.human_node, graph.take_handoff_tool, ecc.
# l'idea è di creare delle interfaccie, tipo per state, e spostare le parti identiche nel modulo 
# recsys/shared in modo da evitare di avere codice duplicato

# TODO: inoltre bisogna implementare shared/__init__.py in modo da evitare di dover usare 
#    import sys
#    sys.path.append("<path>")
# per usare file da un modulo all'altro.

# TODO: fai roadmap links langraph --> vedi tutti link nel codice, salvati su whts app, su chrome, cronologia ultime 2 settimane, ecc. 

# TODO: alla fine l'idea è di sostituire tutti i CSV con dei database SQL!



# DA FARE ORA:
# TODO: per i film visti dato che utente inserisce film con nomi vaghi, bisogna creare una funzione
# che faccia ricerca per similarità in movies_df e usare un llm per risolvere casi ambigui.
# es. utente dice che gli piace The Hobbit, ma ci sono 3 film su The Hobbit -> da risolvere (es. mettendo lo stesso rating a tutti e tre)
# oppure dice il "the first movie of The Hobbit" -> da associare a titolo e id corretto

# TODO: aggiungere l'età in sign_up per fare poi filtraggi su film vietati ai minori

# TODO: aggiungere anche il fatto che se user dice "mi piaciono film tipo Top Gun e Fast and Fourous"
# bisogna che il llm assegni a questi film uno score per salvare le preferenze
# (facendo una sorta di sentiment analysis)

# TODO: aggiungere anche la possibilità di chiedere preferences più generali
# es. Mi piacciono i film di azione e di fantascienza, non mi piacciono i film horror.
# queste preferenze vanno salvate e usate, tipo si può salvare come stringa e poi passare nel prompt al llm
# ---> salvale in un file csv chiamato user_preferences
# e.g., user_id: 2, prefs: "The user likes action movies; the user does not like thriller movies;
# the user has already seen all marvel movies up to 2024; ..." <--- these preferences are extracted and 
# collected by the llm through a tool save_user_preferences_tool
# these preferences must be used in prompting for recommendation

# TODO: dopo sistema tutta la parte rag e recommendation graph per usare i dati movie lens e per usare filtri che ho creato in CRM

# TODO tipi di raccomandazioni:
#   - suggeriscimi un buon film -> collaborative filter
#   - suggeriscimi un buon film recente / appena uscito al cinema -> hybrid_filtering + sentiment analysis
#   - suggeriscimi un buon film di azione -> hybrid filter: content_based + collaborative
#   - suggeriscimi uno dei migliori film di sempre -> top ranking 
#   - suggeriscimi un film storico -> filtering/content_based + top ranking
#   - ho visto questo film ma non ne ho capito il significato -> research, sentiment analysis on FAQ, and forums
#   - cosa ne pensano gli altri utenti di questo film -> sentiment analysis
#   - descrivimi questo film -> research
#   - dimmi qualche curiosità su questo film -> research
#   - quali sono le differenze tra questo film e il libro su cui è basato -> research, FAQ
#   - quali sono i migliori film di tom cruise -> filtering + sentiment analysis
# nota: research = corrective rag
# nota: dopo filtraggio ottengo un subset di film, su quei film devo fare prediction + sorting per 
# ottenere ranking, da ranking suggerisco top-k.
# esempio planning: suggeriscimi un buon film di azione recente --> piano:
#   - movies_df -> filtering -> action_movies_df
#   - action_movies_df -> hybrid_filtering (content_based + collaborative) -> top_K_suggestions
#   - top_K_suggestions -> corrective rag (research) + sentiment_analysis -> top_k_suggestions
# ---> qui usiamo sentiment_analysis per riordinare i top_K film suggeriti da CRM e per aggiungere
# la parte di explainability.

# TODO: aggiungere salvataggio conversazioni di ogni utente (e.g, in un database, o in formato pkl)
# in modo da riprendere conversazioni precedenti.
# vedi: https://langchain-ai.github.io/langgraph/how-tos/ 

# TODO: per la parte rag la rete va addestrata prima [offline] su 1000 e passa utenti che ho già nel dataframe "ratings", dopo
# prima di fare la raccommandazione all utente corrente prendo la decina di film che gli piacciono
# e riaddestro la rete preaddestrata [online], Dopodichè posso usare la rete per fare racommandation 
# (questo risolve cold-start problem) 
    
# TODO: crea rete separata per simulare il fatto che l'utente vede dei film e gli salva nel file CSV (simula un app)
    
# TODO: crea rete separata per fare l'addestramento offline e ottenere la rete preaddestrata da usare.
# ----> questo simula funzionamento data warehouse
# si potrebbe anche creare una funzione che runna su server (stile lambda in cloud) che a un ora fissa riaddestra la rete
# [offline] su tutti i dati raccolti durante la giornata. 

# TODO: si può anche salvare la rete addestrata online per ogni utente in un dataset (e.g., salvi reti in una directory e ti salvi
# il nome univoco della rete nel CSV user_register o in un altro CSV a parte)
# meglio in un CSV a parte e.g., user_id, online_model_id

# TODO: da fare la parte di corrective rag, in modo che la recensione del film sia anche basata su sentiment
# analysis su recensioni. 
# e.g., l'utente ha visto tutti i film Marvel finora, ma i film marvel usciti quest'anno hanno 
# recensioni molto negative, quindi il modello può suggerire il nuovo film, ma notificare l'utente che
# il nuovo film marvel è stato molto criticato (senza fare spoiler)

# il vantaggio del llm in recsys è di personalizzare ancora di più l'esperienza utente

# TODO: alla fine crea un agente che simuli l'utente per testare tutto il programma.

# TODO: nelle demo c'è un bug che è che a ogni iterazione deve stampare gli ultimi AI messages nella history
# ma solo del nodo corrente, non di tutti i nodi, altrimenti stampa messaggi duplicati avvolte.

# TODO:
# IDEA: per usare LLM + CRM insieme un idea è:
# - CRM filtra movies_df (es. utente vuole film di azione recenti (=ultimi 2 anni)), allora filtro i risultati con ratings utente da filtro collaborativo
# - LLM analizza i risultati (ottenuti da tool che usa CRM) e ritorna i 10 film con rating predetto più alto
# - poi magari utente dice "no stavo pensando a qualcosa con Nicholas Cage", allora LLM richiama tool e fa filtraggio questa volta
#   su dataframe filtrato prima, in modo da ridurre campo e ritorna di nuovo i nuovi 10 film con rating predetto più alto
# - e così via finchè utente non è soddisfatto
# (ovviamente ogni volta per i 10 film predetti ritorna explainability part per spiegare perchè ha suggerito quei film)
# TODO: aggiungere anche loop su rag_agent, in modo che se LLM suggerisce 10 film e utente ha domande generali su uno di questi
# poi l'agente possa usare il nodo corretto per rispondere. 


# TODO:
Idea per evitare di dover chiamare sys.path.append ogni volta in ogni notebook:
Crea file env contente tutti i percorsi da aggiungere al system path:
env
    paths = [....]

Crea uno script che per ogni percorso esegue comando sys.path.append 
(fai pip install di questo script in modo da renderlo eseguibile):
script.py -> codice .py
pip install script
esegui script env

Oppure un'idea migliore è fare direttamente un Docker

ALLA FINE: da creare un documento tecnico con tutta la descrizione di tutto quanto il programma nel 
dettaglio con codici demo e output.

################################ <<<<<<<<<<<<<<<<<<<<<<<<<<---------------------------------------------- DA QUI <<<<<--------


NOTA: 
Report da Gemini:
"""
The core issue is that your ask_user_for_more_info agent is attempting to both send a regular chat 
message and execute a tool call in the same turn. This is causing a conflict because the control 
flow logic expects either a message or a tool call, but not both simultaneously. The error 
"Command(graph='ask_user_for_more_info... goto='analyze_and_route_query')" arises because the tool 
execution creates a Command to transfer to the next agent, but the agent's main logic also tries to 
return a Command (implicitly, to go back to the human node), leading to the conflict.
"""
---> questo significa che l'errore dei 2 tool chiamati può essere dovuto a questo!


DONE:
# sistema problema due chiamate tools in sign_up

# gestire il fatto che utente non ha visto altri film, andando a chiedere film visti in recommendation node
# in questo modo risolviamo problema cold start problem prima di chiamare agent/grafo rag
# aggiungere human in the loop qui per prendere dati su film visti da utente.
