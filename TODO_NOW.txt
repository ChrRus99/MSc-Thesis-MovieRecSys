


------------------------------------------------------------------------------------------------
  DA QUI <<<<<<<<<<<<<<<<<<<<------------------------ !!!!!!!!!!!!!!!!!!!!
------------------------------------------------------------------------------------------------
TODO: ISTRUZIONI X QUANTO TORNO A FINE FEBBRAIO: <<<<<<<<<<------------- DA QUI
- bisogna sistemare problema prompting per integrazione tools retrieve_movies_info_tool e retrieve_cast_and_crew_info_tool
- bisogna creare i tool per create_recommendation_research_plan in tools.py (già creati in NOTEBOOK 6!!!!)
- bisogna integrare questi tools in create_recommendation_research_plan node in rag_agent.
- da decidere se usare planning in create_recommendation_research_plan node (secondo me si, vedi agentic rag), 
  ma all'inizio per semplicità fai solo nodo semplice, dopo integra sottografo researcer_graph per fare planning.
- bisogna unire i due programmi main_graph e rag_graph nel nodo recommendation di main_graph
- dopo fai tutta roba scritta in TODO_NOW (ossia qui sotto) e in TODO.
- prima però sisteama tutto codice parte langgraph rifacendo i nodi in modo più ordinato (vedi TODO) e sistemando e separando prompts
------------------------------------------------------------------------------------------------





###### DA QUI <<<<<<<<<<<<<<<<----------------------
DA FARE ORA:
- sistemare la cosa di aggiungere un nuovo utente ---> FATTO

- creare funzione per info da movies_df ---> FATTO
- creare il tool per info da movies_df ---> FATTO
- integrare il tool per info da movies_df <<<<<<----------------------- DA QUI TODO: NOTEBOOK 5 <<<<<<--------- TODO

- creare funzione per recommendation da movies_df ---> FATTO
- creare il tool per recommendation da movies_df ---> FATTO
- integrare il tool per recommendation da movies_df <<<<<<----------------------- DA QUI TODO: NOTEBOOK 6 <<<<<<--------- TODO

NOTA: creare un tool per recommendation per ogni tipo di filtro/raccomandazione (collaborative, top_ranking, hybrid, ecc.)

NOTA: attualmente ci sono 2 tools per answer_to_general_user_question: uno per estrarre info per film (da movies_df),
e uno per estrarre info da cast e crew (da credits_df) ma per query complesse non vanno bene (non sono sufficienti)
quindi bisogna sostituire questi tool con un tool che lavora su Knowledge Graph per estrarre dati strutturati più complessi

NOTA: attento che in CRM gli id degli utenti sono tutti int, mentre in langgraph gli id sono stringhe (perchè int non è serializzabile)! --> da sistemare sta cosa
###### DA QUI <<<<<<<<<<<<<<<<----------------------


NOTA: ci sono problemi con il prompting, nel senso che se fornisci esempi e query varia anche di pochissimo rispetto a 
esempi in prompt, non riesce a chiamare il tool correttamente.
Gestire tutte le domande possibili è infeasible, quindi bisogna vedere come fare.
Inoltre aggiungendo esempi disimpara gli esempi precedenti!
Un'idea ma molto OVERENGINEERING sarebbe creare una lista di conversazioni di esempio con tutti i casi possibili e poi si fa RAG
in modo da trovare esempio che si serve da passare nel prompt.
Vedere se questa cosa può dipendere o essere influenzata dal fatto che imposto la temperature del LLM a 0.

IMPORTANTE TODO:
gestire i dataset sta diventando complicato per il fatto che il processing deve essere fatto 1 sola volta
per tutto il programma, l'idea è di creare dei database SQL 1:1 per i file CSV in modo da tenere una versione
aggionata sempre runnante (come per knowledge graph per Neo4j).
Inoltre per fare le query bisogna creare una sorta di microservice che con chiamate API che ritorni le info estratte dai databases
in questo modo CRM diventa una libreria, la parte di gestione del tabular e graph datasets diventa un microservice
e la parte dei filtri diventano tool con chiamate a libreria.

Lo stesso discorso vale per il training offline e online, è troppo incasinato mantenere le cose mischiate
invece è meglio creare un microservice per gestire il training in maniera indipendente
e fare inference tramite chiamate API ritornando solo i risultati, in modo da mantenere tutto separato
ed avere:

databases & microservices:
- microservice + databases SQL per gestire datasets tabulari 
  ---> API calls in SQL per ottenere info sui film
- microservice + per gestire GNN graph dataset + training + inference (offline + online)
  ---> API calls per ottenere recommendation ({'user_id': user_id, 'query': filtering_query}) -> ottengo -> recommended movies (e.g., movieId's)
- microservice + Knowledge graph dataset (Neo4j+Cypher)
  ---> API calls in Cypher per ottenere info sui film (unione tools usati in answer_to_general_user_question) & per ottenere recommendation (vedi paper)
backend:
- app langgraph per gestire interazione con utente + orchestration agenti e tools ---> è una sorta di proxy
frontend (optional):
- chatbot interface (simile a Stregatto, ChatGPT, e altri vedi Whatsapp)
  ---> API calls request-response
---> questo permette di ridurre la dipendenza tra moduli (decoupling) e di creare un'interfaccia comune tra essi!
(per creare collegamento tra libreria CRM e microservice si possono creare delle classi adapter per mappare solo funzioni necessarie da usare in microservice usando CRM solo come una libreria)

nota: in realtà sarebbe meglio evitare di fare chiamate SQL e Cypher ai microservices, ma piuttosto fare chiamate normali request-response (magari con query)
in modo da ottenere direttamente come risultato dizionary di informazioni sui film o recommendations con top ranking 
questo per nascondere completametne la parte di database all'esterno. 
Ma questo è da decidere meglio, magari vedi come hanno definito le chiamate API per MovieLens, IMDB, ecc. e fai una cosa simile.

TODO LangGraph:
- rifare tutti nodi fatti bene separando prompt in prompt.py e creando delle catene langchain dove serve (tipo dove ci sono output strutturati)
per rendere più pulito e efficiente il codice


TODO CRM:
- si potrebbe anche creare valid_ratings usando ratings_df, QUELLO GRANDE + preprocessing + filtreing of all movies not in movies_df !!! In modo da avere più dati per il training
---> get_rated_movies_big

- creare tool per recommendation --> vedi graph_dataset_handler_in_test_phase.py

- IMPORTANTE: rivedi un pò le external features usate nel graph dataset che non mi sembrano molto sensate (e.g., "title")

- sistemare cosa che in TabularDatasetHandler bisogna mettere modo di modificare movies_df in modo da filtrarlo, questo serve soprattutto per HybridFilter, altrimenti ogni previsione ci vuole troppo tempo.


IMPORTANTE:
per la cosa di integrare credits (cast, crew, director, etc.) e keyworks vedi TabularDatasetHandler e ContentBasedFiltering
effettivamente per maneggiare tutta questa quantità di dati in maniera efficace conviene usare un knowledge graph 
in modo ma collezionare efficacemente dati per query complesse 
e.g., quale in quale genere di film ha recitato Tom Cruise negli ultimi 2 anni? <<<--- query molto complessa
in questo caso conviene passare direttamente structured data dal knowledge graph e il LLM tira fuori da solo la risposta
perchè usando filtering classico su tabular dataset è praticamente impossibile
---> i dati da prendere da movies_df, credits_df e keywords_df
---> questo è utile perchè se cambia la query cambia il tipo di filtraggio che dobbiamo fare, quindi è impossibile gestire qualsiasi tipo di filtraggio, metre con un LLM si usa un approccio tipo KG-RAG
---> chiedi bene a David che metrica vuole usare per misurare presetazioni di sto metodo


IMPORTANTE:
- siamo vicini a battere la surprise library con GraphSAGE_movie_suggestor
  ---> se riusciamo a sistemare meglio le external features possibmao batterlo!!! <<<---- IMPORTANTE
- vedi performance Surprise library: https://surpriselib.com/
- vedi banchmarks aggiornati per SOTA on MovieLens 100k: https://paperswithcode.com/sota/collaborative-filtering-on-movielens-100k?utm_source=chatgpt.com
- vedi paper recente su recommendation con Knowledge graph: https://arxiv.org/html/2405.08465v1


IDEA:
- non si capisce bene se la regressione su film non visti da nessun utente funzioni bene.
- per testare bene questa cosa:
  - crea funzione per prendere film non visti da nessun utente
  - crea un utente con film specifici (e.g., tutti film di azione con Tom Cruise)
  - usa la funzione prediction su nuovo utente per vedere se film suggeriti di azione e/o con Tom Cruise NON VISTI DA NESSUN UTENTE hanno un pred_rating alto !!!


TODO RAG AGENT: 
- in respond_to_general_movie_query node aggiungere tool per rispondere in base a 
  informazioni contenute in movies_df  ---> prima crea test sotto in questo file (già mezzo fatto)

- in create_recommendation_research_plan node adesso si può usare una rete GNN con filtri per fare
  recommendation ---> prima crea test sotto in questo file

- crea tool + gestione scenari per capire quale filtro usare in base a domanda utente in 
  create_recommendation_research_plan node

- aggiungere il fatto di salvare 


NOTA: osservando main_GNN_approaches mi viene in mente che si potrebbe arrotondare rating sia per
eccesso che per difetto (e.g., 0.8->1.0 e 2.1->2.0) tanto ratings sono numeri "tondi" (ossia, 
variano di 0.5), in questo modo probabilmente aumenta accuracy! 


TODO: dopo fai altri tool per altri filtri, e.g., toprank per prendere film più belli di tutti i tempi


TODO: gli indirizzi delle librerie vanno trasformati tutti in indirizzi assoluti:
da
from Src.scripts.data.tabular_dataset_handler import TabularDatasetHandler
a
from conventional_recommendation_models.movie_recommendation_system.Src.scripts.data.tabular_dataset_handler import TabularDatasetHandler
in modo da usare 
import os
import sys
sys.path.append('D:/Internship/recsys')
anzichè 
sys.path.append('D:/Internship/recsys/conventional_recommendation_models/movie_recommendation_system')
in questo modo possiamo usare tutte le classi nei moduli!

IMPORTANTE: vedi paper interessanti salvati su Whatsapp per roba in generale 
+ vedi agentic RAG, Chain of Toughts, Corrective RAG ecc. se si possono integrare, questo permetterebbe
di creare una connessione tra RAG e RecSys x tesi.
+ vedi https://arxiv.org/html/2405.08465v1 molto molto importante KG with RecSys
---> introduce surprise to any existing recsys in order to recoomend related items which probably has not beed rated yet.

vedi https://youtu.be/aQ4yQXeB1Ss?si=oIptL2nj_dPGU9XW molto molto importante su agentic rag!!!
questo è alla fine quello che facciamo in questo progetto, e può essere usato come argomento comune nella tesi
tra advanced rag e recsys!!!

TODO: nel validation node un'idea potrebbe essere quella di analizare le critiche e le risposte dell'utente per estrarre informazioni
riguardo le sue preferenze, in questo modo si mantiene in memoria un file .txt contente un report aggiornato riguardo i gusti dell'utente da usare
passandolo al LLM come prompt nella fase di recommendation per suggerire una risposta ancora più mirata.
(e.g., se utente menziona che non gli piacciono i film romantici o che gli piacciono i film di Tom Hanks queste informazioni possono essere 
usate in futuro per le prossime raccomandazioni, nella fase di filtraggio)

TODO OTTIMIZZAZIONE IMPORTANTE: per velocizzare la parte di recommendation, un'idea potrebbe essere quella di mantenere in memoria il pred_rating di ogni film nel movies_df
tipo una sorta di tabella pred_ratings_df dove le colonne sono movieId, userId, pred_rating, ground_truth_rating.
ogni volta che la rete dell'utente viene riaddestrata la colonna del pred_rating di quell'utente viene ricalcolata in maniera asincrona
---> questo permette di evitare che i rating debbano essere calcolati al volo ogni volta, rendendo l'applicazione molto molto più veloce.
---> in questo modo è possibile passare al modello attraverso il tool un numero di film molto più grande dopo la fase di filtraggio!!!
per esempio la rete online e la colonna dei pred_ratings potrebbero essere ricalcolate (SE NECESSARIO) alla fine di ogni conversazione con l'utente i-esimo.

TODO: ogni volta che inziamo la conversazione con un utente che è già registrato dobbiamo chiedergli se ha visto qualche film di recente e come lo valuterebbe,
oppure se ha visto qualche film tra quelli racommandati l'ultima volta, in modo da migliorare la racommandazione.