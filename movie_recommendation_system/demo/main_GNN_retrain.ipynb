{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the path to the root directory of the project to the system path\n",
    "ROOT_PATH = \"D:\\\\Internship\"\n",
    "sys.path.append(os.path.join(ROOT_PATH, \"recsys\\\\movie_recommendation_system\\\\src\"))\n",
    "\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# My scripts\n",
    "from movie_recommender.data.graph_dataset_handler import HeterogeneousGraphDatasetHandler\n",
    "from movie_recommender.data.expandable_graph_dataset_handler import ExpandableHeterogeneousGraphDatasetHandler\n",
    "from movie_recommender.models.gnn_retrain_strategies import GNNRetrainModelHandler\n",
    "from movie_recommender.recommenders.collaborative_filtering import CollaborativeFiltering\n",
    "\n",
    "# Remove warnings\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# Data and trained models paths\n",
    "data_path = os.path.join(ROOT_PATH, \"resources\", \"movielens\")\n",
    "processed_data_path = os.path.join(ROOT_PATH, \"resources\", \"movielens_processed\")\n",
    "trained_models_path = os.path.join(ROOT_PATH, \"trained_models\")\n",
    "updated_models_path = os.path.join(trained_models_path, \"updated_models\")\n",
    "\n",
    "gdh_filepath = os.path.join(processed_data_path, \"gdh_instance.pkl\")\n",
    "GraphSAGE_filepath = os.path.join(trained_models_path, \"GraphSAGE_based_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if CUDA is available:\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"CUDA is available.\")\n",
    "    \n",
    "#     # Get the number of available GPUs:\n",
    "#     num_gpus = torch.cuda.device_count()\n",
    "#     print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    \n",
    "#     # Get information about each GPU:\n",
    "#     for i in range(torch.cuda.device_count()):\n",
    "#         gpu = torch.cuda.get_device_properties(i)\n",
    "#         print(f\"GPU {i}: {gpu.name}, Compute Capability: {gpu.major}.{gpu.minor}\")\n",
    "    \n",
    "#     # Get the currently selected GPU:\n",
    "#     current_gpu = torch.cuda.current_device()\n",
    "#     print(f\"Currently selected GPU number: {current_gpu}\")\n",
    "# else:\n",
    "#     print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pre-built graph dataset instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a graph dataset handler\n",
    "gdh = HeterogeneousGraphDatasetHandler.load_class_instance(filepath=gdh_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    node_id=[672],\n",
       "    x=[672, 600],\n",
       "  },\n",
       "  movie={\n",
       "    node_id=[45433],\n",
       "    x=[45433, 405],\n",
       "  },\n",
       "  (user, rating, movie)={\n",
       "    edge_index=[2, 45004],\n",
       "    edge_label=[45004],\n",
       "    y=[45004],\n",
       "  },\n",
       "  (movie, rev_rating, user)={\n",
       "    edge_index=[2, 45004],\n",
       "    edge_label=[45004],\n",
       "    y=[45004],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = gdh.get_graph_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column information\n",
    "# def print_movie_details(row_number):\n",
    "#     if 0 <= row_number < len(gdh._movies_df):\n",
    "#         row = gdh._movies_df.iloc[row_number]\n",
    "#         for column, value in row.items():\n",
    "#             print(f\"{column}: {value}\")\n",
    "#     else:\n",
    "#         print(\"Invalid row number. Please provide a valid row index.\")\n",
    "\n",
    "# print(\"Column content\")\n",
    "# print_movie_details(0)\n",
    "# print(\"\\nColumns types\")\n",
    "# gdh._movies_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Spider-Verse Collection</td>\n",
       "      <td>100000000</td>\n",
       "      <td>[Animation, Action, Adventure, Science Fiction]</td>\n",
       "      <td>https://www.acrossthespiderverse.movie/</td>\n",
       "      <td>414906</td>\n",
       "      <td>en</td>\n",
       "      <td>Spider-Man: Across the Spider-Verse</td>\n",
       "      <td>Miles Morales catapults across the Multiverse,...</td>\n",
       "      <td>89.543</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>690000000.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>It's how you wear the mask that matters.</td>\n",
       "      <td>Spider-Man: Across the Spider-Verse</td>\n",
       "      <td>8.7</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Dune Collection</td>\n",
       "      <td>190000000</td>\n",
       "      <td>[Science Fiction, Adventure, Drama]</td>\n",
       "      <td>https://www.dunemovie.com/</td>\n",
       "      <td>693134</td>\n",
       "      <td>en</td>\n",
       "      <td>Dune: Part Two</td>\n",
       "      <td>Paul Atreides unites with Chani and the Fremen...</td>\n",
       "      <td>95.678</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>720000000.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Long live the fighters.</td>\n",
       "      <td>Dune: Part Two</td>\n",
       "      <td>8.9</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Toy Story Collection</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>nan</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult    belongs_to_collection     budget  \\\n",
       "0  False  Spider-Verse Collection  100000000   \n",
       "1  False          Dune Collection  190000000   \n",
       "2  False     Toy Story Collection   30000000   \n",
       "\n",
       "                                            genres  \\\n",
       "0  [Animation, Action, Adventure, Science Fiction]   \n",
       "1              [Science Fiction, Adventure, Drama]   \n",
       "2                      [Animation, Comedy, Family]   \n",
       "\n",
       "                                  homepage      id original_language  \\\n",
       "0  https://www.acrossthespiderverse.movie/  414906                en   \n",
       "1               https://www.dunemovie.com/  693134                en   \n",
       "2     http://toystory.disney.com/toy-story     862                en   \n",
       "\n",
       "                        original_title  \\\n",
       "0  Spider-Man: Across the Spider-Verse   \n",
       "1                       Dune: Part Two   \n",
       "2                            Toy Story   \n",
       "\n",
       "                                            overview popularity  ...  \\\n",
       "0  Miles Morales catapults across the Multiverse,...     89.543  ...   \n",
       "1  Paul Atreides unites with Chani and the Fremen...     95.678  ...   \n",
       "2  Led by Woody, Andy's toys live happily in his ...  21.946943  ...   \n",
       "\n",
       "  release_date      revenue runtime                          spoken_languages  \\\n",
       "0   2023-06-02  690000000.0   140.0  [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1   2024-03-01  720000000.0   166.0  [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "2   1995-10-30  373554033.0    81.0  [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                   tagline  \\\n",
       "0  Released  It's how you wear the mask that matters.   \n",
       "1  Released                   Long live the fighters.   \n",
       "2  Released                                       nan   \n",
       "\n",
       "                                 title vote_average vote_count  year  \n",
       "0  Spider-Man: Across the Spider-Verse          8.7    20000.0  2023  \n",
       "1                       Dune: Part Two          8.9    50000.0  2024  \n",
       "2                            Toy Story          7.7     5415.0  1995  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_movies_df = pd.DataFrame([\n",
    "    # New movie\n",
    "    {\n",
    "        \"adult\": False,\n",
    "        \"belongs_to_collection\": \"Spider-Verse Collection\",\n",
    "        \"budget\": \"100000000\",\n",
    "        \"genres\": [\"Animation\", \"Action\", \"Adventure\", \"Science Fiction\"],\n",
    "        \"homepage\": \"https://www.acrossthespiderverse.movie/\",\n",
    "        \"id\": 414906,\n",
    "        \"original_language\": \"en\",\n",
    "        \"original_title\": \"Spider-Man: Across the Spider-Verse\",\n",
    "        \"overview\": \"Miles Morales catapults across the Multiverse, where he encounters a team of Spider-People charged with protecting its very existence. When the heroes clash on how to handle a new threat, Miles must redefine what it means to be a hero.\",\n",
    "        \"popularity\": \"89.543\",\n",
    "        \"production_companies\": [\"Columbia Pictures\", \"Sony Pictures Animation\", \"Marvel Entertainment\"],\n",
    "        \"production_countries\": [\"United States of America\"],\n",
    "        \"release_date\": \"2023-06-02\",\n",
    "        \"revenue\": 690000000.0,\n",
    "        \"runtime\": 140.0,\n",
    "        \"spoken_languages\": [{\"iso_639_1\": \"en\", \"name\": \"English\"}],\n",
    "        \"status\": \"Released\",\n",
    "        \"tagline\": \"It's how you wear the mask that matters.\",\n",
    "        \"title\": \"Spider-Man: Across the Spider-Verse\",\n",
    "        \"vote_average\": 8.7,\n",
    "        \"vote_count\": 20000.0,\n",
    "        \"year\": \"2023\",\n",
    "    },\n",
    "    # New movie\n",
    "    {\n",
    "        \"adult\": False,\n",
    "        \"belongs_to_collection\": \"Dune Collection\",\n",
    "        \"budget\": \"190000000\",\n",
    "        \"genres\": [\"Science Fiction\", \"Adventure\", \"Drama\"],\n",
    "        \"homepage\": \"https://www.dunemovie.com/\",\n",
    "        \"id\": 693134,\n",
    "        \"original_language\": \"en\",\n",
    "        \"original_title\": \"Dune: Part Two\",\n",
    "        \"overview\": \"Paul Atreides unites with Chani and the Fremen while seeking revenge against those who destroyed his family, facing a choice between love and the fate of the universe.\",\n",
    "        \"popularity\": \"95.678\",\n",
    "        \"production_companies\": [\"Legendary Pictures\", \"Warner Bros. Pictures\"],\n",
    "        \"production_countries\": [\"United States of America\"],\n",
    "        \"release_date\": \"2024-03-01\",\n",
    "        \"revenue\": 720000000.0,\n",
    "        \"runtime\": 166.0,\n",
    "        \"spoken_languages\": [{\"iso_639_1\": \"en\", \"name\": \"English\"}],\n",
    "        \"status\": \"Released\",\n",
    "        \"tagline\": \"Long live the fighters.\",\n",
    "        \"title\": \"Dune: Part Two\",\n",
    "        \"vote_average\": 8.9,\n",
    "        \"vote_count\": 50000.0,\n",
    "        \"year\": \"2024\",\n",
    "    },\n",
    "    # Duplicate\n",
    "    {\n",
    "        \"adult\": False,\n",
    "        \"belongs_to_collection\": \"Toy Story Collection\",\n",
    "        \"budget\": \"30000000\",\n",
    "        \"genres\": [\"Animation\", \"Comedy\", \"Family\"],\n",
    "        \"homepage\": \"http://toystory.disney.com/toy-story\",\n",
    "        \"id\": 862,  # Same ID as original\n",
    "        \"original_language\": \"en\",\n",
    "        \"original_title\": \"Toy Story\",\n",
    "        \"overview\": \"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\",\n",
    "        \"popularity\": \"21.946943\",\n",
    "        \"production_companies\": [\"Pixar Animation Studios\"],\n",
    "        \"production_countries\": [\"United States of America\"],\n",
    "        \"release_date\": \"1995-10-30\",\n",
    "        \"revenue\": 373554033.0,\n",
    "        \"runtime\": 81.0,\n",
    "        \"spoken_languages\": [{\"iso_639_1\": \"en\", \"name\": \"English\"}],\n",
    "        \"status\": \"Released\",\n",
    "        \"tagline\": \"nan\",\n",
    "        \"title\": \"Toy Story\",\n",
    "        \"vote_average\": 7.7,\n",
    "        \"vote_count\": 5415.0,\n",
    "        \"year\": \"1995\",\n",
    "    }\n",
    "])\n",
    "new_movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adult                       bool\n",
       "belongs_to_collection     object\n",
       "budget                    object\n",
       "genres                    object\n",
       "homepage                  object\n",
       "id                         int64\n",
       "original_language         object\n",
       "original_title            object\n",
       "overview                  object\n",
       "popularity                object\n",
       "production_companies      object\n",
       "production_countries      object\n",
       "release_date              object\n",
       "revenue                  float64\n",
       "runtime                  float64\n",
       "spoken_languages          object\n",
       "status                    object\n",
       "tagline                   object\n",
       "title                     object\n",
       "vote_average             float64\n",
       "vote_count               float64\n",
       "year                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_movies_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new user-movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new user\n",
    "user_id = 1000 #gdh.users_ratings_df[\"userId\"].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 744, 5, 1743771267)\n",
      "(1000, 597, 4.5, 1743771267)\n",
      "(1000, 8844, 4.5, 1743771267)\n",
      "(1000, 862, 3.5, 1743771267)\n",
      "(1000, 680, 2, 1743771267)\n",
      "(1000, 22, 4, 1743771267)\n",
      "(1000, 671, 5, 1743771267)\n",
      "(1000, 672, 5, 1743771267)\n",
      "(1000, 673, 5, 1743771267)\n",
      "(1000, 674, 5, 1743771267)\n",
      "(1000, 120, 5, 1743771267)\n",
      "(1000, 121, 5, 1743771267)\n",
      "(1000, 49051, 5, 1743771267)\n",
      "(1000, 11036, 3.5, 1743771267)\n",
      "(1000, 10625, 3.5, 1743771267)\n",
      "(1000, 37799, 4.5, 1743771267)\n",
      "(1000, 621, 2, 1743771267)\n",
      "(1000, 1366, 3.5, 1743771267)\n",
      "(1000, 313369, 1.5, 1743771267)\n",
      "(1000, 88, 2.5, 1743771267)\n"
     ]
    }
   ],
   "source": [
    "# Create new user-movie ratings\n",
    "movies_list = [\n",
    "    {\"title\": \"Top Gun\", \"rating\": 5},\n",
    "    {\"title\": \"Titanic\", \"rating\": 4.5},\n",
    "    {\"title\": \"Jumanji\", \"rating\": 4.5},\n",
    "    {\"title\": \"Toy Story\", \"rating\": 3.5},\n",
    "    {\"title\": \"Pulp Fiction\", \"rating\": 2},\n",
    "    {\"title\": \"Pirates of the Caribbean: The Curse of the Black Pearl\", \"rating\": 4},\n",
    "    {\"title\": \"Harry Potter and the Philosopher's Stone\", \"rating\": 5},\n",
    "    {\"title\": \"Harry Potter and the Chamber of Secrets\", \"rating\": 5},\n",
    "    {\"title\": \"Harry Potter and the Prisoner of Azkaban\", \"rating\": 5},\n",
    "    {\"title\": \"Harry Potter and the Goblet of Fire\", \"rating\": 5},\n",
    "    {\"title\": \"The Lord of the Rings: The Fellowship of the Ring\", \"rating\": 5},\n",
    "    {\"title\": \"The Lord of the Rings: The Two Towers\", \"rating\": 5},\n",
    "    {\"title\": \"The Hobbit: An Unexpected Journey\", \"rating\": 5},\n",
    "    {\"title\": \"The Notebook\", \"rating\": 3.5},\n",
    "    {\"title\": \"Mean Girls\", \"rating\": 3.5},\n",
    "    {\"title\": \"The Social Network\", \"rating\": 4.5},\n",
    "    {\"title\": \"Grease\", \"rating\": 2},\n",
    "    {\"title\": \"Rocky\", \"rating\": 3.5},\n",
    "    {\"title\": \"La La Land\", \"rating\": 1.5},\n",
    "    {\"title\": \"Dirty Dancing\", \"rating\": 2.5},\n",
    "]\n",
    "\n",
    "# Convert the user-movie ratings to tuples\n",
    "timestamp_now = int(datetime.now().timestamp())\n",
    "\n",
    "movies_tuples = [\n",
    "    (\n",
    "        user_id,\n",
    "        gdh.movies_df[gdh.movies_df[\"title\"] == movie[\"title\"]][\"id\"].values[0],\n",
    "        movie[\"rating\"],\n",
    "        timestamp_now\n",
    "    ) for idx, movie in enumerate(movies_list)\n",
    "]\n",
    "\n",
    "# Output result\n",
    "for entry in movies_tuples:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>744</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1743771267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>597</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1743771267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>8844</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1743771267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>862</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1743771267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1743771267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0    1000      744     5.0  1743771267\n",
       "1    1000      597     4.5  1743771267\n",
       "2    1000     8844     4.5  1743771267\n",
       "3    1000      862     3.5  1743771267\n",
       "4    1000      680     2.0  1743771267"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of tuples to a DataFrame\n",
    "new_users_ratings_df = pd.DataFrame(movies_tuples, columns=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
    "new_users_ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expandable graph dataset handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the graph dataset handler with the expandable dataset handler\n",
    "egdh = ExpandableHeterogeneousGraphDatasetHandler(gdh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    node_id=[672],\n",
       "    x=[672, 600],\n",
       "  },\n",
       "  movie={\n",
       "    node_id=[45433],\n",
       "    x=[45433, 405],\n",
       "  },\n",
       "  (user, rating, movie)={\n",
       "    edge_index=[2, 45004],\n",
       "    edge_label=[45004],\n",
       "    y=[45004],\n",
       "  },\n",
       "  (movie, rev_rating, user)={\n",
       "    edge_index=[2, 45004],\n",
       "    edge_label=[45004],\n",
       "    y=[45004],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the graph dataset before adding new movies and ratings\n",
    "egdh.get_graph_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movie records before updating 45433\n",
      "Found 2 new movies to add to 'movies_df': Movies ids [414906, 693134]\n",
      "Number of movie records after updating 45435\n"
     ]
    }
   ],
   "source": [
    "# Test expandable graph dataset handler with new movies\n",
    "updated_movies_df = egdh.movies_df\n",
    "print(\"Number of movie records before updating\", len(egdh.movies_df))\n",
    "egdh.add_new_movies(new_movies_df)\n",
    "print(\"Number of movie records after updating\", len(egdh.movies_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    node_id=[672],\n",
       "    x=[672, 600],\n",
       "  },\n",
       "  movie={\n",
       "    node_id=[45435],\n",
       "    x=[45435, 405],\n",
       "  },\n",
       "  (user, rating, movie)={\n",
       "    edge_index=[2, 45004],\n",
       "    edge_label=[45004],\n",
       "    y=[45004],\n",
       "  },\n",
       "  (movie, rev_rating, user)={\n",
       "    edge_index=[2, 45004],\n",
       "    edge_label=[45004],\n",
       "    y=[45004],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the new movies were added to the graph dataset\n",
    "dataset = egdh.get_graph_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rating records before updating 45004\n",
      "Found 20 new ratings to add to 'users_ratings_df'\n",
      "Found 1 new users to add to 'users_ratings_df': Users ids [1000]\n",
      "Number of rating records after updating 45024\n"
     ]
    }
   ],
   "source": [
    "# Test expandable graph dataset handler with new ratings\n",
    "updated_users_ratings_df = egdh.users_ratings_df\n",
    "print(\"Number of rating records before updating\", len(egdh.users_ratings_df))\n",
    "egdh.add_new_user_movie_ratings(new_users_ratings_df)\n",
    "print(\"Number of rating records after updating\", len(egdh.users_ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    node_id=[673],\n",
       "    x=[673, 600],\n",
       "  },\n",
       "  movie={\n",
       "    node_id=[45435],\n",
       "    x=[45435, 405],\n",
       "  },\n",
       "  (user, rating, movie)={\n",
       "    edge_index=[2, 45024],\n",
       "    edge_label=[45024],\n",
       "    y=[45024],\n",
       "  },\n",
       "  (movie, rev_rating, user)={\n",
       "    edge_index=[2, 45024],\n",
       "    edge_label=[45024],\n",
       "    y=[45024],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the new ratings were added to the graph dataset\n",
    "dataset = egdh.get_graph_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  movie={\n",
       "    node_id=[45435],\n",
       "    x=[45435, 405],\n",
       "  },\n",
       "  user={\n",
       "    node_id=[673],\n",
       "    x=[673, 600],\n",
       "  },\n",
       "  (user, rating, movie)={\n",
       "    edge_index=[2, 20],\n",
       "    edge_label=[20],\n",
       "    y=[20],\n",
       "  },\n",
       "  (movie, rev_rating, user)={\n",
       "    edge_index=[2, 20],\n",
       "    edge_label=[20],\n",
       "    y=[20],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the subgraph dataset\n",
    "subgraph_dataset = egdh.get_subgraph_dataset()\n",
    "subgraph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  (46108, 46108)\n",
      "\n",
      "Dataset type:  <class 'torch_geometric.data.hetero_data.HeteroData'>\n",
      "\n",
      "Dataset metadata:  (['user', 'movie'], [('user', 'rating', 'movie'), ('movie', 'rev_rating', 'user')])\n",
      "\n",
      "Dataset to dict:  {'_global_store': {}, 'user': {'node_id': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "        504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
      "        518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n",
      "        532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "        546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n",
      "        560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n",
      "        574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n",
      "        588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
      "        602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,\n",
      "        616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,\n",
      "        630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n",
      "        644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
      "        658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671,\n",
      "        672]), 'x': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}, 'movie': {'node_id': tensor([    0,     1,     2,  ..., 45432, 45433, 45434]), 'x': tensor([[-0.0244,  0.0460,  0.0574,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0388,  0.1252, -0.0227,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0384,  0.0172, -0.0009,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0708,  0.0334, -0.0978,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0989, -0.0147, -0.0174,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0378,  0.0366,  0.0214,  ...,  0.0000,  0.0000,  0.0000]])}, ('user', 'rating', 'movie'): {'edge_index': tensor([[    0,     0,     0,  ...,   672,   672,   672],\n",
      "        [ 2296,  8309,  2590,  ...,  1844, 40852,  1056]]), 'edge_label': tensor([2.5000, 1.0000, 4.0000,  ..., 3.5000, 1.5000, 2.5000]), 'y': tensor([2.5000, 1.0000, 4.0000,  ..., 3.5000, 1.5000, 2.5000])}, ('movie', 'rev_rating', 'user'): {'edge_index': tensor([[ 2296,  8309,  2590,  ...,  1844, 40852,  1056],\n",
      "        [    0,     0,     0,  ...,   672,   672,   672]]), 'edge_label': tensor([2.5000, 1.0000, 4.0000,  ..., 3.5000, 1.5000, 2.5000]), 'y': tensor([2.5000, 1.0000, 4.0000,  ..., 3.5000, 1.5000, 2.5000])}}\n"
     ]
    }
   ],
   "source": [
    "# Print dataset information\n",
    "print(\"Dataset size: \", dataset.size())\n",
    "print(\"\\nDataset type: \", type(dataset))\n",
    "print(\"\\nDataset metadata: \", dataset.metadata())\n",
    "print(\"\\nDataset to dict: \", dataset.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data in pre-trained model training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "GraphSAGE_model = GNNRetrainModelHandler.load_pretrained_model(\n",
    "    pretrained_model_filepath=GraphSAGE_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    node_id=[672],\n",
       "    x=[672, 600],\n",
       "  },\n",
       "  movie={\n",
       "    node_id=[45433],\n",
       "    x=[45433, 405],\n",
       "  },\n",
       "  (user, rating, movie)={\n",
       "    edge_index=[2, 45004],\n",
       "    edge_label=[45004],\n",
       "    y=[45004],\n",
       "  },\n",
       "  (movie, rev_rating, user)={\n",
       "    edge_index=[2, 45004],\n",
       "    edge_label=[45004],\n",
       "    y=[45004],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraphSAGE_model._egdh.get_graph_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraphSAGE_model._egdh.get_subgraph_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 new movies to add to 'movies_df': Movies ids [414906, 693134]\n",
      "Found 20 new ratings to add to 'users_ratings_df'\n",
      "Found 1 new users to add to 'users_ratings_df': Users ids [1000]\n"
     ]
    }
   ],
   "source": [
    "# Set the new train set for the re-training of the model\n",
    "GraphSAGE_model.add_new_train_data(new_movies_df=new_movies_df, new_ratings_df=new_users_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={\n",
       "    node_id=[673],\n",
       "    x=[673, 600],\n",
       "  },\n",
       "  movie={\n",
       "    node_id=[45435],\n",
       "    x=[45435, 405],\n",
       "  },\n",
       "  (user, rating, movie)={\n",
       "    edge_index=[2, 45024],\n",
       "    edge_label=[45024],\n",
       "    y=[45024],\n",
       "  },\n",
       "  (movie, rev_rating, user)={\n",
       "    edge_index=[2, 45024],\n",
       "    edge_label=[45024],\n",
       "    y=[45024],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraphSAGE_model._egdh.get_graph_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  movie={\n",
       "    node_id=[45435],\n",
       "    x=[45435, 405],\n",
       "  },\n",
       "  user={\n",
       "    node_id=[673],\n",
       "    x=[673, 600],\n",
       "  },\n",
       "  (user, rating, movie)={\n",
       "    edge_index=[2, 20],\n",
       "    edge_label=[20],\n",
       "    y=[20],\n",
       "  },\n",
       "  (movie, rev_rating, user)={\n",
       "    edge_index=[2, 20],\n",
       "    edge_label=[20],\n",
       "    y=[20],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GraphSAGE_model._egdh.get_subgraph_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test new user-movie ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 122, 5, 1743771285)\n",
      "(1000, 57158, 5, 1743771285)\n",
      "(1000, 122917, 5, 1743771285)\n",
      "(1000, 675, 5, 1743771285)\n",
      "(1000, 767, 5, 1743771285)\n",
      "(1000, 12444, 5, 1743771285)\n",
      "(1000, 12445, 5, 1743771285)\n",
      "(1000, 19995, 3, 1743771285)\n",
      "(1000, 8358, 4, 1743771285)\n",
      "(1000, 314, 2, 1743771285)\n",
      "(1000, 1726, 5, 1743771285)\n",
      "(1000, 164251, 1, 1743771285)\n",
      "(1000, 11034, 2.5, 1743771285)\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "# Create new user-movie ratings\n",
    "test_movies_list = [\n",
    "    {\"title\": \"The Lord of the Rings: The Return of the King\", \"rating\": 5},\n",
    "    {\"title\": \"The Hobbit: The Desolation of Smaug\", \"rating\": 5},\n",
    "    {\"title\": \"The Hobbit: The Battle of the Five Armies\", \"rating\": 5},\n",
    "    {\"title\": \"Harry Potter and the Order of the Phoenix\", \"rating\": 5},\n",
    "    {\"title\": \"Harry Potter and the Half-Blood Prince\", \"rating\": 5},\n",
    "    {\"title\": \"Harry Potter and the Deathly Hallows: Part 1\", \"rating\": 5},\n",
    "    {\"title\": \"Harry Potter and the Deathly Hallows: Part 2\", \"rating\": 5},\n",
    "    {\"title\": \"Avatar\", \"rating\": 3},\n",
    "    {\"title\": \"Cast Away\", \"rating\": 4},\n",
    "    {\"title\": \"Catwoman\", \"rating\": 2},\n",
    "    {\"title\": \"Iron Man\", \"rating\": 5},\n",
    "    {\"title\": \"Serena\", \"rating\": 1},\n",
    "    {\"title\": \"The Great Gatsby\", \"rating\": 2.5},\n",
    "]\n",
    "\n",
    "# Convert the user-movie ratings to tuples\n",
    "timestamp_now = int(datetime.now().timestamp())\n",
    "\n",
    "test_movies_tuples = [\n",
    "    (\n",
    "        user_id,\n",
    "        gdh.movies_df[gdh.movies_df[\"title\"] == movie[\"title\"]][\"id\"].values[0],\n",
    "        movie[\"rating\"],\n",
    "        timestamp_now\n",
    "    ) for idx, movie in enumerate(test_movies_list)\n",
    "]\n",
    "\n",
    "# Output result\n",
    "for entry in test_movies_tuples:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1743771285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>57158</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1743771285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>122917</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1743771285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>675</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1743771285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>767</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1743771285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0    1000      122     5.0  1743771285\n",
       "1    1000    57158     5.0  1743771285\n",
       "2    1000   122917     5.0  1743771285\n",
       "3    1000      675     5.0  1743771285\n",
       "4    1000      767     5.0  1743771285"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list of tuples to a DataFrame\n",
    "test_new_users_ratings_df = pd.DataFrame(test_movies_tuples, columns=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
    "test_new_users_ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils for testing re-training performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Toy Story Collection</td>\n",
       "      <td>30000000</td>\n",
       "      <td>Animation|Comedy|Family</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>65000000</td>\n",
       "      <td>Adventure|Fantasy|Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>8000000</td>\n",
       "      <td>Thriller|Crime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>680</td>\n",
       "      <td>en</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>A burger-loving hit man, his philosophical par...</td>\n",
       "      <td>140.950236</td>\n",
       "      <td>...</td>\n",
       "      <td>1994-09-10</td>\n",
       "      <td>213928762.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just because you are a character doesn't mean ...</td>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8670.0</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>False</td>\n",
       "      <td>Dirty Dancing Collection</td>\n",
       "      <td>6000000</td>\n",
       "      <td>Drama|Music|Romance</td>\n",
       "      <td>http://lionsgateathome.com/dirty-dancing</td>\n",
       "      <td>88</td>\n",
       "      <td>en</td>\n",
       "      <td>Dirty Dancing</td>\n",
       "      <td>Expecting the usual tedium that accompanies a ...</td>\n",
       "      <td>14.044122</td>\n",
       "      <td>...</td>\n",
       "      <td>1987-08-21</td>\n",
       "      <td>213954274.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Have the time of your life.</td>\n",
       "      <td>Dirty Dancing</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>15000000</td>\n",
       "      <td>Action|Romance|War</td>\n",
       "      <td>NaN</td>\n",
       "      <td>744</td>\n",
       "      <td>en</td>\n",
       "      <td>Top Gun</td>\n",
       "      <td>For Lieutenant Pete 'Maverick' Mitchell and hi...</td>\n",
       "      <td>20.301019</td>\n",
       "      <td>...</td>\n",
       "      <td>1986-05-16</td>\n",
       "      <td>356830601.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Up there with the best of the best.</td>\n",
       "      <td>Top Gun</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adult     belongs_to_collection    budget                    genres  \\\n",
       "0     False      Toy Story Collection  30000000   Animation|Comedy|Family   \n",
       "1     False                      None  65000000  Adventure|Fantasy|Family   \n",
       "292   False                      None   8000000            Thriller|Crime   \n",
       "1056  False  Dirty Dancing Collection   6000000       Drama|Music|Romance   \n",
       "1069  False                      None  15000000        Action|Romance|War   \n",
       "\n",
       "                                      homepage    id original_language  \\\n",
       "0         http://toystory.disney.com/toy-story   862                en   \n",
       "1                                          NaN  8844                en   \n",
       "292                                        NaN   680                en   \n",
       "1056  http://lionsgateathome.com/dirty-dancing    88                en   \n",
       "1069                                       NaN   744                en   \n",
       "\n",
       "     original_title                                           overview  \\\n",
       "0         Toy Story  Led by Woody, Andy's toys live happily in his ...   \n",
       "1           Jumanji  When siblings Judy and Peter discover an encha...   \n",
       "292    Pulp Fiction  A burger-loving hit man, his philosophical par...   \n",
       "1056  Dirty Dancing  Expecting the usual tedium that accompanies a ...   \n",
       "1069        Top Gun  For Lieutenant Pete 'Maverick' Mitchell and hi...   \n",
       "\n",
       "      popularity  ... release_date      revenue runtime  \\\n",
       "0      21.946943  ...   1995-10-30  373554033.0    81.0   \n",
       "1      17.015539  ...   1995-12-15  262797249.0   104.0   \n",
       "292   140.950236  ...   1994-09-10  213928762.0   154.0   \n",
       "1056   14.044122  ...   1987-08-21  213954274.0   100.0   \n",
       "1069   20.301019  ...   1986-05-16  356830601.0   110.0   \n",
       "\n",
       "                                       spoken_languages    status  \\\n",
       "0              [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1     [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "292   [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "1056           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1069           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "                                                tagline          title  \\\n",
       "0                                                   NaN      Toy Story   \n",
       "1             Roll the dice and unleash the excitement!        Jumanji   \n",
       "292   Just because you are a character doesn't mean ...   Pulp Fiction   \n",
       "1056                        Have the time of your life.  Dirty Dancing   \n",
       "1069                Up there with the best of the best.        Top Gun   \n",
       "\n",
       "     vote_average vote_count  year  \n",
       "0             7.7     5415.0  1995  \n",
       "1             6.9     2413.0  1995  \n",
       "292           8.3     8670.0  1994  \n",
       "1056          7.1     1371.0  1987  \n",
       "1069          6.7     1736.0  1986  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the subset of movies that were rated by the new user\n",
    "movies_df = GraphSAGE_model._egdh._movies_df\n",
    "new_rated_movies_df = movies_df[movies_df[\"id\"].isin(new_users_ratings_df[\"movieId\"])]\n",
    "new_rated_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>90000000</td>\n",
       "      <td>Adventure|Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8358</td>\n",
       "      <td>en</td>\n",
       "      <td>Cast Away</td>\n",
       "      <td>Chuck, a top international manager for FedEx, ...</td>\n",
       "      <td>21.296343</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-12-22</td>\n",
       "      <td>4.296321e+08</td>\n",
       "      <td>143.0</td>\n",
       "      <td>[{'iso_639_1': 'ru', 'name': 'Pусский'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the edge of the world, his journey begins.</td>\n",
       "      <td>Cast Away</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3304.0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>False</td>\n",
       "      <td>The Lord of the Rings Collection</td>\n",
       "      <td>94000000</td>\n",
       "      <td>Adventure|Fantasy|Action</td>\n",
       "      <td>http://www.lordoftherings.net</td>\n",
       "      <td>122</td>\n",
       "      <td>en</td>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>Aragorn is revealed as the heir to the ancient...</td>\n",
       "      <td>29.324358</td>\n",
       "      <td>...</td>\n",
       "      <td>2003-12-01</td>\n",
       "      <td>1.118889e+09</td>\n",
       "      <td>201.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The eye of the enemy is moving.</td>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8226.0</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>6500000</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11034</td>\n",
       "      <td>en</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>Nick Carraway, a young Midwesterner now living...</td>\n",
       "      <td>5.702638</td>\n",
       "      <td>...</td>\n",
       "      <td>1974-03-27</td>\n",
       "      <td>2.653320e+07</td>\n",
       "      <td>144.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Gone is the romance that was so divine.</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>6.2</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7939</th>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>100000000</td>\n",
       "      <td>Action|Crime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314</td>\n",
       "      <td>en</td>\n",
       "      <td>Catwoman</td>\n",
       "      <td>Liquidated after discovering a corporate consp...</td>\n",
       "      <td>13.340272</td>\n",
       "      <td>...</td>\n",
       "      <td>2004-07-22</td>\n",
       "      <td>8.210238e+07</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'es', 'name': 'Español'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>CATch her in IMAX</td>\n",
       "      <td>Catwoman</td>\n",
       "      <td>4.2</td>\n",
       "      <td>833.0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11927</th>\n",
       "      <td>False</td>\n",
       "      <td>Harry Potter Collection</td>\n",
       "      <td>150000000</td>\n",
       "      <td>Adventure|Fantasy|Family|Mystery</td>\n",
       "      <td>http://www.harrypotterorderofthephoenix.com/</td>\n",
       "      <td>675</td>\n",
       "      <td>en</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Returning for his fifth year of study at Hogwa...</td>\n",
       "      <td>21.3643</td>\n",
       "      <td>...</td>\n",
       "      <td>2007-06-28</td>\n",
       "      <td>9.382127e+08</td>\n",
       "      <td>138.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Evil Must Be Confronted.</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5633.0</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adult             belongs_to_collection     budget  \\\n",
       "3897   False                              None   90000000   \n",
       "7000   False  The Lord of the Rings Collection   94000000   \n",
       "7025   False                              None    6500000   \n",
       "7939   False                              None  100000000   \n",
       "11927  False           Harry Potter Collection  150000000   \n",
       "\n",
       "                                 genres  \\\n",
       "3897                    Adventure|Drama   \n",
       "7000           Adventure|Fantasy|Action   \n",
       "7025                      Drama|Romance   \n",
       "7939                       Action|Crime   \n",
       "11927  Adventure|Fantasy|Family|Mystery   \n",
       "\n",
       "                                           homepage     id original_language  \\\n",
       "3897                                            NaN   8358                en   \n",
       "7000                  http://www.lordoftherings.net    122                en   \n",
       "7025                                            NaN  11034                en   \n",
       "7939                                            NaN    314                en   \n",
       "11927  http://www.harrypotterorderofthephoenix.com/    675                en   \n",
       "\n",
       "                                      original_title  \\\n",
       "3897                                       Cast Away   \n",
       "7000   The Lord of the Rings: The Return of the King   \n",
       "7025                                The Great Gatsby   \n",
       "7939                                        Catwoman   \n",
       "11927      Harry Potter and the Order of the Phoenix   \n",
       "\n",
       "                                                overview popularity  ...  \\\n",
       "3897   Chuck, a top international manager for FedEx, ...  21.296343  ...   \n",
       "7000   Aragorn is revealed as the heir to the ancient...  29.324358  ...   \n",
       "7025   Nick Carraway, a young Midwesterner now living...   5.702638  ...   \n",
       "7939   Liquidated after discovering a corporate consp...  13.340272  ...   \n",
       "11927  Returning for his fifth year of study at Hogwa...    21.3643  ...   \n",
       "\n",
       "      release_date       revenue runtime  \\\n",
       "3897    2000-12-22  4.296321e+08   143.0   \n",
       "7000    2003-12-01  1.118889e+09   201.0   \n",
       "7025    1974-03-27  2.653320e+07   144.0   \n",
       "7939    2004-07-22  8.210238e+07   104.0   \n",
       "11927   2007-06-28  9.382127e+08   138.0   \n",
       "\n",
       "                                        spoken_languages    status  \\\n",
       "3897   [{'iso_639_1': 'ru', 'name': 'Pусский'}, {'iso...  Released   \n",
       "7000            [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "7025            [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "7939   [{'iso_639_1': 'es', 'name': 'Español'}, {'iso...  Released   \n",
       "11927           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "                                             tagline  \\\n",
       "3897   At the edge of the world, his journey begins.   \n",
       "7000                 The eye of the enemy is moving.   \n",
       "7025         Gone is the romance that was so divine.   \n",
       "7939                               CATch her in IMAX   \n",
       "11927                       Evil Must Be Confronted.   \n",
       "\n",
       "                                               title vote_average vote_count  \\\n",
       "3897                                       Cast Away          7.5     3304.0   \n",
       "7000   The Lord of the Rings: The Return of the King          8.1     8226.0   \n",
       "7025                                The Great Gatsby          6.2      144.0   \n",
       "7939                                        Catwoman          4.2      833.0   \n",
       "11927      Harry Potter and the Order of the Phoenix          7.4     5633.0   \n",
       "\n",
       "       year  \n",
       "3897   2000  \n",
       "7000   2003  \n",
       "7025   1974  \n",
       "7939   2004  \n",
       "11927  2007  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the subset of test movies that were rated by the new user\n",
    "movies_df = GraphSAGE_model._egdh._movies_df\n",
    "test_new_rated_movies_df = movies_df[movies_df[\"id\"].isin(test_new_users_ratings_df[\"movieId\"])]\n",
    "test_new_rated_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(pred_ratings):\n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Error (RMSE) for predicted and ground truth ratings.\n",
    "\n",
    "    Parameters:\n",
    "        - pred_ratings (pd.DataFrame): A DataFrame containing 'predicted_rating' and \n",
    "            'ground_truth_rating' columns.\n",
    "\n",
    "    Returns:\n",
    "        float: The computed RMSE value.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(\n",
    "        pred_ratings[\"ground_truth_rating\"], \n",
    "        pred_ratings[\"predicted_rating\"]\n",
    "    ))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(GraphSAGE_model):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the GraphSAGE model on both training and test data.\n",
    "\n",
    "    Parameters:\n",
    "        - GraphSAGE_model: The pre-trained or retrained GraphSAGE model to evaluate.\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "\n",
    "    # Initialize the recommender\n",
    "    GraphSAGE_recommender = CollaborativeFiltering(model_handler=GraphSAGE_model)\n",
    "\n",
    "    # Evaluate performance specifically over the new user training data\n",
    "    pred_ratings_train = GraphSAGE_recommender.predict_ratings(user_id, new_rated_movies_df)\n",
    "    rmse_train = compute_rmse(pred_ratings_train)\n",
    "\n",
    "    # Evaluate performance specifically over the new user test data\n",
    "    pred_ratings_test = GraphSAGE_recommender.predict_ratings(user_id, test_new_rated_movies_df)\n",
    "    if \"ground_truth_rating\" in pred_ratings_test.columns:\n",
    "        pred_ratings_test.drop(columns=[\"ground_truth_rating\"], inplace=True)\n",
    "    pred_ratings_test = pred_ratings_test.merge(\n",
    "        test_new_users_ratings_df.rename(columns={\"rating\": \"ground_truth_rating\"})[[\"movieId\", \"ground_truth_rating\"]],\n",
    "        on=\"movieId\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    rmse_test = compute_rmse(pred_ratings_test)\n",
    "\n",
    "    # Display results side by side\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"display: flex; justify-content: space-around;\">\n",
    "        <div>\n",
    "            <h4>Training Data</h4>\n",
    "            <p>RMSE: {rmse_train:.4f}</p>\n",
    "            {pred_ratings_train.to_html(index=False)}\n",
    "        </div>\n",
    "        <div>\n",
    "            <h4>Test Data</h4>\n",
    "            <p>RMSE: {rmse_test:.4f}</p>\n",
    "            {pred_ratings_test.to_html(index=False)}\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "GraphSAGE_model = GNNRetrainModelHandler.load_pretrained_model(\n",
    "    pretrained_model_filepath=GraphSAGE_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 new movies to add to 'movies_df': Movies ids [414906, 693134]\n",
      "Found 20 new ratings to add to 'users_ratings_df'\n",
      "Found 1 new users to add to 'users_ratings_df': Users ids [1000]\n"
     ]
    }
   ],
   "source": [
    "# Set the new train set for the re-training of the model\n",
    "GraphSAGE_model.add_new_train_data(new_movies_df=new_movies_df, new_ratings_df=new_users_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda\n",
      "'\n",
      "Test RMSE: 0.9055, Test MAE: 0.6928\n",
      "\n",
      "      userId  movieId  pred_rating  gt_rating\n",
      "0        514     9645     3.909420        2.5\n",
      "1         26      286     4.455622        5.0\n",
      "2        599    44114     3.718285        5.0\n",
      "3        101     7008     4.035489        4.0\n",
      "4        101    11443     4.162599        3.0\n",
      "...      ...      ...          ...        ...\n",
      "4495     246     2244     3.258173        2.0\n",
      "4496     104    10299     3.125103        3.0\n",
      "4497     469     5044     3.438445        3.0\n",
      "4498     129    36979     3.477707        4.0\n",
      "4499     563    10009     2.232373        1.0\n",
      "\n",
      "[4500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate general performance pre-trained model\n",
    "GraphSAGE_model.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"display: flex; justify-content: space-around;\">\n",
       "        <div>\n",
       "            <h4>Training Data</h4>\n",
       "            <p>RMSE: 1.4190</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>3.370536</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8844</td>\n",
       "      <td>1.124036</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.661665</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>4.229530</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>4.997815</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>4.363821</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>4.681252</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1366</td>\n",
       "      <td>4.714817</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>4.916984</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.346409</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>4.672766</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>4.117024</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>4.580343</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10625</td>\n",
       "      <td>3.541134</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>673</td>\n",
       "      <td>4.279641</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11036</td>\n",
       "      <td>2.591956</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>4.550504</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37799</td>\n",
       "      <td>2.824427</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49051</td>\n",
       "      <td>4.248689</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313369</td>\n",
       "      <td>3.759644</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div>\n",
       "            <h4>Test Data</h4>\n",
       "            <p>RMSE: 1.4272</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8358</td>\n",
       "      <td>4.165007</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>4.423152</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11034</td>\n",
       "      <td>3.915348</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>4.699201</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>3.950711</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1726</td>\n",
       "      <td>3.454071</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>4.676386</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19995</td>\n",
       "      <td>3.805110</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12444</td>\n",
       "      <td>3.999969</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12445</td>\n",
       "      <td>3.963425</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57158</td>\n",
       "      <td>3.849480</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164251</td>\n",
       "      <td>3.798029</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122917</td>\n",
       "      <td>3.834270</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate performance specifically over the new training data\n",
    "evaluate_model_performance(GraphSAGE_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No movie added: Movies ids [414906, 693134, 862] are all already present in 'movies_df'.\n",
      "Found 13 new ratings to add to 'users_ratings_df'\n",
      "No new users to add. Users [1000] are already present in 'users_ratings_df'.\n"
     ]
    }
   ],
   "source": [
    "# Test addition new ratings for already existing user\n",
    "GraphSAGE_model.add_new_train_data(new_movies_df=new_movies_df, new_ratings_df=test_new_users_ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "GraphSAGE_model = GNNRetrainModelHandler.load_pretrained_model(\n",
    "    pretrained_model_filepath=GraphSAGE_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 new movies to add to 'movies_df': Movies ids [414906, 693134]\n",
      "Found 20 new ratings to add to 'users_ratings_df'\n",
      "Found 1 new users to add to 'users_ratings_df': Users ids [1000]\n"
     ]
    }
   ],
   "source": [
    "# Set the new train set for the re-training of the model\n",
    "GraphSAGE_model.add_new_train_data(new_movies_df=new_movies_df, new_ratings_df=new_users_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n",
      "Adaptive patience set to 32 epochs based on num_epochs=350.\n",
      "Epoch: 001, Train loss: 13.0628, Train RMSE: 3.2571, Train MAE: 3.0822, Val RMSE: 3.2751, Val MAE: 3.1021\n",
      "Epoch: 002, Train loss: 10.6090, Train RMSE: 2.2620, Train MAE: 2.0575, Val RMSE: 2.2830, Val MAE: 2.0815\n",
      "Epoch: 003, Train loss: 5.1166, Train RMSE: 1.3227, Train MAE: 1.0207, Val RMSE: 1.2968, Val MAE: 0.9975\n",
      "Epoch: 004, Train loss: 1.7555, Train RMSE: 1.7438, Train MAE: 1.4041, Val RMSE: 1.7169, Val MAE: 1.3734\n",
      "Epoch: 005, Train loss: 3.7963, Train RMSE: 1.0604, Train MAE: 0.8576, Val RMSE: 1.0601, Val MAE: 0.8587\n",
      "Epoch: 006, Train loss: 1.1244, Train RMSE: 1.5085, Train MAE: 1.3140, Val RMSE: 1.5291, Val MAE: 1.3394\n",
      "Epoch: 007, Train loss: 2.2756, Train RMSE: 1.6800, Train MAE: 1.4830, Val RMSE: 1.7018, Val MAE: 1.5100\n",
      "Epoch: 008, Train loss: 2.8225, Train RMSE: 1.4703, Train MAE: 1.2790, Val RMSE: 1.4914, Val MAE: 1.3040\n",
      "Epoch: 009, Train loss: 2.1618, Train RMSE: 1.0991, Train MAE: 0.9022, Val RMSE: 1.1125, Val MAE: 0.9176\n",
      "Epoch: 010, Train loss: 1.2081, Train RMSE: 1.1119, Train MAE: 0.8422, Val RMSE: 1.1003, Val MAE: 0.8313\n",
      "Epoch: 011, Train loss: 1.2376, Train RMSE: 1.4022, Train MAE: 1.1006, Val RMSE: 1.3804, Val MAE: 1.0777\n",
      "Epoch: 012, Train loss: 2.0035, Train RMSE: 1.2386, Train MAE: 0.9528, Val RMSE: 1.2216, Val MAE: 0.9356\n",
      "Epoch: 013, Train loss: 1.5455, Train RMSE: 1.0017, Train MAE: 0.7865, Val RMSE: 1.0034, Val MAE: 0.7907\n",
      "Epoch: 014, Train loss: 1.0039, Train RMSE: 1.0969, Train MAE: 0.9017, Val RMSE: 1.1138, Val MAE: 0.9204\n",
      "Epoch: 015, Train loss: 1.2032, Train RMSE: 1.2296, Train MAE: 1.0392, Val RMSE: 1.2505, Val MAE: 1.0613\n",
      "Epoch: 016, Train loss: 1.5120, Train RMSE: 1.2159, Train MAE: 1.0256, Val RMSE: 1.2369, Val MAE: 1.0476\n",
      "Epoch: 017, Train loss: 1.4784, Train RMSE: 1.0811, Train MAE: 0.8875, Val RMSE: 1.0987, Val MAE: 0.9068\n",
      "Epoch: 018, Train loss: 1.1688, Train RMSE: 0.9804, Train MAE: 0.7757, Val RMSE: 0.9870, Val MAE: 0.7858\n",
      "Epoch: 019, Train loss: 0.9615, Train RMSE: 1.0664, Train MAE: 0.8059, Val RMSE: 1.0594, Val MAE: 0.8020\n",
      "Epoch: 020, Train loss: 1.1420, Train RMSE: 1.1362, Train MAE: 0.8606, Val RMSE: 1.1253, Val MAE: 0.8524\n",
      "Epoch: 021, Train loss: 1.3025, Train RMSE: 1.0456, Train MAE: 0.7912, Val RMSE: 1.0404, Val MAE: 0.7894\n",
      "Epoch: 022, Train loss: 1.0968, Train RMSE: 0.9702, Train MAE: 0.7630, Val RMSE: 0.9771, Val MAE: 0.7741\n",
      "Epoch: 023, Train loss: 0.9418, Train RMSE: 1.0142, Train MAE: 0.8225, Val RMSE: 1.0302, Val MAE: 0.8413\n",
      "Epoch: 024, Train loss: 1.0288, Train RMSE: 1.0674, Train MAE: 0.8763, Val RMSE: 1.0867, Val MAE: 0.8980\n",
      "Epoch: 025, Train loss: 1.1394, Train RMSE: 1.0523, Train MAE: 0.8613, Val RMSE: 1.0712, Val MAE: 0.8828\n",
      "Epoch: 026, Train loss: 1.1074, Train RMSE: 0.9897, Train MAE: 0.7972, Val RMSE: 1.0047, Val MAE: 0.8159\n",
      "Epoch: 027, Train loss: 0.9796, Train RMSE: 0.9606, Train MAE: 0.7508, Val RMSE: 0.9678, Val MAE: 0.7629\n",
      "Epoch: 028, Train loss: 0.9231, Train RMSE: 1.0007, Train MAE: 0.7610, Val RMSE: 1.0002, Val MAE: 0.7648\n",
      "Epoch: 029, Train loss: 1.0026, Train RMSE: 1.0236, Train MAE: 0.7744, Val RMSE: 1.0210, Val MAE: 0.7760\n",
      "Epoch: 030, Train loss: 1.0498, Train RMSE: 0.9837, Train MAE: 0.7513, Val RMSE: 0.9855, Val MAE: 0.7578\n",
      "Epoch: 031, Train loss: 0.9686, Train RMSE: 0.9523, Train MAE: 0.7462, Val RMSE: 0.9617, Val MAE: 0.7604\n",
      "Epoch: 032, Train loss: 0.9071, Train RMSE: 0.9701, Train MAE: 0.7771, Val RMSE: 0.9855, Val MAE: 0.7962\n",
      "Epoch: 033, Train loss: 0.9412, Train RMSE: 0.9922, Train MAE: 0.8022, Val RMSE: 1.0100, Val MAE: 0.8234\n",
      "Epoch: 034, Train loss: 0.9846, Train RMSE: 0.9814, Train MAE: 0.7906, Val RMSE: 0.9985, Val MAE: 0.8112\n",
      "Epoch: 035, Train loss: 0.9632, Train RMSE: 0.9505, Train MAE: 0.7528, Val RMSE: 0.9641, Val MAE: 0.7706\n",
      "Epoch: 036, Train loss: 0.9037, Train RMSE: 0.9508, Train MAE: 0.7349, Val RMSE: 0.9586, Val MAE: 0.7475\n",
      "Epoch: 037, Train loss: 0.9048, Train RMSE: 0.9694, Train MAE: 0.7403, Val RMSE: 0.9741, Val MAE: 0.7498\n",
      "Epoch: 038, Train loss: 0.9411, Train RMSE: 0.9589, Train MAE: 0.7350, Val RMSE: 0.9653, Val MAE: 0.7462\n",
      "Epoch: 039, Train loss: 0.9206, Train RMSE: 0.9402, Train MAE: 0.7320, Val RMSE: 0.9514, Val MAE: 0.7479\n",
      "Epoch: 040, Train loss: 0.8847, Train RMSE: 0.9434, Train MAE: 0.7466, Val RMSE: 0.9589, Val MAE: 0.7658\n",
      "Epoch: 041, Train loss: 0.8904, Train RMSE: 0.9519, Train MAE: 0.7587, Val RMSE: 0.9694, Val MAE: 0.7793\n",
      "Epoch: 042, Train loss: 0.9064, Train RMSE: 0.9466, Train MAE: 0.7524, Val RMSE: 0.9641, Val MAE: 0.7730\n",
      "Epoch: 043, Train loss: 0.8964, Train RMSE: 0.9350, Train MAE: 0.7354, Val RMSE: 0.9507, Val MAE: 0.7550\n",
      "Epoch: 044, Train loss: 0.8747, Train RMSE: 0.9334, Train MAE: 0.7239, Val RMSE: 0.9466, Val MAE: 0.7420\n",
      "Epoch: 045, Train loss: 0.8721, Train RMSE: 0.9394, Train MAE: 0.7221, Val RMSE: 0.9509, Val MAE: 0.7386\n",
      "Epoch: 046, Train loss: 0.8838, Train RMSE: 0.9367, Train MAE: 0.7205, Val RMSE: 0.9488, Val MAE: 0.7374\n",
      "Epoch: 047, Train loss: 0.8789, Train RMSE: 0.9282, Train MAE: 0.7199, Val RMSE: 0.9428, Val MAE: 0.7391\n",
      "Epoch: 048, Train loss: 0.8627, Train RMSE: 0.9268, Train MAE: 0.7266, Val RMSE: 0.9442, Val MAE: 0.7472\n",
      "Epoch: 049, Train loss: 0.8596, Train RMSE: 0.9302, Train MAE: 0.7339, Val RMSE: 0.9495, Val MAE: 0.7555\n",
      "Epoch: 050, Train loss: 0.8659, Train RMSE: 0.9286, Train MAE: 0.7323, Val RMSE: 0.9482, Val MAE: 0.7541\n",
      "Epoch: 051, Train loss: 0.8629, Train RMSE: 0.9223, Train MAE: 0.7224, Val RMSE: 0.9411, Val MAE: 0.7438\n",
      "Epoch: 052, Train loss: 0.8515, Train RMSE: 0.9200, Train MAE: 0.7135, Val RMSE: 0.9372, Val MAE: 0.7348\n",
      "Epoch: 053, Train loss: 0.8477, Train RMSE: 0.9222, Train MAE: 0.7103, Val RMSE: 0.9382, Val MAE: 0.7311\n",
      "Epoch: 054, Train loss: 0.8519, Train RMSE: 0.9202, Train MAE: 0.7089, Val RMSE: 0.9367, Val MAE: 0.7301\n",
      "Epoch: 055, Train loss: 0.8484, Train RMSE: 0.9156, Train MAE: 0.7096, Val RMSE: 0.9338, Val MAE: 0.7316\n",
      "Epoch: 056, Train loss: 0.8395, Train RMSE: 0.9147, Train MAE: 0.7142, Val RMSE: 0.9348, Val MAE: 0.7369\n",
      "Epoch: 057, Train loss: 0.8376, Train RMSE: 0.9155, Train MAE: 0.7176, Val RMSE: 0.9368, Val MAE: 0.7408\n",
      "Epoch: 058, Train loss: 0.8390, Train RMSE: 0.9132, Train MAE: 0.7145, Val RMSE: 0.9345, Val MAE: 0.7379\n",
      "Epoch: 059, Train loss: 0.8348, Train RMSE: 0.9095, Train MAE: 0.7072, Val RMSE: 0.9299, Val MAE: 0.7303\n",
      "Epoch: 060, Train loss: 0.8284, Train RMSE: 0.9088, Train MAE: 0.7017, Val RMSE: 0.9280, Val MAE: 0.7246\n",
      "Epoch: 061, Train loss: 0.8274, Train RMSE: 0.9086, Train MAE: 0.6995, Val RMSE: 0.9275, Val MAE: 0.7225\n",
      "Epoch: 062, Train loss: 0.8270, Train RMSE: 0.9056, Train MAE: 0.6991, Val RMSE: 0.9257, Val MAE: 0.7225\n",
      "Epoch: 063, Train loss: 0.8216, Train RMSE: 0.9035, Train MAE: 0.7013, Val RMSE: 0.9254, Val MAE: 0.7255\n",
      "Epoch: 064, Train loss: 0.8175, Train RMSE: 0.9032, Train MAE: 0.7039, Val RMSE: 0.9264, Val MAE: 0.7287\n",
      "Epoch: 065, Train loss: 0.8168, Train RMSE: 0.9017, Train MAE: 0.7024, Val RMSE: 0.9252, Val MAE: 0.7275\n",
      "Epoch: 066, Train loss: 0.8141, Train RMSE: 0.8992, Train MAE: 0.6973, Val RMSE: 0.9221, Val MAE: 0.7224\n",
      "Epoch: 067, Train loss: 0.8097, Train RMSE: 0.8982, Train MAE: 0.6929, Val RMSE: 0.9203, Val MAE: 0.7180\n",
      "Epoch: 068, Train loss: 0.8081, Train RMSE: 0.8969, Train MAE: 0.6910, Val RMSE: 0.9194, Val MAE: 0.7165\n",
      "Epoch: 069, Train loss: 0.8058, Train RMSE: 0.8947, Train MAE: 0.6912, Val RMSE: 0.9184, Val MAE: 0.7173\n",
      "Epoch: 070, Train loss: 0.8018, Train RMSE: 0.8936, Train MAE: 0.6928, Val RMSE: 0.9187, Val MAE: 0.7197\n",
      "Epoch: 071, Train loss: 0.7997, Train RMSE: 0.8927, Train MAE: 0.6928, Val RMSE: 0.9187, Val MAE: 0.7203\n",
      "Epoch: 072, Train loss: 0.7980, Train RMSE: 0.8909, Train MAE: 0.6900, Val RMSE: 0.9172, Val MAE: 0.7180\n",
      "Epoch: 073, Train loss: 0.7948, Train RMSE: 0.8895, Train MAE: 0.6865, Val RMSE: 0.9158, Val MAE: 0.7149\n",
      "Epoch: 074, Train loss: 0.7925, Train RMSE: 0.8885, Train MAE: 0.6844, Val RMSE: 0.9150, Val MAE: 0.7132\n",
      "Epoch: 075, Train loss: 0.7908, Train RMSE: 0.8869, Train MAE: 0.6840, Val RMSE: 0.9143, Val MAE: 0.7132\n",
      "Epoch: 076, Train loss: 0.7879, Train RMSE: 0.8857, Train MAE: 0.6848, Val RMSE: 0.9141, Val MAE: 0.7145\n",
      "Epoch: 077, Train loss: 0.7855, Train RMSE: 0.8847, Train MAE: 0.6850, Val RMSE: 0.9140, Val MAE: 0.7151\n",
      "Epoch: 078, Train loss: 0.7837, Train RMSE: 0.8833, Train MAE: 0.6832, Val RMSE: 0.9131, Val MAE: 0.7136\n",
      "Epoch: 079, Train loss: 0.7813, Train RMSE: 0.8820, Train MAE: 0.6806, Val RMSE: 0.9120, Val MAE: 0.7112\n",
      "Epoch: 080, Train loss: 0.7791, Train RMSE: 0.8809, Train MAE: 0.6790, Val RMSE: 0.9113, Val MAE: 0.7098\n",
      "Epoch: 081, Train loss: 0.7772, Train RMSE: 0.8796, Train MAE: 0.6785, Val RMSE: 0.9108, Val MAE: 0.7098\n",
      "Epoch: 082, Train loss: 0.7749, Train RMSE: 0.8785, Train MAE: 0.6787, Val RMSE: 0.9106, Val MAE: 0.7105\n",
      "Epoch: 083, Train loss: 0.7728, Train RMSE: 0.8774, Train MAE: 0.6782, Val RMSE: 0.9102, Val MAE: 0.7104\n",
      "Epoch: 084, Train loss: 0.7709, Train RMSE: 0.8762, Train MAE: 0.6766, Val RMSE: 0.9093, Val MAE: 0.7090\n",
      "Epoch: 085, Train loss: 0.7687, Train RMSE: 0.8751, Train MAE: 0.6748, Val RMSE: 0.9084, Val MAE: 0.7075\n",
      "Epoch: 086, Train loss: 0.7668, Train RMSE: 0.8740, Train MAE: 0.6737, Val RMSE: 0.9078, Val MAE: 0.7067\n",
      "Epoch: 087, Train loss: 0.7649, Train RMSE: 0.8729, Train MAE: 0.6735, Val RMSE: 0.9076, Val MAE: 0.7069\n",
      "Epoch: 088, Train loss: 0.7629, Train RMSE: 0.8719, Train MAE: 0.6734, Val RMSE: 0.9074, Val MAE: 0.7071\n",
      "Epoch: 089, Train loss: 0.7612, Train RMSE: 0.8709, Train MAE: 0.6724, Val RMSE: 0.9069, Val MAE: 0.7065\n",
      "Epoch: 090, Train loss: 0.7594, Train RMSE: 0.8698, Train MAE: 0.6709, Val RMSE: 0.9062, Val MAE: 0.7053\n",
      "Epoch: 091, Train loss: 0.7576, Train RMSE: 0.8689, Train MAE: 0.6698, Val RMSE: 0.9057, Val MAE: 0.7045\n",
      "Epoch: 092, Train loss: 0.7559, Train RMSE: 0.8679, Train MAE: 0.6694, Val RMSE: 0.9054, Val MAE: 0.7045\n",
      "Epoch: 093, Train loss: 0.7541, Train RMSE: 0.8670, Train MAE: 0.6693, Val RMSE: 0.9052, Val MAE: 0.7046\n",
      "Epoch: 094, Train loss: 0.7526, Train RMSE: 0.8661, Train MAE: 0.6685, Val RMSE: 0.9048, Val MAE: 0.7040\n",
      "Epoch: 095, Train loss: 0.7510, Train RMSE: 0.8652, Train MAE: 0.6671, Val RMSE: 0.9043, Val MAE: 0.7029\n",
      "Epoch: 096, Train loss: 0.7496, Train RMSE: 0.8644, Train MAE: 0.6664, Val RMSE: 0.9039, Val MAE: 0.7025\n",
      "Epoch: 097, Train loss: 0.7481, Train RMSE: 0.8636, Train MAE: 0.6661, Val RMSE: 0.9038, Val MAE: 0.7026\n",
      "Epoch: 098, Train loss: 0.7467, Train RMSE: 0.8629, Train MAE: 0.6659, Val RMSE: 0.9036, Val MAE: 0.7026\n",
      "Epoch: 099, Train loss: 0.7454, Train RMSE: 0.8621, Train MAE: 0.6652, Val RMSE: 0.9032, Val MAE: 0.7020\n",
      "Epoch: 100, Train loss: 0.7441, Train RMSE: 0.8614, Train MAE: 0.6642, Val RMSE: 0.9029, Val MAE: 0.7013\n",
      "Epoch: 101, Train loss: 0.7428, Train RMSE: 0.8606, Train MAE: 0.6636, Val RMSE: 0.9026, Val MAE: 0.7010\n",
      "Epoch: 102, Train loss: 0.7415, Train RMSE: 0.8599, Train MAE: 0.6633, Val RMSE: 0.9025, Val MAE: 0.7010\n",
      "Epoch: 103, Train loss: 0.7402, Train RMSE: 0.8592, Train MAE: 0.6628, Val RMSE: 0.9022, Val MAE: 0.7007\n",
      "Epoch: 104, Train loss: 0.7389, Train RMSE: 0.8584, Train MAE: 0.6622, Val RMSE: 0.9020, Val MAE: 0.7003\n",
      "Epoch: 105, Train loss: 0.7377, Train RMSE: 0.8577, Train MAE: 0.6615, Val RMSE: 0.9017, Val MAE: 0.7000\n",
      "Epoch: 106, Train loss: 0.7365, Train RMSE: 0.8571, Train MAE: 0.6611, Val RMSE: 0.9016, Val MAE: 0.7000\n",
      "Epoch: 107, Train loss: 0.7354, Train RMSE: 0.8565, Train MAE: 0.6608, Val RMSE: 0.9015, Val MAE: 0.7000\n",
      "Epoch: 108, Train loss: 0.7343, Train RMSE: 0.8558, Train MAE: 0.6601, Val RMSE: 0.9012, Val MAE: 0.6996\n",
      "Epoch: 109, Train loss: 0.7332, Train RMSE: 0.8552, Train MAE: 0.6594, Val RMSE: 0.9008, Val MAE: 0.6991\n",
      "Epoch: 110, Train loss: 0.7321, Train RMSE: 0.8546, Train MAE: 0.6591, Val RMSE: 0.9005, Val MAE: 0.6990\n",
      "Epoch: 111, Train loss: 0.7310, Train RMSE: 0.8540, Train MAE: 0.6588, Val RMSE: 0.9002, Val MAE: 0.6989\n",
      "Epoch: 112, Train loss: 0.7300, Train RMSE: 0.8534, Train MAE: 0.6582, Val RMSE: 0.8999, Val MAE: 0.6985\n",
      "Epoch: 113, Train loss: 0.7289, Train RMSE: 0.8528, Train MAE: 0.6575, Val RMSE: 0.8995, Val MAE: 0.6980\n",
      "Epoch: 114, Train loss: 0.7280, Train RMSE: 0.8522, Train MAE: 0.6571, Val RMSE: 0.8993, Val MAE: 0.6978\n",
      "Epoch: 115, Train loss: 0.7270, Train RMSE: 0.8517, Train MAE: 0.6568, Val RMSE: 0.8991, Val MAE: 0.6977\n",
      "Epoch: 116, Train loss: 0.7261, Train RMSE: 0.8512, Train MAE: 0.6563, Val RMSE: 0.8988, Val MAE: 0.6974\n",
      "Epoch: 117, Train loss: 0.7251, Train RMSE: 0.8507, Train MAE: 0.6558, Val RMSE: 0.8986, Val MAE: 0.6971\n",
      "Epoch: 118, Train loss: 0.7242, Train RMSE: 0.8501, Train MAE: 0.6554, Val RMSE: 0.8985, Val MAE: 0.6971\n",
      "Epoch: 119, Train loss: 0.7234, Train RMSE: 0.8496, Train MAE: 0.6549, Val RMSE: 0.8982, Val MAE: 0.6968\n",
      "Epoch: 120, Train loss: 0.7225, Train RMSE: 0.8492, Train MAE: 0.6544, Val RMSE: 0.8980, Val MAE: 0.6965\n",
      "Epoch: 121, Train loss: 0.7217, Train RMSE: 0.8487, Train MAE: 0.6542, Val RMSE: 0.8979, Val MAE: 0.6965\n",
      "Epoch: 122, Train loss: 0.7208, Train RMSE: 0.8482, Train MAE: 0.6539, Val RMSE: 0.8978, Val MAE: 0.6964\n",
      "Epoch: 123, Train loss: 0.7200, Train RMSE: 0.8477, Train MAE: 0.6533, Val RMSE: 0.8975, Val MAE: 0.6960\n",
      "Epoch: 124, Train loss: 0.7193, Train RMSE: 0.8473, Train MAE: 0.6531, Val RMSE: 0.8974, Val MAE: 0.6960\n",
      "Epoch: 125, Train loss: 0.7185, Train RMSE: 0.8468, Train MAE: 0.6528, Val RMSE: 0.8974, Val MAE: 0.6960\n",
      "Epoch: 126, Train loss: 0.7177, Train RMSE: 0.8464, Train MAE: 0.6523, Val RMSE: 0.8973, Val MAE: 0.6958\n",
      "Epoch: 127, Train loss: 0.7170, Train RMSE: 0.8460, Train MAE: 0.6520, Val RMSE: 0.8972, Val MAE: 0.6957\n",
      "Epoch: 128, Train loss: 0.7162, Train RMSE: 0.8456, Train MAE: 0.6516, Val RMSE: 0.8970, Val MAE: 0.6954\n",
      "Epoch: 129, Train loss: 0.7155, Train RMSE: 0.8451, Train MAE: 0.6512, Val RMSE: 0.8969, Val MAE: 0.6952\n",
      "Epoch: 130, Train loss: 0.7148, Train RMSE: 0.8447, Train MAE: 0.6509, Val RMSE: 0.8968, Val MAE: 0.6951\n",
      "Epoch: 131, Train loss: 0.7141, Train RMSE: 0.8443, Train MAE: 0.6506, Val RMSE: 0.8967, Val MAE: 0.6949\n",
      "Epoch: 132, Train loss: 0.7134, Train RMSE: 0.8439, Train MAE: 0.6502, Val RMSE: 0.8964, Val MAE: 0.6946\n",
      "Epoch: 133, Train loss: 0.7127, Train RMSE: 0.8435, Train MAE: 0.6500, Val RMSE: 0.8964, Val MAE: 0.6945\n",
      "Epoch: 134, Train loss: 0.7121, Train RMSE: 0.8431, Train MAE: 0.6495, Val RMSE: 0.8963, Val MAE: 0.6942\n",
      "Epoch: 135, Train loss: 0.7114, Train RMSE: 0.8428, Train MAE: 0.6492, Val RMSE: 0.8963, Val MAE: 0.6943\n",
      "Epoch: 136, Train loss: 0.7108, Train RMSE: 0.8424, Train MAE: 0.6491, Val RMSE: 0.8964, Val MAE: 0.6945\n",
      "Epoch: 137, Train loss: 0.7101, Train RMSE: 0.8420, Train MAE: 0.6486, Val RMSE: 0.8964, Val MAE: 0.6943\n",
      "Epoch: 138, Train loss: 0.7095, Train RMSE: 0.8416, Train MAE: 0.6485, Val RMSE: 0.8965, Val MAE: 0.6945\n",
      "Epoch: 139, Train loss: 0.7089, Train RMSE: 0.8413, Train MAE: 0.6479, Val RMSE: 0.8965, Val MAE: 0.6943\n",
      "Epoch: 140, Train loss: 0.7082, Train RMSE: 0.8409, Train MAE: 0.6477, Val RMSE: 0.8964, Val MAE: 0.6942\n",
      "Epoch: 141, Train loss: 0.7076, Train RMSE: 0.8406, Train MAE: 0.6475, Val RMSE: 0.8964, Val MAE: 0.6942\n",
      "Epoch: 142, Train loss: 0.7071, Train RMSE: 0.8402, Train MAE: 0.6470, Val RMSE: 0.8962, Val MAE: 0.6939\n",
      "Epoch: 143, Train loss: 0.7065, Train RMSE: 0.8399, Train MAE: 0.6469, Val RMSE: 0.8962, Val MAE: 0.6939\n",
      "Epoch: 144, Train loss: 0.7059, Train RMSE: 0.8396, Train MAE: 0.6466, Val RMSE: 0.8961, Val MAE: 0.6937\n",
      "Epoch: 145, Train loss: 0.7054, Train RMSE: 0.8393, Train MAE: 0.6464, Val RMSE: 0.8961, Val MAE: 0.6936\n",
      "Epoch: 146, Train loss: 0.7049, Train RMSE: 0.8390, Train MAE: 0.6461, Val RMSE: 0.8961, Val MAE: 0.6936\n",
      "Epoch: 147, Train loss: 0.7043, Train RMSE: 0.8387, Train MAE: 0.6457, Val RMSE: 0.8960, Val MAE: 0.6934\n",
      "Epoch: 148, Train loss: 0.7038, Train RMSE: 0.8384, Train MAE: 0.6454, Val RMSE: 0.8959, Val MAE: 0.6932\n",
      "Epoch: 149, Train loss: 0.7033, Train RMSE: 0.8381, Train MAE: 0.6453, Val RMSE: 0.8959, Val MAE: 0.6931\n",
      "Epoch: 150, Train loss: 0.7028, Train RMSE: 0.8378, Train MAE: 0.6449, Val RMSE: 0.8958, Val MAE: 0.6929\n",
      "Epoch: 151, Train loss: 0.7023, Train RMSE: 0.8375, Train MAE: 0.6449, Val RMSE: 0.8958, Val MAE: 0.6928\n",
      "Epoch: 152, Train loss: 0.7018, Train RMSE: 0.8372, Train MAE: 0.6444, Val RMSE: 0.8957, Val MAE: 0.6926\n",
      "Epoch: 153, Train loss: 0.7014, Train RMSE: 0.8369, Train MAE: 0.6446, Val RMSE: 0.8958, Val MAE: 0.6928\n",
      "Epoch: 154, Train loss: 0.7009, Train RMSE: 0.8366, Train MAE: 0.6437, Val RMSE: 0.8956, Val MAE: 0.6921\n",
      "Epoch: 155, Train loss: 0.7004, Train RMSE: 0.8364, Train MAE: 0.6443, Val RMSE: 0.8957, Val MAE: 0.6927\n",
      "Epoch: 156, Train loss: 0.7000, Train RMSE: 0.8361, Train MAE: 0.6430, Val RMSE: 0.8953, Val MAE: 0.6916\n",
      "Epoch: 157, Train loss: 0.6996, Train RMSE: 0.8358, Train MAE: 0.6438, Val RMSE: 0.8956, Val MAE: 0.6924\n",
      "Epoch: 158, Train loss: 0.6991, Train RMSE: 0.8355, Train MAE: 0.6428, Val RMSE: 0.8954, Val MAE: 0.6916\n",
      "Epoch: 159, Train loss: 0.6986, Train RMSE: 0.8353, Train MAE: 0.6430, Val RMSE: 0.8955, Val MAE: 0.6920\n",
      "Epoch: 160, Train loss: 0.6982, Train RMSE: 0.8350, Train MAE: 0.6426, Val RMSE: 0.8954, Val MAE: 0.6917\n",
      "Epoch: 161, Train loss: 0.6977, Train RMSE: 0.8348, Train MAE: 0.6424, Val RMSE: 0.8953, Val MAE: 0.6916\n",
      "Epoch: 162, Train loss: 0.6973, Train RMSE: 0.8345, Train MAE: 0.6422, Val RMSE: 0.8952, Val MAE: 0.6914\n",
      "Epoch: 163, Train loss: 0.6969, Train RMSE: 0.8342, Train MAE: 0.6418, Val RMSE: 0.8950, Val MAE: 0.6911\n",
      "Epoch: 164, Train loss: 0.6965, Train RMSE: 0.8340, Train MAE: 0.6418, Val RMSE: 0.8949, Val MAE: 0.6911\n",
      "Epoch: 165, Train loss: 0.6961, Train RMSE: 0.8338, Train MAE: 0.6414, Val RMSE: 0.8948, Val MAE: 0.6909\n",
      "Epoch: 166, Train loss: 0.6957, Train RMSE: 0.8336, Train MAE: 0.6413, Val RMSE: 0.8948, Val MAE: 0.6910\n",
      "Epoch: 167, Train loss: 0.6953, Train RMSE: 0.8333, Train MAE: 0.6409, Val RMSE: 0.8946, Val MAE: 0.6907\n",
      "Epoch: 168, Train loss: 0.6949, Train RMSE: 0.8331, Train MAE: 0.6411, Val RMSE: 0.8946, Val MAE: 0.6909\n",
      "Epoch: 169, Train loss: 0.6946, Train RMSE: 0.8329, Train MAE: 0.6400, Val RMSE: 0.8942, Val MAE: 0.6900\n",
      "Epoch: 170, Train loss: 0.6942, Train RMSE: 0.8329, Train MAE: 0.6418, Val RMSE: 0.8950, Val MAE: 0.6917\n",
      "Epoch: 171, Train loss: 0.6942, Train RMSE: 0.8329, Train MAE: 0.6388, Val RMSE: 0.8941, Val MAE: 0.6890\n",
      "Epoch: 172, Train loss: 0.6944, Train RMSE: 0.8333, Train MAE: 0.6435, Val RMSE: 0.8961, Val MAE: 0.6935\n",
      "Epoch: 173, Train loss: 0.6947, Train RMSE: 0.8324, Train MAE: 0.6382, Val RMSE: 0.8943, Val MAE: 0.6889\n",
      "Epoch: 174, Train loss: 0.6935, Train RMSE: 0.8319, Train MAE: 0.6396, Val RMSE: 0.8943, Val MAE: 0.6902\n",
      "Epoch: 175, Train loss: 0.6925, Train RMSE: 0.8320, Train MAE: 0.6416, Val RMSE: 0.8952, Val MAE: 0.6921\n",
      "Epoch: 176, Train loss: 0.6927, Train RMSE: 0.8319, Train MAE: 0.6379, Val RMSE: 0.8944, Val MAE: 0.6889\n",
      "Epoch: 177, Train loss: 0.6927, Train RMSE: 0.8315, Train MAE: 0.6405, Val RMSE: 0.8952, Val MAE: 0.6914\n",
      "Epoch: 178, Train loss: 0.6918, Train RMSE: 0.8310, Train MAE: 0.6390, Val RMSE: 0.8943, Val MAE: 0.6898\n",
      "Epoch: 179, Train loss: 0.6911, Train RMSE: 0.8310, Train MAE: 0.6377, Val RMSE: 0.8938, Val MAE: 0.6884\n",
      "Epoch: 180, Train loss: 0.6911, Train RMSE: 0.8310, Train MAE: 0.6408, Val RMSE: 0.8952, Val MAE: 0.6915\n",
      "Epoch: 181, Train loss: 0.6910, Train RMSE: 0.8304, Train MAE: 0.6375, Val RMSE: 0.8943, Val MAE: 0.6885\n",
      "Epoch: 182, Train loss: 0.6901, Train RMSE: 0.8300, Train MAE: 0.6373, Val RMSE: 0.8938, Val MAE: 0.6883\n",
      "Epoch: 183, Train loss: 0.6895, Train RMSE: 0.8303, Train MAE: 0.6402, Val RMSE: 0.8949, Val MAE: 0.6909\n",
      "Epoch: 184, Train loss: 0.6899, Train RMSE: 0.8300, Train MAE: 0.6365, Val RMSE: 0.8935, Val MAE: 0.6875\n",
      "Epoch: 185, Train loss: 0.6895, Train RMSE: 0.8295, Train MAE: 0.6386, Val RMSE: 0.8945, Val MAE: 0.6900\n",
      "Epoch: 186, Train loss: 0.6886, Train RMSE: 0.8292, Train MAE: 0.6377, Val RMSE: 0.8943, Val MAE: 0.6891\n",
      "Epoch: 187, Train loss: 0.6881, Train RMSE: 0.8291, Train MAE: 0.6361, Val RMSE: 0.8934, Val MAE: 0.6873\n",
      "Epoch: 188, Train loss: 0.6880, Train RMSE: 0.8292, Train MAE: 0.6392, Val RMSE: 0.8946, Val MAE: 0.6904\n",
      "Epoch: 189, Train loss: 0.6880, Train RMSE: 0.8286, Train MAE: 0.6359, Val RMSE: 0.8933, Val MAE: 0.6873\n",
      "Epoch: 190, Train loss: 0.6871, Train RMSE: 0.8283, Train MAE: 0.6360, Val RMSE: 0.8936, Val MAE: 0.6873\n",
      "Epoch: 191, Train loss: 0.6866, Train RMSE: 0.8282, Train MAE: 0.6376, Val RMSE: 0.8949, Val MAE: 0.6894\n",
      "Epoch: 192, Train loss: 0.6864, Train RMSE: 0.8280, Train MAE: 0.6347, Val RMSE: 0.8935, Val MAE: 0.6866\n",
      "Epoch: 193, Train loss: 0.6862, Train RMSE: 0.8276, Train MAE: 0.6378, Val RMSE: 0.8959, Val MAE: 0.6906\n",
      "Epoch: 194, Train loss: 0.6854, Train RMSE: 0.8268, Train MAE: 0.6346, Val RMSE: 0.8950, Val MAE: 0.6877\n",
      "Epoch: 195, Train loss: 0.6842, Train RMSE: 0.8268, Train MAE: 0.6354, Val RMSE: 0.8984, Val MAE: 0.6901\n",
      "Epoch: 196, Train loss: 0.6842, Train RMSE: 0.8269, Train MAE: 0.6337, Val RMSE: 0.8945, Val MAE: 0.6865\n",
      "Epoch: 197, Train loss: 0.6844, Train RMSE: 0.8283, Train MAE: 0.6415, Val RMSE: 0.8986, Val MAE: 0.6945\n",
      "Epoch: 198, Train loss: 0.6864, Train RMSE: 0.8273, Train MAE: 0.6336, Val RMSE: 0.8936, Val MAE: 0.6860\n",
      "Epoch: 199, Train loss: 0.6849, Train RMSE: 0.8254, Train MAE: 0.6360, Val RMSE: 0.8955, Val MAE: 0.6896\n",
      "Epoch: 200, Train loss: 0.6816, Train RMSE: 0.8255, Train MAE: 0.6359, Val RMSE: 0.8970, Val MAE: 0.6902\n",
      "Epoch: 201, Train loss: 0.6818, Train RMSE: 0.8281, Train MAE: 0.6318, Val RMSE: 0.8939, Val MAE: 0.6838\n",
      "Epoch: 202, Train loss: 0.6865, Train RMSE: 0.8307, Train MAE: 0.6458, Val RMSE: 0.9041, Val MAE: 0.7002\n",
      "Epoch: 203, Train loss: 0.6903, Train RMSE: 0.8281, Train MAE: 0.6326, Val RMSE: 0.8925, Val MAE: 0.6839\n",
      "Epoch: 204, Train loss: 0.6863, Train RMSE: 0.8256, Train MAE: 0.6339, Val RMSE: 0.8911, Val MAE: 0.6852\n",
      "Epoch: 205, Train loss: 0.6820, Train RMSE: 0.8287, Train MAE: 0.6439, Val RMSE: 0.8976, Val MAE: 0.6955\n",
      "Epoch: 206, Train loss: 0.6870, Train RMSE: 0.8245, Train MAE: 0.6325, Val RMSE: 0.8913, Val MAE: 0.6851\n",
      "Epoch: 207, Train loss: 0.6803, Train RMSE: 0.8245, Train MAE: 0.6310, Val RMSE: 0.8932, Val MAE: 0.6853\n",
      "Epoch: 208, Train loss: 0.6804, Train RMSE: 0.8288, Train MAE: 0.6417, Val RMSE: 0.9048, Val MAE: 0.6983\n",
      "Epoch: 209, Train loss: 0.6872, Train RMSE: 0.8297, Train MAE: 0.6307, Val RMSE: 0.8954, Val MAE: 0.6832\n",
      "Epoch: 210, Train loss: 0.6894, Train RMSE: 0.8236, Train MAE: 0.6354, Val RMSE: 0.8941, Val MAE: 0.6885\n",
      "Epoch: 211, Train loss: 0.6786, Train RMSE: 0.8271, Train MAE: 0.6426, Val RMSE: 0.8990, Val MAE: 0.6962\n",
      "Epoch: 212, Train loss: 0.6842, Train RMSE: 0.8258, Train MAE: 0.6313, Val RMSE: 0.8917, Val MAE: 0.6833\n",
      "Epoch: 213, Train loss: 0.6825, Train RMSE: 0.8227, Train MAE: 0.6311, Val RMSE: 0.8910, Val MAE: 0.6843\n",
      "Epoch: 214, Train loss: 0.6773, Train RMSE: 0.8280, Train MAE: 0.6433, Val RMSE: 0.9029, Val MAE: 0.6987\n",
      "Epoch: 215, Train loss: 0.6857, Train RMSE: 0.8254, Train MAE: 0.6291, Val RMSE: 0.8921, Val MAE: 0.6818\n",
      "Epoch: 216, Train loss: 0.6821, Train RMSE: 0.8213, Train MAE: 0.6299, Val RMSE: 0.8914, Val MAE: 0.6842\n",
      "Epoch: 217, Train loss: 0.6750, Train RMSE: 0.8262, Train MAE: 0.6415, Val RMSE: 0.9011, Val MAE: 0.6972\n",
      "Epoch: 218, Train loss: 0.6827, Train RMSE: 0.8231, Train MAE: 0.6290, Val RMSE: 0.8907, Val MAE: 0.6820\n",
      "Epoch: 219, Train loss: 0.6779, Train RMSE: 0.8212, Train MAE: 0.6294, Val RMSE: 0.8898, Val MAE: 0.6823\n",
      "Epoch: 220, Train loss: 0.6748, Train RMSE: 0.8250, Train MAE: 0.6408, Val RMSE: 0.8997, Val MAE: 0.6957\n",
      "Epoch: 221, Train loss: 0.6808, Train RMSE: 0.8207, Train MAE: 0.6282, Val RMSE: 0.8899, Val MAE: 0.6817\n",
      "Epoch: 222, Train loss: 0.6740, Train RMSE: 0.8201, Train MAE: 0.6274, Val RMSE: 0.8906, Val MAE: 0.6818\n",
      "Epoch: 223, Train loss: 0.6731, Train RMSE: 0.8229, Train MAE: 0.6371, Val RMSE: 0.8998, Val MAE: 0.6939\n",
      "Epoch: 224, Train loss: 0.6774, Train RMSE: 0.8203, Train MAE: 0.6268, Val RMSE: 0.8904, Val MAE: 0.6808\n",
      "Epoch: 225, Train loss: 0.6733, Train RMSE: 0.8185, Train MAE: 0.6276, Val RMSE: 0.8899, Val MAE: 0.6819\n",
      "Epoch: 226, Train loss: 0.6704, Train RMSE: 0.8210, Train MAE: 0.6359, Val RMSE: 0.8973, Val MAE: 0.6921\n",
      "Epoch: 227, Train loss: 0.6743, Train RMSE: 0.8188, Train MAE: 0.6264, Val RMSE: 0.8896, Val MAE: 0.6808\n",
      "Epoch: 228, Train loss: 0.6709, Train RMSE: 0.8171, Train MAE: 0.6264, Val RMSE: 0.8904, Val MAE: 0.6821\n",
      "Epoch: 229, Train loss: 0.6681, Train RMSE: 0.8195, Train MAE: 0.6335, Val RMSE: 0.8976, Val MAE: 0.6909\n",
      "Epoch: 230, Train loss: 0.6718, Train RMSE: 0.8196, Train MAE: 0.6249, Val RMSE: 0.8897, Val MAE: 0.6789\n",
      "Epoch: 231, Train loss: 0.6723, Train RMSE: 0.8158, Train MAE: 0.6275, Val RMSE: 0.8909, Val MAE: 0.6832\n",
      "Epoch: 232, Train loss: 0.6658, Train RMSE: 0.8175, Train MAE: 0.6317, Val RMSE: 0.8956, Val MAE: 0.6890\n",
      "Epoch: 233, Train loss: 0.6685, Train RMSE: 0.8194, Train MAE: 0.6243, Val RMSE: 0.8895, Val MAE: 0.6783\n",
      "Epoch: 234, Train loss: 0.6719, Train RMSE: 0.8147, Train MAE: 0.6274, Val RMSE: 0.8925, Val MAE: 0.6848\n",
      "Epoch: 235, Train loss: 0.6640, Train RMSE: 0.8150, Train MAE: 0.6286, Val RMSE: 0.8942, Val MAE: 0.6865\n",
      "Epoch: 236, Train loss: 0.6645, Train RMSE: 0.8185, Train MAE: 0.6232, Val RMSE: 0.8895, Val MAE: 0.6772\n",
      "Epoch: 237, Train loss: 0.6705, Train RMSE: 0.8147, Train MAE: 0.6289, Val RMSE: 0.8955, Val MAE: 0.6877\n",
      "Epoch: 238, Train loss: 0.6639, Train RMSE: 0.8123, Train MAE: 0.6235, Val RMSE: 0.8903, Val MAE: 0.6811\n",
      "Epoch: 239, Train loss: 0.6601, Train RMSE: 0.8127, Train MAE: 0.6213, Val RMSE: 0.8891, Val MAE: 0.6783\n",
      "Epoch: 240, Train loss: 0.6608, Train RMSE: 0.8142, Train MAE: 0.6284, Val RMSE: 0.8976, Val MAE: 0.6889\n",
      "Epoch: 241, Train loss: 0.6632, Train RMSE: 0.8176, Train MAE: 0.6218, Val RMSE: 0.8895, Val MAE: 0.6762\n",
      "Epoch: 242, Train loss: 0.6689, Train RMSE: 0.8136, Train MAE: 0.6293, Val RMSE: 0.8968, Val MAE: 0.6894\n",
      "Epoch: 243, Train loss: 0.6621, Train RMSE: 0.8108, Train MAE: 0.6211, Val RMSE: 0.8878, Val MAE: 0.6782\n",
      "Epoch: 244, Train loss: 0.6576, Train RMSE: 0.8092, Train MAE: 0.6203, Val RMSE: 0.8893, Val MAE: 0.6794\n",
      "Epoch: 245, Train loss: 0.6550, Train RMSE: 0.8115, Train MAE: 0.6252, Val RMSE: 0.8975, Val MAE: 0.6877\n",
      "Epoch: 246, Train loss: 0.6587, Train RMSE: 0.8208, Train MAE: 0.6223, Val RMSE: 0.8925, Val MAE: 0.6768\n",
      "Epoch: 247, Train loss: 0.6743, Train RMSE: 0.8194, Train MAE: 0.6372, Val RMSE: 0.9074, Val MAE: 0.6996\n",
      "Epoch: 248, Train loss: 0.6715, Train RMSE: 0.8209, Train MAE: 0.6248, Val RMSE: 0.8887, Val MAE: 0.6769\n",
      "Epoch: 249, Train loss: 0.6743, Train RMSE: 0.8128, Train MAE: 0.6247, Val RMSE: 0.8867, Val MAE: 0.6795\n",
      "Epoch: 250, Train loss: 0.6608, Train RMSE: 0.8232, Train MAE: 0.6427, Val RMSE: 0.9113, Val MAE: 0.7061\n",
      "Epoch: 251, Train loss: 0.6777, Train RMSE: 0.8255, Train MAE: 0.6246, Val RMSE: 0.8943, Val MAE: 0.6780\n",
      "Epoch: 252, Train loss: 0.6823, Train RMSE: 0.8071, Train MAE: 0.6172, Val RMSE: 0.8888, Val MAE: 0.6778\n",
      "Epoch: 253, Train loss: 0.6517, Train RMSE: 0.8339, Train MAE: 0.6507, Val RMSE: 0.9271, Val MAE: 0.7162\n",
      "Epoch: 254, Train loss: 0.6956, Train RMSE: 0.8576, Train MAE: 0.6444, Val RMSE: 0.9142, Val MAE: 0.6916\n",
      "Epoch: 255, Train loss: 0.7371, Train RMSE: 0.8296, Train MAE: 0.6354, Val RMSE: 0.8892, Val MAE: 0.6828\n",
      "Epoch: 256, Train loss: 0.6884, Train RMSE: 0.8560, Train MAE: 0.6794, Val RMSE: 0.9200, Val MAE: 0.7286\n",
      "Epoch: 257, Train loss: 0.7328, Train RMSE: 0.8340, Train MAE: 0.6519, Val RMSE: 0.8982, Val MAE: 0.7016\n",
      "Epoch: 258, Train loss: 0.6955, Train RMSE: 0.8371, Train MAE: 0.6327, Val RMSE: 0.8964, Val MAE: 0.6815\n",
      "Epoch: 259, Train loss: 0.7018, Train RMSE: 0.8239, Train MAE: 0.6245, Val RMSE: 0.8900, Val MAE: 0.6773\n",
      "Epoch: 260, Train loss: 0.6798, Train RMSE: 0.8336, Train MAE: 0.6494, Val RMSE: 0.9170, Val MAE: 0.7093\n",
      "Epoch: 261, Train loss: 0.6952, Train RMSE: 0.8221, Train MAE: 0.6342, Val RMSE: 0.9060, Val MAE: 0.6957\n",
      "Epoch: 262, Train loss: 0.6762, Train RMSE: 0.8319, Train MAE: 0.6268, Val RMSE: 0.9019, Val MAE: 0.6818\n",
      "Epoch: 263, Train loss: 0.6944, Train RMSE: 0.8137, Train MAE: 0.6197, Val RMSE: 0.8899, Val MAE: 0.6772\n",
      "Epoch: 264, Train loss: 0.6628, Train RMSE: 0.8263, Train MAE: 0.6452, Val RMSE: 0.9110, Val MAE: 0.7062\n",
      "Epoch: 265, Train loss: 0.6829, Train RMSE: 0.8130, Train MAE: 0.6279, Val RMSE: 0.8931, Val MAE: 0.6860\n",
      "Epoch: 266, Train loss: 0.6611, Train RMSE: 0.8214, Train MAE: 0.6222, Val RMSE: 0.8934, Val MAE: 0.6769\n",
      "Epoch: 267, Train loss: 0.6755, Train RMSE: 0.8091, Train MAE: 0.6174, Val RMSE: 0.8894, Val MAE: 0.6761\n",
      "Epoch: 268, Train loss: 0.6551, Train RMSE: 0.8218, Train MAE: 0.6386, Val RMSE: 0.9120, Val MAE: 0.7015\n",
      "Epoch: 269, Train loss: 0.6755, Train RMSE: 0.8074, Train MAE: 0.6159, Val RMSE: 0.8882, Val MAE: 0.6749\n",
      "Epoch: 270, Train loss: 0.6523, Train RMSE: 0.8142, Train MAE: 0.6175, Val RMSE: 0.8895, Val MAE: 0.6737\n",
      "Epoch: 271, Train loss: 0.6637, Train RMSE: 0.8078, Train MAE: 0.6232, Val RMSE: 0.8924, Val MAE: 0.6850\n",
      "Epoch: 272, Train loss: 0.6527, Train RMSE: 0.8099, Train MAE: 0.6267, Val RMSE: 0.8960, Val MAE: 0.6895\n",
      "Epoch: 273, Train loss: 0.6560, Train RMSE: 0.8089, Train MAE: 0.6150, Val RMSE: 0.8869, Val MAE: 0.6733\n",
      "Epoch: 274, Train loss: 0.6548, Train RMSE: 0.8056, Train MAE: 0.6136, Val RMSE: 0.8869, Val MAE: 0.6740\n",
      "Epoch: 275, Train loss: 0.6494, Train RMSE: 0.8107, Train MAE: 0.6271, Val RMSE: 0.9010, Val MAE: 0.6919\n",
      "Epoch: 276, Train loss: 0.6575, Train RMSE: 0.8030, Train MAE: 0.6137, Val RMSE: 0.8876, Val MAE: 0.6757\n",
      "Epoch: 277, Train loss: 0.6451, Train RMSE: 0.8067, Train MAE: 0.6133, Val RMSE: 0.8874, Val MAE: 0.6731\n",
      "Epoch: 278, Train loss: 0.6511, Train RMSE: 0.8036, Train MAE: 0.6191, Val RMSE: 0.8930, Val MAE: 0.6836\n",
      "Epoch: 279, Train loss: 0.6459, Train RMSE: 0.8029, Train MAE: 0.6180, Val RMSE: 0.8930, Val MAE: 0.6833\n",
      "Epoch: 280, Train loss: 0.6448, Train RMSE: 0.8044, Train MAE: 0.6120, Val RMSE: 0.8885, Val MAE: 0.6740\n",
      "Epoch: 281, Train loss: 0.6475, Train RMSE: 0.8004, Train MAE: 0.6120, Val RMSE: 0.8898, Val MAE: 0.6778\n",
      "Early stopping triggered at epoch 281. Best validation RMSE: 0.8867 at epoch 249.\n",
      "Best model with lowest validation RMSE restored from epoch 249.\n",
      "\n",
      "TensorBoard training information of model full_retrained_model saved at path: D:\\Internship\\trained_models\\runs\\training_plot_full_retrained_model_350_epochs_0.01_lr\n",
      "\n",
      "Trained model full_retrained_model saved at path: D:\\Internship\\trained_models\n"
     ]
    }
   ],
   "source": [
    "# Full retrain the model\n",
    "GraphSAGE_model.full_retrain(\n",
    "    num_epochs=350,\n",
    "    lr=0.01,\n",
    "    model_name=\"full_retrained_model\",\n",
    "    trained_model_path=trained_models_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda\n",
      "'\n",
      "Test RMSE: 0.9105, Test MAE: 0.7000\n",
      "\n",
      "      userId  movieId  pred_rating  gt_rating\n",
      "0        514     9645     3.878598        2.5\n",
      "1         26      286     4.348916        5.0\n",
      "2        599    44114     3.761158        5.0\n",
      "3        101     7008     4.153367        4.0\n",
      "4        101    11443     4.113421        3.0\n",
      "...      ...      ...          ...        ...\n",
      "4495     246     2244     3.379130        2.0\n",
      "4496     104    10299     2.938054        3.0\n",
      "4497     469     5044     3.506150        3.0\n",
      "4498     129    36979     3.285060        4.0\n",
      "4499     563    10009     1.145944        1.0\n",
      "\n",
      "[4500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate general performance after full retraining\n",
    "GraphSAGE_model.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"display: flex; justify-content: space-around;\">\n",
       "        <div>\n",
       "            <h4>Training Data</h4>\n",
       "            <p>RMSE: 0.9151</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>3.588421</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8844</td>\n",
       "      <td>4.458500</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.975657</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.400517</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>3.555361</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>3.912991</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1366</td>\n",
       "      <td>4.333863</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>4.355219</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.093032</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>3.177104</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.732851</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10625</td>\n",
       "      <td>3.578928</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>673</td>\n",
       "      <td>3.590487</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11036</td>\n",
       "      <td>3.597401</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>3.643429</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37799</td>\n",
       "      <td>4.546115</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49051</td>\n",
       "      <td>4.939208</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313369</td>\n",
       "      <td>1.792868</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div>\n",
       "            <h4>Test Data</h4>\n",
       "            <p>RMSE: 1.4079</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8358</td>\n",
       "      <td>3.318212</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>3.751835</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11034</td>\n",
       "      <td>3.406344</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>4.249714</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>3.869349</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1726</td>\n",
       "      <td>3.338596</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>4.268681</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19995</td>\n",
       "      <td>2.599612</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12444</td>\n",
       "      <td>3.950366</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12445</td>\n",
       "      <td>3.881575</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57158</td>\n",
       "      <td>3.523490</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164251</td>\n",
       "      <td>3.552463</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122917</td>\n",
       "      <td>3.556771</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate performance specifically over the new training data\n",
    "evaluate_model_performance(GraphSAGE_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Incremental training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "GraphSAGE_model = GNNRetrainModelHandler.load_pretrained_model(\n",
    "    pretrained_model_filepath=GraphSAGE_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 new movies to add to 'movies_df': Movies ids [414906, 693134]\n",
      "Found 20 new ratings to add to 'users_ratings_df'\n",
      "Found 1 new users to add to 'users_ratings_df': Users ids [1000]\n"
     ]
    }
   ],
   "source": [
    "# Set the new train set for the re-training of the model\n",
    "GraphSAGE_model.add_new_train_data(new_movies_df=new_movies_df, new_ratings_df=new_users_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n",
      "Adaptive patience set to 15 epochs based on num_epochs=15.\n",
      "Epoch: 001, Train loss: 1.5888, Train RMSE: 1.0700, Train MAE: 0.7461, Val RMSE: 0.9088, Val MAE: 0.6886\n",
      "Epoch: 002, Train loss: 1.2983, Train RMSE: 1.0069, Train MAE: 0.6909, Val RMSE: 0.9031, Val MAE: 0.6894\n",
      "Epoch: 003, Train loss: 1.0906, Train RMSE: 0.9528, Train MAE: 0.6677, Val RMSE: 0.9059, Val MAE: 0.7031\n",
      "Epoch: 004, Train loss: 0.9232, Train RMSE: 0.9116, Train MAE: 0.6663, Val RMSE: 0.9255, Val MAE: 0.7321\n",
      "Epoch: 005, Train loss: 0.8362, Train RMSE: 0.8956, Train MAE: 0.6589, Val RMSE: 0.9509, Val MAE: 0.7631\n",
      "Epoch: 006, Train loss: 0.8030, Train RMSE: 0.8802, Train MAE: 0.6533, Val RMSE: 0.9649, Val MAE: 0.7793\n",
      "Epoch: 007, Train loss: 0.7748, Train RMSE: 0.8554, Train MAE: 0.6259, Val RMSE: 0.9634, Val MAE: 0.7770\n",
      "Epoch: 008, Train loss: 0.7318, Train RMSE: 0.8234, Train MAE: 0.5785, Val RMSE: 0.9519, Val MAE: 0.7623\n",
      "Epoch: 009, Train loss: 0.6781, Train RMSE: 0.7928, Train MAE: 0.5316, Val RMSE: 0.9385, Val MAE: 0.7437\n",
      "Epoch: 010, Train loss: 0.6301, Train RMSE: 0.7697, Train MAE: 0.4985, Val RMSE: 0.9293, Val MAE: 0.7280\n",
      "Epoch: 011, Train loss: 0.5973, Train RMSE: 0.7536, Train MAE: 0.4756, Val RMSE: 0.9265, Val MAE: 0.7191\n",
      "Epoch: 012, Train loss: 0.5761, Train RMSE: 0.7383, Train MAE: 0.4590, Val RMSE: 0.9271, Val MAE: 0.7154\n",
      "Epoch: 013, Train loss: 0.5552, Train RMSE: 0.7203, Train MAE: 0.4456, Val RMSE: 0.9279, Val MAE: 0.7150\n",
      "Epoch: 014, Train loss: 0.5285, Train RMSE: 0.7012, Train MAE: 0.4343, Val RMSE: 0.9281, Val MAE: 0.7167\n",
      "Epoch: 015, Train loss: 0.4992, Train RMSE: 0.6852, Train MAE: 0.4276, Val RMSE: 0.9287, Val MAE: 0.7200\n",
      "Best model with lowest validation RMSE restored from epoch 11.\n",
      "\n",
      "TensorBoard training information of model incremental_trained_model saved at path: D:\\Internship\\trained_models\\runs\\training_plot_incremental_trained_model_15_epochs_0.001_lr\n",
      "\n",
      "Trained model incremental_trained_model saved at path: D:\\Internship\\trained_models\n"
     ]
    }
   ],
   "source": [
    "# Incremental train the model\n",
    "GraphSAGE_model.incremental_train(\n",
    "    num_epochs=15,\n",
    "    lr=0.001,\n",
    "    model_name=\"incremental_trained_model\",\n",
    "    trained_model_path=trained_models_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda\n",
      "'\n",
      "Test RMSE: 0.9368, Test MAE: 0.7280\n",
      "\n",
      "      userId  movieId  pred_rating  gt_rating\n",
      "0        514     9645     3.692862        2.5\n",
      "1         26      286     4.035707        5.0\n",
      "2        599    44114     3.519161        5.0\n",
      "3        101     7008     3.927359        4.0\n",
      "4        101    11443     4.028891        3.0\n",
      "...      ...      ...          ...        ...\n",
      "4495     246     2244     3.171138        2.0\n",
      "4496     104    10299     3.245615        3.0\n",
      "4497     469     5044     3.291425        3.0\n",
      "4498     129    36979     3.431199        4.0\n",
      "4499     563    10009     3.432747        1.0\n",
      "\n",
      "[4500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate general performance after incremental training\n",
    "GraphSAGE_model.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"display: flex; justify-content: space-around;\">\n",
       "        <div>\n",
       "            <h4>Training Data</h4>\n",
       "            <p>RMSE: 1.0017</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>3.777080</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8844</td>\n",
       "      <td>3.360795</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.100924</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>4.065730</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>4.644041</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>3.858717</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>4.277199</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1366</td>\n",
       "      <td>4.368412</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>4.634444</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.317852</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>4.686312</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>4.027935</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>4.275002</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10625</td>\n",
       "      <td>3.722888</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>673</td>\n",
       "      <td>4.228527</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11036</td>\n",
       "      <td>3.612758</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>4.377115</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37799</td>\n",
       "      <td>3.861016</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49051</td>\n",
       "      <td>4.428279</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313369</td>\n",
       "      <td>3.486173</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div>\n",
       "            <h4>Test Data</h4>\n",
       "            <p>RMSE: 1.3544</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8358</td>\n",
       "      <td>3.816863</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>4.193461</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11034</td>\n",
       "      <td>3.608039</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>4.332638</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>3.725600</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1726</td>\n",
       "      <td>3.961396</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>4.515242</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19995</td>\n",
       "      <td>3.587844</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12444</td>\n",
       "      <td>3.753611</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12445</td>\n",
       "      <td>3.718725</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57158</td>\n",
       "      <td>3.661858</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164251</td>\n",
       "      <td>3.525287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122917</td>\n",
       "      <td>3.640488</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate performance specifically over the new training data\n",
    "evaluate_model_performance(GraphSAGE_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "GraphSAGE_model = GNNRetrainModelHandler.load_pretrained_model(\n",
    "    pretrained_model_filepath=\"D:\\\\Internship\\\\recsys\\data\\\\temp\\\\online\\\\online_updated_GNN_user_bdd62e39-8999-468b-be8a-c36277a93bdc.pth\"\n",
    "    #pretrained_model_filepath=\"D:\\\\Internship\\\\recsys\\\\data\\\\temp\\\\offline\\\\offline_updated_GNN_model.pth\"\n",
    "    #pretrained_model_filepath=\"D:\\\\Internship\\\\recsys\\\\data\\\\temp\\\\init\\\\init_GNN_model.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 new movies to add to 'movies_df': Movies ids [414906, 693134]\n",
      "Found 5 new ratings to add to 'users_ratings_df'\n",
      "No new users to add. Users [1000] are already present in 'users_ratings_df'.\n"
     ]
    }
   ],
   "source": [
    "# Set the new train set for the re-training of the model\n",
    "GraphSAGE_model.add_new_train_data(new_movies_df=new_movies_df, new_ratings_df=new_users_ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "GraphSAGE_model = GNNRetrainModelHandler.load_pretrained_model(\n",
    "    pretrained_model_filepath=GraphSAGE_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 new movies to add to 'movies_df': Movies ids [414906, 693134]\n",
      "Found 20 new ratings to add to 'users_ratings_df'\n",
      "Found 1 new users to add to 'users_ratings_df': Users ids [1000]\n"
     ]
    }
   ],
   "source": [
    "# Set the new train set for the re-training of the model\n",
    "GraphSAGE_model.add_new_train_data(new_movies_df=new_movies_df, new_ratings_df=new_users_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n",
      "Adaptive patience set to 29 epochs based on num_epochs=250.\n",
      "Epoch: 001, Loss: 0.7944, Train RMSE: 1.2271, Train MAE: 0.8411, Val RMSE: 1.3346, Val MAE: 1.0302\n",
      "Epoch: 002, Loss: 3.0079, Train RMSE: 1.2951, Train MAE: 1.1559, Val RMSE: 1.4067, Val MAE: 1.2278\n",
      "Epoch: 003, Loss: 0.8481, Train RMSE: 2.0002, Train MAE: 1.8913, Val RMSE: 1.9317, Val MAE: 1.7462\n",
      "Epoch: 004, Loss: 2.0082, Train RMSE: 2.0474, Train MAE: 1.9209, Val RMSE: 1.9550, Val MAE: 1.7701\n",
      "Epoch: 005, Loss: 2.1032, Train RMSE: 1.7005, Train MAE: 1.5820, Val RMSE: 1.7210, Val MAE: 1.5399\n",
      "Epoch: 006, Loss: 1.4533, Train RMSE: 1.1118, Train MAE: 0.9624, Val RMSE: 1.3268, Val MAE: 1.1503\n",
      "Epoch: 007, Loss: 0.6267, Train RMSE: 0.7226, Train MAE: 0.5909, Val RMSE: 0.9797, Val MAE: 0.7846\n",
      "Epoch: 008, Loss: 0.3492, Train RMSE: 0.8581, Train MAE: 0.6167, Val RMSE: 1.0368, Val MAE: 0.7758\n",
      "Epoch: 009, Loss: 0.8356, Train RMSE: 0.9152, Train MAE: 0.6739, Val RMSE: 1.0567, Val MAE: 0.7898\n",
      "Epoch: 010, Loss: 0.8741, Train RMSE: 0.7508, Train MAE: 0.5384, Val RMSE: 0.9659, Val MAE: 0.7436\n",
      "Epoch: 011, Loss: 0.3822, Train RMSE: 0.4768, Train MAE: 0.3224, Val RMSE: 1.0423, Val MAE: 0.8570\n",
      "Epoch: 012, Loss: 0.1226, Train RMSE: 0.6320, Train MAE: 0.5504, Val RMSE: 1.2335, Val MAE: 1.0555\n",
      "Epoch: 013, Loss: 0.2059, Train RMSE: 0.8460, Train MAE: 0.7792, Val RMSE: 1.3794, Val MAE: 1.2024\n",
      "Epoch: 014, Loss: 0.3641, Train RMSE: 0.9038, Train MAE: 0.8311, Val RMSE: 1.4295, Val MAE: 1.2523\n",
      "Epoch: 015, Loss: 0.4147, Train RMSE: 0.8135, Train MAE: 0.7187, Val RMSE: 1.3905, Val MAE: 1.2129\n",
      "Epoch: 016, Loss: 0.3372, Train RMSE: 0.6470, Train MAE: 0.5270, Val RMSE: 1.2870, Val MAE: 1.1081\n",
      "Epoch: 017, Loss: 0.2159, Train RMSE: 0.5287, Train MAE: 0.3889, Val RMSE: 1.1622, Val MAE: 0.9804\n",
      "Epoch: 018, Loss: 0.1646, Train RMSE: 0.4962, Train MAE: 0.3440, Val RMSE: 1.0711, Val MAE: 0.8841\n",
      "Epoch: 019, Loss: 0.1991, Train RMSE: 0.4982, Train MAE: 0.3273, Val RMSE: 1.0321, Val MAE: 0.8405\n",
      "Epoch: 020, Loss: 0.2428, Train RMSE: 0.4437, Train MAE: 0.2821, Val RMSE: 1.0328, Val MAE: 0.8411\n",
      "Epoch: 021, Loss: 0.1886, Train RMSE: 0.3506, Train MAE: 0.2385, Val RMSE: 1.0648, Val MAE: 0.8770\n",
      "Epoch: 022, Loss: 0.0953, Train RMSE: 0.2980, Train MAE: 0.2080, Val RMSE: 1.1191, Val MAE: 0.9348\n",
      "Epoch: 023, Loss: 0.0527, Train RMSE: 0.3561, Train MAE: 0.2901, Val RMSE: 1.1733, Val MAE: 0.9912\n",
      "Epoch: 024, Loss: 0.0694, Train RMSE: 0.4333, Train MAE: 0.3620, Val RMSE: 1.2028, Val MAE: 1.0215\n",
      "Epoch: 025, Loss: 0.0995, Train RMSE: 0.4401, Train MAE: 0.3570, Val RMSE: 1.1971, Val MAE: 1.0154\n",
      "Epoch: 026, Loss: 0.1025, Train RMSE: 0.3861, Train MAE: 0.3096, Val RMSE: 1.1604, Val MAE: 0.9775\n",
      "Epoch: 027, Loss: 0.0820, Train RMSE: 0.3093, Train MAE: 0.2539, Val RMSE: 1.1095, Val MAE: 0.9243\n",
      "Epoch: 028, Loss: 0.0603, Train RMSE: 0.2621, Train MAE: 0.2090, Val RMSE: 1.0653, Val MAE: 0.8767\n",
      "Epoch: 029, Loss: 0.0566, Train RMSE: 0.2769, Train MAE: 0.2026, Val RMSE: 1.0411, Val MAE: 0.8491\n",
      "Epoch: 030, Loss: 0.0701, Train RMSE: 0.2733, Train MAE: 0.1936, Val RMSE: 1.0383, Val MAE: 0.8454\n",
      "Epoch: 031, Loss: 0.0698, Train RMSE: 0.2142, Train MAE: 0.1497, Val RMSE: 1.0554, Val MAE: 0.8649\n",
      "Epoch: 032, Loss: 0.0455, Train RMSE: 0.1523, Train MAE: 0.1057, Val RMSE: 1.0909, Val MAE: 0.9032\n",
      "Epoch: 033, Loss: 0.0231, Train RMSE: 0.1563, Train MAE: 0.1161, Val RMSE: 1.1361, Val MAE: 0.9505\n",
      "Epoch: 034, Loss: 0.0194, Train RMSE: 0.2023, Train MAE: 0.1724, Val RMSE: 1.1753, Val MAE: 0.9909\n",
      "Epoch: 035, Loss: 0.0274, Train RMSE: 0.2340, Train MAE: 0.2036, Val RMSE: 1.1953, Val MAE: 1.0111\n",
      "Epoch: 036, Loss: 0.0348, Train RMSE: 0.2224, Train MAE: 0.1837, Val RMSE: 1.1920, Val MAE: 1.0075\n",
      "Epoch: 037, Loss: 0.0324, Train RMSE: 0.1846, Train MAE: 0.1364, Val RMSE: 1.1712, Val MAE: 0.9858\n",
      "Epoch: 038, Loss: 0.0251, Train RMSE: 0.1728, Train MAE: 0.1261, Val RMSE: 1.1445, Val MAE: 0.9577\n",
      "Epoch: 039, Loss: 0.0250, Train RMSE: 0.1861, Train MAE: 0.1301, Val RMSE: 1.1235, Val MAE: 0.9355\n",
      "Epoch: 040, Loss: 0.0310, Train RMSE: 0.1831, Train MAE: 0.1251, Val RMSE: 1.1150, Val MAE: 0.9265\n",
      "Epoch: 041, Loss: 0.0317, Train RMSE: 0.1596, Train MAE: 0.1084, Val RMSE: 1.1200, Val MAE: 0.9319\n",
      "Epoch: 042, Loss: 0.0248, Train RMSE: 0.1283, Train MAE: 0.0908, Val RMSE: 1.1350, Val MAE: 0.9476\n",
      "Epoch: 043, Loss: 0.0168, Train RMSE: 0.1158, Train MAE: 0.0913, Val RMSE: 1.1523, Val MAE: 0.9657\n",
      "Epoch: 044, Loss: 0.0140, Train RMSE: 0.1368, Train MAE: 0.1123, Val RMSE: 1.1632, Val MAE: 0.9771\n",
      "Epoch: 045, Loss: 0.0163, Train RMSE: 0.1452, Train MAE: 0.1212, Val RMSE: 1.1618, Val MAE: 0.9758\n",
      "Epoch: 046, Loss: 0.0172, Train RMSE: 0.1238, Train MAE: 0.0996, Val RMSE: 1.1483, Val MAE: 0.9618\n",
      "Epoch: 047, Loss: 0.0144, Train RMSE: 0.0999, Train MAE: 0.0769, Val RMSE: 1.1284, Val MAE: 0.9411\n",
      "Epoch: 048, Loss: 0.0121, Train RMSE: 0.1021, Train MAE: 0.0779, Val RMSE: 1.1104, Val MAE: 0.9222\n",
      "Epoch: 049, Loss: 0.0134, Train RMSE: 0.1080, Train MAE: 0.0764, Val RMSE: 1.1006, Val MAE: 0.9117\n",
      "Epoch: 050, Loss: 0.0150, Train RMSE: 0.0995, Train MAE: 0.0682, Val RMSE: 1.1015, Val MAE: 0.9126\n",
      "Epoch: 051, Loss: 0.0140, Train RMSE: 0.0823, Train MAE: 0.0596, Val RMSE: 1.1117, Val MAE: 0.9233\n",
      "Epoch: 052, Loss: 0.0115, Train RMSE: 0.0687, Train MAE: 0.0530, Val RMSE: 1.1272, Val MAE: 0.9394\n",
      "Epoch: 053, Loss: 0.0096, Train RMSE: 0.0761, Train MAE: 0.0642, Val RMSE: 1.1419, Val MAE: 0.9546\n",
      "Epoch: 054, Loss: 0.0099, Train RMSE: 0.0849, Train MAE: 0.0749, Val RMSE: 1.1505, Val MAE: 0.9635\n",
      "Epoch: 055, Loss: 0.0106, Train RMSE: 0.0788, Train MAE: 0.0656, Val RMSE: 1.1509, Val MAE: 0.9638\n",
      "Epoch: 056, Loss: 0.0101, Train RMSE: 0.0539, Train MAE: 0.0395, Val RMSE: 1.1440, Val MAE: 0.9566\n",
      "Epoch: 057, Loss: 0.0086, Train RMSE: 0.0499, Train MAE: 0.0337, Val RMSE: 1.1353, Val MAE: 0.9475\n",
      "Epoch: 058, Loss: 0.0091, Train RMSE: 0.0508, Train MAE: 0.0349, Val RMSE: 1.1295, Val MAE: 0.9414\n",
      "Epoch: 059, Loss: 0.0099, Train RMSE: 0.0474, Train MAE: 0.0327, Val RMSE: 1.1292, Val MAE: 0.9411\n",
      "Epoch: 060, Loss: 0.0098, Train RMSE: 0.0433, Train MAE: 0.0307, Val RMSE: 1.1342, Val MAE: 0.9463\n",
      "Epoch: 061, Loss: 0.0089, Train RMSE: 0.0434, Train MAE: 0.0319, Val RMSE: 1.1418, Val MAE: 0.9543\n",
      "Epoch: 062, Loss: 0.0081, Train RMSE: 0.0528, Train MAE: 0.0418, Val RMSE: 1.1480, Val MAE: 0.9608\n",
      "Epoch: 063, Loss: 0.0082, Train RMSE: 0.0606, Train MAE: 0.0506, Val RMSE: 1.1493, Val MAE: 0.9622\n",
      "Epoch: 064, Loss: 0.0085, Train RMSE: 0.0551, Train MAE: 0.0473, Val RMSE: 1.1449, Val MAE: 0.9576\n",
      "Epoch: 065, Loss: 0.0082, Train RMSE: 0.0441, Train MAE: 0.0337, Val RMSE: 1.1366, Val MAE: 0.9490\n",
      "Epoch: 066, Loss: 0.0077, Train RMSE: 0.0427, Train MAE: 0.0305, Val RMSE: 1.1281, Val MAE: 0.9401\n",
      "Epoch: 067, Loss: 0.0079, Train RMSE: 0.0454, Train MAE: 0.0304, Val RMSE: 1.1227, Val MAE: 0.9345\n",
      "Epoch: 068, Loss: 0.0081, Train RMSE: 0.0431, Train MAE: 0.0296, Val RMSE: 1.1222, Val MAE: 0.9339\n",
      "Epoch: 069, Loss: 0.0080, Train RMSE: 0.0368, Train MAE: 0.0280, Val RMSE: 1.1260, Val MAE: 0.9378\n",
      "Epoch: 070, Loss: 0.0076, Train RMSE: 0.0327, Train MAE: 0.0277, Val RMSE: 1.1318, Val MAE: 0.9439\n",
      "Epoch: 071, Loss: 0.0073, Train RMSE: 0.0354, Train MAE: 0.0281, Val RMSE: 1.1368, Val MAE: 0.9491\n",
      "Epoch: 072, Loss: 0.0074, Train RMSE: 0.0362, Train MAE: 0.0285, Val RMSE: 1.1388, Val MAE: 0.9511\n",
      "Epoch: 073, Loss: 0.0075, Train RMSE: 0.0289, Train MAE: 0.0215, Val RMSE: 1.1373, Val MAE: 0.9496\n",
      "Epoch: 074, Loss: 0.0073, Train RMSE: 0.0225, Train MAE: 0.0147, Val RMSE: 1.1339, Val MAE: 0.9459\n",
      "Epoch: 075, Loss: 0.0072, Train RMSE: 0.0236, Train MAE: 0.0150, Val RMSE: 1.1307, Val MAE: 0.9426\n",
      "Epoch: 076, Loss: 0.0073, Train RMSE: 0.0225, Train MAE: 0.0155, Val RMSE: 1.1297, Val MAE: 0.9415\n",
      "Epoch: 077, Loss: 0.0074, Train RMSE: 0.0182, Train MAE: 0.0122, Val RMSE: 1.1315, Val MAE: 0.9434\n",
      "Epoch: 078, Loss: 0.0073, Train RMSE: 0.0160, Train MAE: 0.0108, Val RMSE: 1.1352, Val MAE: 0.9472\n",
      "Epoch: 079, Loss: 0.0072, Train RMSE: 0.0200, Train MAE: 0.0154, Val RMSE: 1.1389, Val MAE: 0.9511\n",
      "Epoch: 080, Loss: 0.0072, Train RMSE: 0.0253, Train MAE: 0.0212, Val RMSE: 1.1407, Val MAE: 0.9530\n",
      "Epoch: 081, Loss: 0.0072, Train RMSE: 0.0247, Train MAE: 0.0204, Val RMSE: 1.1397, Val MAE: 0.9520\n",
      "Epoch: 082, Loss: 0.0072, Train RMSE: 0.0190, Train MAE: 0.0144, Val RMSE: 1.1365, Val MAE: 0.9487\n",
      "Epoch: 083, Loss: 0.0071, Train RMSE: 0.0170, Train MAE: 0.0112, Val RMSE: 1.1328, Val MAE: 0.9449\n",
      "Epoch: 084, Loss: 0.0071, Train RMSE: 0.0191, Train MAE: 0.0119, Val RMSE: 1.1304, Val MAE: 0.9424\n",
      "Epoch: 085, Loss: 0.0071, Train RMSE: 0.0196, Train MAE: 0.0126, Val RMSE: 1.1301, Val MAE: 0.9421\n",
      "Epoch: 086, Loss: 0.0071, Train RMSE: 0.0194, Train MAE: 0.0129, Val RMSE: 1.1317, Val MAE: 0.9438\n",
      "Epoch: 087, Loss: 0.0070, Train RMSE: 0.0207, Train MAE: 0.0161, Val RMSE: 1.1340, Val MAE: 0.9463\n",
      "Epoch: 088, Loss: 0.0070, Train RMSE: 0.0225, Train MAE: 0.0193, Val RMSE: 1.1356, Val MAE: 0.9479\n",
      "Epoch: 089, Loss: 0.0071, Train RMSE: 0.0221, Train MAE: 0.0186, Val RMSE: 1.1356, Val MAE: 0.9479\n",
      "Epoch: 090, Loss: 0.0071, Train RMSE: 0.0191, Train MAE: 0.0150, Val RMSE: 1.1341, Val MAE: 0.9463\n",
      "Epoch: 091, Loss: 0.0070, Train RMSE: 0.0172, Train MAE: 0.0116, Val RMSE: 1.1321, Val MAE: 0.9443\n",
      "Epoch: 092, Loss: 0.0070, Train RMSE: 0.0170, Train MAE: 0.0102, Val RMSE: 1.1308, Val MAE: 0.9429\n",
      "Epoch: 093, Loss: 0.0070, Train RMSE: 0.0151, Train MAE: 0.0090, Val RMSE: 1.1309, Val MAE: 0.9430\n",
      "Epoch: 094, Loss: 0.0070, Train RMSE: 0.0127, Train MAE: 0.0079, Val RMSE: 1.1323, Val MAE: 0.9444\n",
      "Epoch: 095, Loss: 0.0070, Train RMSE: 0.0131, Train MAE: 0.0098, Val RMSE: 1.1341, Val MAE: 0.9464\n",
      "Epoch: 096, Loss: 0.0070, Train RMSE: 0.0154, Train MAE: 0.0130, Val RMSE: 1.1355, Val MAE: 0.9478\n",
      "Epoch: 097, Loss: 0.0070, Train RMSE: 0.0160, Train MAE: 0.0132, Val RMSE: 1.1356, Val MAE: 0.9479\n",
      "Epoch: 098, Loss: 0.0070, Train RMSE: 0.0138, Train MAE: 0.0105, Val RMSE: 1.1346, Val MAE: 0.9468\n",
      "Epoch: 099, Loss: 0.0070, Train RMSE: 0.0112, Train MAE: 0.0075, Val RMSE: 1.1331, Val MAE: 0.9453\n",
      "Epoch: 100, Loss: 0.0070, Train RMSE: 0.0106, Train MAE: 0.0068, Val RMSE: 1.1321, Val MAE: 0.9442\n",
      "Epoch: 101, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0072, Val RMSE: 1.1321, Val MAE: 0.9442\n",
      "Epoch: 102, Loss: 0.0070, Train RMSE: 0.0117, Train MAE: 0.0081, Val RMSE: 1.1330, Val MAE: 0.9451\n",
      "Epoch: 103, Loss: 0.0070, Train RMSE: 0.0130, Train MAE: 0.0098, Val RMSE: 1.1341, Val MAE: 0.9463\n",
      "Epoch: 104, Loss: 0.0070, Train RMSE: 0.0137, Train MAE: 0.0111, Val RMSE: 1.1348, Val MAE: 0.9471\n",
      "Epoch: 105, Loss: 0.0070, Train RMSE: 0.0134, Train MAE: 0.0110, Val RMSE: 1.1348, Val MAE: 0.9470\n",
      "Epoch: 106, Loss: 0.0070, Train RMSE: 0.0124, Train MAE: 0.0097, Val RMSE: 1.1340, Val MAE: 0.9462\n",
      "Epoch: 107, Loss: 0.0070, Train RMSE: 0.0122, Train MAE: 0.0088, Val RMSE: 1.1330, Val MAE: 0.9452\n",
      "Epoch: 108, Loss: 0.0070, Train RMSE: 0.0124, Train MAE: 0.0086, Val RMSE: 1.1325, Val MAE: 0.9446\n",
      "Epoch: 109, Loss: 0.0070, Train RMSE: 0.0118, Train MAE: 0.0084, Val RMSE: 1.1327, Val MAE: 0.9448\n",
      "Epoch: 110, Loss: 0.0070, Train RMSE: 0.0114, Train MAE: 0.0085, Val RMSE: 1.1334, Val MAE: 0.9455\n",
      "Epoch: 111, Loss: 0.0070, Train RMSE: 0.0120, Train MAE: 0.0094, Val RMSE: 1.1342, Val MAE: 0.9464\n",
      "Epoch: 112, Loss: 0.0070, Train RMSE: 0.0128, Train MAE: 0.0101, Val RMSE: 1.1346, Val MAE: 0.9468\n",
      "Epoch: 113, Loss: 0.0070, Train RMSE: 0.0126, Train MAE: 0.0095, Val RMSE: 1.1343, Val MAE: 0.9465\n",
      "Epoch: 114, Loss: 0.0070, Train RMSE: 0.0114, Train MAE: 0.0080, Val RMSE: 1.1337, Val MAE: 0.9459\n",
      "Epoch: 115, Loss: 0.0070, Train RMSE: 0.0103, Train MAE: 0.0069, Val RMSE: 1.1331, Val MAE: 0.9452\n",
      "Epoch: 116, Loss: 0.0070, Train RMSE: 0.0100, Train MAE: 0.0066, Val RMSE: 1.1329, Val MAE: 0.9450\n",
      "Epoch: 117, Loss: 0.0070, Train RMSE: 0.0105, Train MAE: 0.0070, Val RMSE: 1.1332, Val MAE: 0.9453\n",
      "Epoch: 118, Loss: 0.0070, Train RMSE: 0.0113, Train MAE: 0.0080, Val RMSE: 1.1338, Val MAE: 0.9459\n",
      "Epoch: 119, Loss: 0.0070, Train RMSE: 0.0117, Train MAE: 0.0088, Val RMSE: 1.1342, Val MAE: 0.9464\n",
      "Epoch: 120, Loss: 0.0070, Train RMSE: 0.0115, Train MAE: 0.0090, Val RMSE: 1.1343, Val MAE: 0.9465\n",
      "Epoch: 121, Loss: 0.0070, Train RMSE: 0.0110, Train MAE: 0.0083, Val RMSE: 1.1340, Val MAE: 0.9461\n",
      "Epoch: 122, Loss: 0.0070, Train RMSE: 0.0108, Train MAE: 0.0077, Val RMSE: 1.1335, Val MAE: 0.9456\n",
      "Epoch: 123, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0075, Val RMSE: 1.1332, Val MAE: 0.9453\n",
      "Epoch: 124, Loss: 0.0070, Train RMSE: 0.0110, Train MAE: 0.0076, Val RMSE: 1.1332, Val MAE: 0.9454\n",
      "Epoch: 125, Loss: 0.0070, Train RMSE: 0.0111, Train MAE: 0.0081, Val RMSE: 1.1335, Val MAE: 0.9457\n",
      "Epoch: 126, Loss: 0.0070, Train RMSE: 0.0115, Train MAE: 0.0088, Val RMSE: 1.1339, Val MAE: 0.9461\n",
      "Epoch: 127, Loss: 0.0070, Train RMSE: 0.0120, Train MAE: 0.0093, Val RMSE: 1.1341, Val MAE: 0.9462\n",
      "Epoch: 128, Loss: 0.0070, Train RMSE: 0.0119, Train MAE: 0.0090, Val RMSE: 1.1339, Val MAE: 0.9461\n",
      "Epoch: 129, Loss: 0.0070, Train RMSE: 0.0115, Train MAE: 0.0083, Val RMSE: 1.1336, Val MAE: 0.9458\n",
      "Epoch: 130, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0076, Val RMSE: 1.1333, Val MAE: 0.9455\n",
      "Epoch: 131, Loss: 0.0070, Train RMSE: 0.0108, Train MAE: 0.0075, Val RMSE: 1.1333, Val MAE: 0.9454\n",
      "Epoch: 132, Loss: 0.0070, Train RMSE: 0.0111, Train MAE: 0.0078, Val RMSE: 1.1335, Val MAE: 0.9456\n",
      "Epoch: 133, Loss: 0.0070, Train RMSE: 0.0115, Train MAE: 0.0083, Val RMSE: 1.1338, Val MAE: 0.9459\n",
      "Epoch: 134, Loss: 0.0070, Train RMSE: 0.0116, Train MAE: 0.0086, Val RMSE: 1.1339, Val MAE: 0.9461\n",
      "Epoch: 135, Loss: 0.0070, Train RMSE: 0.0113, Train MAE: 0.0085, Val RMSE: 1.1339, Val MAE: 0.9461\n",
      "Epoch: 136, Loss: 0.0070, Train RMSE: 0.0110, Train MAE: 0.0081, Val RMSE: 1.1337, Val MAE: 0.9459\n",
      "Epoch: 137, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0077, Val RMSE: 1.1335, Val MAE: 0.9457\n",
      "Epoch: 138, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0076, Val RMSE: 1.1334, Val MAE: 0.9456\n",
      "Epoch: 139, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0078, Val RMSE: 1.1335, Val MAE: 0.9457\n",
      "Epoch: 140, Loss: 0.0070, Train RMSE: 0.0110, Train MAE: 0.0081, Val RMSE: 1.1337, Val MAE: 0.9458\n",
      "Epoch: 141, Loss: 0.0070, Train RMSE: 0.0112, Train MAE: 0.0084, Val RMSE: 1.1338, Val MAE: 0.9460\n",
      "Epoch: 142, Loss: 0.0070, Train RMSE: 0.0113, Train MAE: 0.0085, Val RMSE: 1.1338, Val MAE: 0.9460\n",
      "Epoch: 143, Loss: 0.0070, Train RMSE: 0.0112, Train MAE: 0.0083, Val RMSE: 1.1337, Val MAE: 0.9459\n",
      "Epoch: 144, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0079, Val RMSE: 1.1335, Val MAE: 0.9457\n",
      "Epoch: 145, Loss: 0.0070, Train RMSE: 0.0108, Train MAE: 0.0077, Val RMSE: 1.1335, Val MAE: 0.9456\n",
      "Epoch: 146, Loss: 0.0070, Train RMSE: 0.0108, Train MAE: 0.0077, Val RMSE: 1.1335, Val MAE: 0.9457\n",
      "Epoch: 147, Loss: 0.0070, Train RMSE: 0.0111, Train MAE: 0.0080, Val RMSE: 1.1337, Val MAE: 0.9458\n",
      "Epoch: 148, Loss: 0.0070, Train RMSE: 0.0112, Train MAE: 0.0082, Val RMSE: 1.1338, Val MAE: 0.9459\n",
      "Epoch: 149, Loss: 0.0070, Train RMSE: 0.0111, Train MAE: 0.0082, Val RMSE: 1.1338, Val MAE: 0.9460\n",
      "Epoch: 150, Loss: 0.0070, Train RMSE: 0.0110, Train MAE: 0.0080, Val RMSE: 1.1337, Val MAE: 0.9459\n",
      "Epoch: 151, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0078, Val RMSE: 1.1336, Val MAE: 0.9458\n",
      "Epoch: 152, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0077, Val RMSE: 1.1335, Val MAE: 0.9457\n",
      "Epoch: 153, Loss: 0.0070, Train RMSE: 0.0109, Train MAE: 0.0078, Val RMSE: 1.1336, Val MAE: 0.9457\n",
      "Epoch: 154, Loss: 0.0070, Train RMSE: 0.0110, Train MAE: 0.0080, Val RMSE: 1.1336, Val MAE: 0.9458\n",
      "Epoch: 155, Loss: 0.0070, Train RMSE: 0.0111, Train MAE: 0.0082, Val RMSE: 1.1337, Val MAE: 0.9459\n",
      "Epoch: 156, Loss: 0.0070, Train RMSE: 0.0112, Train MAE: 0.0083, Val RMSE: 1.1337, Val MAE: 0.9459\n",
      "Epoch: 157, Loss: 0.0070, Train RMSE: 0.0112, Train MAE: 0.0082, Val RMSE: 1.1336, Val MAE: 0.9458\n",
      "Epoch: 158, Loss: 0.0070, Train RMSE: 0.0111, Train MAE: 0.0080, Val RMSE: 1.1336, Val MAE: 0.9457\n",
      "Epoch: 159, Loss: 0.0070, Train RMSE: 0.0110, Train MAE: 0.0079, Val RMSE: 1.1335, Val MAE: 0.9457\n",
      "Epoch: 160, Loss: 0.0070, Train RMSE: 0.0110, Train MAE: 0.0079, Val RMSE: 1.1335, Val MAE: 0.9457\n",
      "Early stopping triggered at epoch 160. Best validation RMSE: 1.1333 at epoch 131.\n",
      "Best model restored from epoch 131.\n",
      "TensorBoard training saved at: D:\\Internship\\trained_models\\runs\\training_plot_distillation_trained_model_250_epochs_0.01_lr\n",
      "\n",
      "Trained model distillation_trained_model saved at path: D:\\Internship\\trained_models\n"
     ]
    }
   ],
   "source": [
    "# Incremental train the model\n",
    "GraphSAGE_model.distillation_train(\n",
    "    num_epochs=250,\n",
    "    lr=0.01,\n",
    "    temperature=1.0,\n",
    "    alpha=0.5,\n",
    "    model_name=\"distillation_trained_model\",\n",
    "    trained_model_path=trained_models_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda\n",
      "'\n",
      "Test RMSE: 1.1394, Test MAE: 0.9418\n",
      "\n",
      "      userId  movieId  pred_rating  gt_rating\n",
      "0        514     9645     2.967564        2.5\n",
      "1         26      286     3.241055        5.0\n",
      "2        599    44114     2.779964        5.0\n",
      "3        101     7008     3.402693        4.0\n",
      "4        101    11443     3.565405        3.0\n",
      "...      ...      ...          ...        ...\n",
      "4495     246     2244     2.929942        2.0\n",
      "4496     104    10299     3.018107        3.0\n",
      "4497     469     5044     2.708227        3.0\n",
      "4498     129    36979     3.044476        4.0\n",
      "4499     563    10009     3.815342        1.0\n",
      "\n",
      "[4500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate general performance after distillation training\n",
    "GraphSAGE_model.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"display: flex; justify-content: space-around;\">\n",
       "        <div>\n",
       "            <h4>Training Data</h4>\n",
       "            <p>RMSE: 0.5833</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>3.622602</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8844</td>\n",
       "      <td>4.608750</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.833967</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.217451</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>1.801937</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>3.590517</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1366</td>\n",
       "      <td>3.388369</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>3.983413</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.412644</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>3.960038</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.217092</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10625</td>\n",
       "      <td>3.623572</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>673</td>\n",
       "      <td>4.024170</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11036</td>\n",
       "      <td>3.619454</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>4.221750</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37799</td>\n",
       "      <td>4.611694</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49051</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313369</td>\n",
       "      <td>1.627221</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div>\n",
       "            <h4>Test Data</h4>\n",
       "            <p>RMSE: 1.2907</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8358</td>\n",
       "      <td>3.025360</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>3.841735</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11034</td>\n",
       "      <td>2.850649</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>3.407903</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>3.429032</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1726</td>\n",
       "      <td>3.881182</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>4.490969</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19995</td>\n",
       "      <td>2.987530</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12444</td>\n",
       "      <td>3.381851</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12445</td>\n",
       "      <td>3.374610</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57158</td>\n",
       "      <td>3.423215</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164251</td>\n",
       "      <td>2.857935</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122917</td>\n",
       "      <td>3.556266</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate performance specifically over the new training data\n",
    "evaluate_model_performance(GraphSAGE_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model\n",
    "GraphSAGE_model = GNNRetrainModelHandler.load_pretrained_model(\n",
    "    pretrained_model_filepath=GraphSAGE_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 new movies to add to 'movies_df': Movies ids [414906, 693134]\n",
      "Found 20 new ratings to add to 'users_ratings_df'\n",
      "Found 1 new users to add to 'users_ratings_df': Users ids [1000]\n"
     ]
    }
   ],
   "source": [
    "# Set the new train set for the re-training of the model\n",
    "GraphSAGE_model.add_new_train_data(new_movies_df=new_movies_df, new_ratings_df=new_users_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n",
      "Adaptive patience set to 20 epochs based on num_epochs=15.\n",
      "Epoch: 001, Loss: 2.0803, Train RMSE: 1.4003, Train MAE: 1.0229, Val RMSE: 0.9028, Val MAE: 0.6842\n",
      "Epoch: 002, Loss: 1.9809, Train RMSE: 1.3675, Train MAE: 0.9572, Val RMSE: 0.9128, Val MAE: 0.6902\n",
      "Epoch: 003, Loss: 1.9271, Train RMSE: 1.3483, Train MAE: 0.9099, Val RMSE: 0.9208, Val MAE: 0.6958\n",
      "Epoch: 004, Loss: 1.9004, Train RMSE: 1.3368, Train MAE: 0.8895, Val RMSE: 0.9220, Val MAE: 0.6968\n",
      "Epoch: 005, Loss: 1.8791, Train RMSE: 1.3283, Train MAE: 0.8819, Val RMSE: 0.9171, Val MAE: 0.6935\n",
      "Epoch: 006, Loss: 1.8514, Train RMSE: 1.3211, Train MAE: 0.8840, Val RMSE: 0.9089, Val MAE: 0.6883\n",
      "Epoch: 007, Loss: 1.8168, Train RMSE: 1.3151, Train MAE: 0.8950, Val RMSE: 0.9008, Val MAE: 0.6840\n",
      "Epoch: 008, Loss: 1.7794, Train RMSE: 1.3110, Train MAE: 0.9098, Val RMSE: 0.8954, Val MAE: 0.6827\n",
      "Epoch: 009, Loss: 1.7445, Train RMSE: 1.3086, Train MAE: 0.9259, Val RMSE: 0.8938, Val MAE: 0.6855\n",
      "Epoch: 010, Loss: 1.7148, Train RMSE: 1.3000, Train MAE: 0.9413, Val RMSE: 0.8964, Val MAE: 0.6917\n",
      "Epoch: 011, Loss: 1.6901, Train RMSE: 1.2919, Train MAE: 0.9558, Val RMSE: 0.9021, Val MAE: 0.7003\n",
      "Epoch: 012, Loss: 1.6690, Train RMSE: 1.2841, Train MAE: 0.9645, Val RMSE: 0.9092, Val MAE: 0.7099\n",
      "Epoch: 013, Loss: 1.6490, Train RMSE: 1.2761, Train MAE: 0.9667, Val RMSE: 0.9163, Val MAE: 0.7188\n",
      "Epoch: 014, Loss: 1.6285, Train RMSE: 1.2676, Train MAE: 0.9627, Val RMSE: 0.9225, Val MAE: 0.7264\n",
      "Epoch: 015, Loss: 1.6067, Train RMSE: 1.2587, Train MAE: 0.9536, Val RMSE: 0.9274, Val MAE: 0.7323\n",
      "Best model with lowest validation RMSE restored from epoch 9.\n",
      "\n",
      "TensorBoard training information of model fine_tuned_model saved at path: D:\\Internship\\trained_models\\runs\\training_plot_fine_tuned_model_15_epochs_0.001_lr\n",
      "\n",
      "Trained model fine_tuned_model saved at path: D:\\Internship\\trained_models\n"
     ]
    }
   ],
   "source": [
    "# Incremental train the model\n",
    "GraphSAGE_model.fine_tune(\n",
    "    num_epochs=15,\n",
    "    lr=0.001,\n",
    "    model_name=\"fine_tuned_model\",\n",
    "    trained_model_path=trained_models_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda\n",
      "'\n",
      "Test RMSE: 0.9391, Test MAE: 0.7428\n",
      "\n",
      "      userId  movieId  pred_rating  gt_rating\n",
      "0        514     9645     3.756391        2.5\n",
      "1         26      286     4.042635        5.0\n",
      "2        599    44114     3.379977        5.0\n",
      "3        101     7008     3.770851        4.0\n",
      "4        101    11443     3.880891        3.0\n",
      "...      ...      ...          ...        ...\n",
      "4495     246     2244     3.132987        2.0\n",
      "4496     104    10299     2.900756        3.0\n",
      "4497     469     5044     2.986651        3.0\n",
      "4498     129    36979     3.180464        4.0\n",
      "4499     563    10009     2.379834        1.0\n",
      "\n",
      "[4500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate general performance after fine-tuning\n",
    "GraphSAGE_model.evaluate_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"display: flex; justify-content: space-around;\">\n",
       "        <div>\n",
       "            <h4>Training Data</h4>\n",
       "            <p>RMSE: 1.3054</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>862</td>\n",
       "      <td>3.758345</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8844</td>\n",
       "      <td>1.998010</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.534894</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>4.329314</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>744</td>\n",
       "      <td>4.795349</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>4.367586</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>4.553530</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1366</td>\n",
       "      <td>4.574782</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>671</td>\n",
       "      <td>4.702748</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.379584</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>4.596958</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>4.227476</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>4.475671</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10625</td>\n",
       "      <td>3.911232</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>673</td>\n",
       "      <td>4.352291</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11036</td>\n",
       "      <td>3.071651</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>4.454551</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37799</td>\n",
       "      <td>3.265432</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49051</td>\n",
       "      <td>4.430545</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313369</td>\n",
       "      <td>4.107770</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "        <div>\n",
       "            <h4>Test Data</h4>\n",
       "            <p>RMSE: 1.3958</p>\n",
       "            <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ground_truth_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8358</td>\n",
       "      <td>4.129676</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>4.363535</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11034</td>\n",
       "      <td>3.977050</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>4.548450</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>3.992866</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1726</td>\n",
       "      <td>3.709986</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>4.558208</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19995</td>\n",
       "      <td>3.876826</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12444</td>\n",
       "      <td>4.026474</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12445</td>\n",
       "      <td>4.000809</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57158</td>\n",
       "      <td>3.913925</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164251</td>\n",
       "      <td>3.880643</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122917</td>\n",
       "      <td>3.921191</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate performance specifically over the new training data\n",
    "evaluate_model_performance(GraphSAGE_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
