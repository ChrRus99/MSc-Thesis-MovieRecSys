{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the path to the directory containing the project\n",
    "sys.path.append('D:\\\\Internship\\\\recsys\\\\data_pipelines')\n",
    "sys.path.append('D:\\\\Internship\\\\recsys\\\\data_pipelines\\\\dags')\n",
    "sys.path.append('D:\\\\Internship\\\\recsys\\\\movie_recommendation_system\\\\src')\n",
    "sys.path.append('D:\\\\Internship\\\\recsys\\\\db_handlers')\n",
    "sys.path.append('D:\\\\Internship\\\\recsys\\\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_pipeline import (\n",
    "    load_and_preprocess_datasets,\n",
    "    reset_existing_databases,\n",
    "    init_databases,\n",
    "    store_data_in_databases,\n",
    "    debug_cuda,\n",
    "    build_graph_dataset,\n",
    "    train_gnn_model,\n",
    "    deploy_model,\n",
    "    build_neo4j_knowledge_graph,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Loading and preprocessing MovieLens datasets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">D:\\Internship\\recsys\\movie_recommendation_system\\src\\movie_recommender\\data\\tabular_dataset_handler.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">265</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DtypeWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: Columns </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">10</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\"> have mixed types. Specify dtype option on import or set </span><span style=\"color: #808000; text-decoration-color: #808000\">low_memory</span><span style=\"color: #808000; text-decoration-color: #808000\">=</span><span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">False</span><span style=\"color: #808000; text-decoration-color: #808000\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mD:\\Internship\\recsys\\movie_recommendation_system\\src\\movie_recommender\\data\\tabular_dataset_handler.py:\u001b[0m\u001b[1;33m265\u001b[0m\u001b[1;33m DtypeWarning\u001b[0m\u001b[33m: Columns \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m have mixed types. Specify dtype option on import or set \u001b[0m\u001b[33mlow_memory\u001b[0m\u001b[33m=\u001b[0m\u001b[3;33mFalse\u001b[0m\u001b[33m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class instance saved to 'D:\\Internship\\recsys\\data\\movielens_processed\\tdh_instance.pkl'\n"
     ]
    }
   ],
   "source": [
    "load_and_preprocess_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Resetting SQL and NoSQL databases\n",
      "[LOG] Tables 'cast_and_crew' and 'movies_metadata' dropped successfully.\n",
      "[LOG] Tables 'user_register' and 'user_model_lookup' dropped successfully.\n",
      "[LOG] Collections 'user_movie_ratings' and 'user_preferences' dropped successfully.\n",
      "[LOG] Bucket 'initial-model' and its contents deleted.\n",
      "[LOG] Bucket 'offline-updated-models' and its contents deleted.\n",
      "[LOG] Bucket 'online-updated-user-models' and its contents deleted.\n",
      "[LOG] Table 'user_movie_ratings' dropped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">D:\\Internship\\recsys\\db_handlers\\db_handlers\\kg_rag_neo4j_db_handler.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">51</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> LangChainDeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: The class `Neo4jGraph` was deprecated in LangChain </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">0.3</span><span style=\"color: #808000; text-decoration-color: #808000\">.</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">8</span><span style=\"color: #808000; text-decoration-color: #808000\"> and will be removed in </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1.0</span><span style=\"color: #808000; text-decoration-color: #808000\">. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mD:\\Internship\\recsys\\db_handlers\\db_handlers\\kg_rag_neo4j_db_handler.py:\u001b[0m\u001b[1;33m51\u001b[0m\u001b[1;33m LangChainDeprecationWarning\u001b[0m\u001b[33m: The class `Neo4jGraph` was deprecated in LangChain \u001b[0m\u001b[1;33m0.3\u001b[0m\u001b[33m.\u001b[0m\u001b[1;33m8\u001b[0m\u001b[33m and will be removed in \u001b[0m\u001b[1;33m1.0\u001b[0m\u001b[33m. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Knowledge graph reset successfully.\n",
      "[LOG] Initializing SQL and NoSQL databases\n",
      "[LOG] Table 'movies_metadata' created successfully.\n",
      "[LOG] Table 'cast_and_crew' created successfully.\n",
      "[LOG] Table 'user_register' created successfully.\n",
      "[LOG] Table 'user_model_lookup' created successfully.\n",
      "[LOG] Collection 'user_movie_ratings' created successfully.\n",
      "[LOG] Collection 'user_preferences' created successfully.\n",
      "[LOG] Bucket 'initial-model' created.\n",
      "[LOG] Bucket 'offline-updated-models' created.\n",
      "[LOG] Bucket 'online-updated-user-models' created.\n",
      "[LOG] Table 'user_movie_ratings' created successfully.\n",
      "[LOG] Storing processed data in SQL and NoSQL databases\n",
      "[LOG] Stored 45433 movies successfully, with 0 errors.\n",
      "[LOG] Stored 45476 cast and crew records successfully, with 0 errors.\n"
     ]
    }
   ],
   "source": [
    "# Branch 1\n",
    "reset_existing_databases()\n",
    "init_databases()\n",
    "store_data_in_databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Debugging CUDA environment variables and PyTorch CUDA availability\n",
      "[INFO] Running CUDA script [debug_cuda_script.py] as a subprocess\n",
      "[ERROR] Failed to execute script as subprocess: D:\\Internship\\recsys\\data_pipelines\\scripts\\init\\debug_cuda_script.py\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Internship\\recsys\\data_pipelines\\scripts\\init\\debug_cuda_script.py\", line 111, in <module>\n",
      "    main()\n",
      "  File \"D:\\Internship\\recsys\\data_pipelines\\scripts\\init\\debug_cuda_script.py\", line 77, in main\n",
      "    ldd_output = subprocess.check_output([\"ldd\", cuda_lib_path], stderr=subprocess.STDOUT).decode()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Public\\anaconda3\\envs\\tf-gpu\\Lib\\subprocess.py\", line 466, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Public\\anaconda3\\envs\\tf-gpu\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Public\\anaconda3\\envs\\tf-gpu\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\Public\\anaconda3\\envs\\tf-gpu\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] Impossibile trovare il file specificato\n",
      "\n",
      "[LOG] Building graph dataset for GNN training\n",
      "[INFO] Running CUDA script [build_init_graph_dataset_script.py] as a subprocess\n",
      "[SUCCESS] Script executed successfully as subprocess: D:\\Internship\\recsys\\data_pipelines\\scripts\\init\\build_init_graph_dataset_script.py\n",
      "[INFO] Running locally\n",
      "Class instance saved to D:\\Internship\\recsys\\data\\movielens_processed\\gdh_instance.pkl\n",
      "\n",
      "[LOG] Pre-train the initial GNN model on the MovieLens graph dataset\n",
      "[INFO] Running CUDA script [train_init_gnn_script.py] as a subprocess\n",
      "[SUCCESS] Script executed successfully as subprocess: D:\\Internship\\recsys\\data_pipelines\\scripts\\init\\train_init_gnn_script.py\n",
      "[INFO] Running locally\n",
      "Device: 'cuda'\n",
      "Adaptive patience set to 35 epochs based on num_epochs=500.\n",
      "Epoch: 001, Train loss: 13.1563, Train RMSE: 3.3063, Train MAE: 3.1343, Val RMSE: 3.3120, Val MAE: 3.1377\n",
      "Epoch: 002, Train loss: 10.9317, Train RMSE: 2.2039, Train MAE: 1.9986, Val RMSE: 2.2155, Val MAE: 2.0136\n",
      "Epoch: 003, Train loss: 4.8571, Train RMSE: 1.5622, Train MAE: 1.2358, Val RMSE: 1.5476, Val MAE: 1.2142\n",
      "Epoch: 004, Train loss: 2.5406, Train RMSE: 1.4535, Train MAE: 1.1394, Val RMSE: 1.4395, Val MAE: 1.1197\n",
      "Epoch: 005, Train loss: 2.1388, Train RMSE: 1.1508, Train MAE: 0.9480, Val RMSE: 1.1614, Val MAE: 0.9609\n",
      "Epoch: 006, Train loss: 1.3243, Train RMSE: 1.4908, Train MAE: 1.2958, Val RMSE: 1.5037, Val MAE: 1.3117\n",
      "Epoch: 007, Train loss: 2.2224, Train RMSE: 1.3884, Train MAE: 1.1938, Val RMSE: 1.4011, Val MAE: 1.2093\n",
      "Epoch: 008, Train loss: 1.9278, Train RMSE: 1.0652, Train MAE: 0.8734, Val RMSE: 1.0745, Val MAE: 0.8831\n",
      "Epoch: 009, Train loss: 1.1346, Train RMSE: 1.1883, Train MAE: 0.9061, Val RMSE: 1.1854, Val MAE: 0.8976\n",
      "Epoch: 010, Train loss: 1.4134, Train RMSE: 1.3219, Train MAE: 1.0266, Val RMSE: 1.3174, Val MAE: 1.0155\n",
      "Epoch: 011, Train loss: 1.7573, Train RMSE: 1.0563, Train MAE: 0.8074, Val RMSE: 1.0596, Val MAE: 0.8055\n",
      "Epoch: 012, Train loss: 1.1163, Train RMSE: 1.0524, Train MAE: 0.8593, Val RMSE: 1.0630, Val MAE: 0.8708\n",
      "Epoch: 013, Train loss: 1.1076, Train RMSE: 1.1910, Train MAE: 0.9958, Val RMSE: 1.2024, Val MAE: 1.0101\n",
      "Epoch: 014, Train loss: 1.4185, Train RMSE: 1.1792, Train MAE: 0.9848, Val RMSE: 1.1906, Val MAE: 0.9988\n",
      "Epoch: 015, Train loss: 1.3905, Train RMSE: 1.0433, Train MAE: 0.8501, Val RMSE: 1.0546, Val MAE: 0.8624\n",
      "Epoch: 016, Train loss: 1.0885, Train RMSE: 0.9935, Train MAE: 0.7732, Val RMSE: 1.0026, Val MAE: 0.7769\n",
      "Epoch: 017, Train loss: 0.9877, Train RMSE: 1.1027, Train MAE: 0.8355, Val RMSE: 1.1098, Val MAE: 0.8335\n",
      "Epoch: 018, Train loss: 1.2236, Train RMSE: 1.0919, Train MAE: 0.8270, Val RMSE: 1.0999, Val MAE: 0.8258\n",
      "Epoch: 019, Train loss: 1.2000, Train RMSE: 0.9857, Train MAE: 0.7640, Val RMSE: 0.9967, Val MAE: 0.7691\n",
      "Epoch: 020, Train loss: 0.9728, Train RMSE: 0.9966, Train MAE: 0.8029, Val RMSE: 1.0092, Val MAE: 0.8145\n",
      "Epoch: 021, Train loss: 0.9934, Train RMSE: 1.0582, Train MAE: 0.8664, Val RMSE: 1.0710, Val MAE: 0.8793\n",
      "Epoch: 022, Train loss: 1.1199, Train RMSE: 1.0499, Train MAE: 0.8583, Val RMSE: 1.0630, Val MAE: 0.8712\n",
      "Epoch: 023, Train loss: 1.1024, Train RMSE: 0.9854, Train MAE: 0.7912, Val RMSE: 0.9993, Val MAE: 0.8029\n",
      "Epoch: 024, Train loss: 0.9713, Train RMSE: 0.9667, Train MAE: 0.7515, Val RMSE: 0.9806, Val MAE: 0.7597\n",
      "Epoch: 025, Train loss: 0.9357, Train RMSE: 1.0140, Train MAE: 0.7714, Val RMSE: 1.0272, Val MAE: 0.7753\n",
      "Epoch: 026, Train loss: 1.0325, Train RMSE: 1.0110, Train MAE: 0.7692, Val RMSE: 1.0247, Val MAE: 0.7733\n",
      "Epoch: 027, Train loss: 1.0264, Train RMSE: 0.9619, Train MAE: 0.7454, Val RMSE: 0.9769, Val MAE: 0.7544\n",
      "Epoch: 028, Train loss: 0.9265, Train RMSE: 0.9626, Train MAE: 0.7661, Val RMSE: 0.9783, Val MAE: 0.7773\n",
      "Epoch: 029, Train loss: 0.9268, Train RMSE: 0.9919, Train MAE: 0.8004, Val RMSE: 1.0077, Val MAE: 0.8136\n",
      "Epoch: 030, Train loss: 0.9840, Train RMSE: 0.9869, Train MAE: 0.7954, Val RMSE: 1.0030, Val MAE: 0.8086\n",
      "Epoch: 031, Train loss: 0.9741, Train RMSE: 0.9547, Train MAE: 0.7579, Val RMSE: 0.9713, Val MAE: 0.7695\n",
      "Epoch: 032, Train loss: 0.9117, Train RMSE: 0.9494, Train MAE: 0.7363, Val RMSE: 0.9657, Val MAE: 0.7463\n",
      "Epoch: 033, Train loss: 0.9023, Train RMSE: 0.9710, Train MAE: 0.7427, Val RMSE: 0.9867, Val MAE: 0.7496\n",
      "Epoch: 034, Train loss: 0.9451, Train RMSE: 0.9641, Train MAE: 0.7385, Val RMSE: 0.9801, Val MAE: 0.7462\n",
      "Epoch: 035, Train loss: 0.9315, Train RMSE: 0.9413, Train MAE: 0.7321, Val RMSE: 0.9584, Val MAE: 0.7432\n",
      "Epoch: 036, Train loss: 0.8868, Train RMSE: 0.9456, Train MAE: 0.7493, Val RMSE: 0.9634, Val MAE: 0.7617\n",
      "Epoch: 037, Train loss: 0.8943, Train RMSE: 0.9576, Train MAE: 0.7655, Val RMSE: 0.9758, Val MAE: 0.7788\n",
      "Epoch: 038, Train loss: 0.9172, Train RMSE: 0.9487, Train MAE: 0.7550, Val RMSE: 0.9670, Val MAE: 0.7679\n",
      "Epoch: 039, Train loss: 0.9002, Train RMSE: 0.9338, Train MAE: 0.7318, Val RMSE: 0.9518, Val MAE: 0.7445\n",
      "Epoch: 040, Train loss: 0.8724, Train RMSE: 0.9389, Train MAE: 0.7239, Val RMSE: 0.9562, Val MAE: 0.7344\n",
      "Epoch: 041, Train loss: 0.8827, Train RMSE: 0.9440, Train MAE: 0.7242, Val RMSE: 0.9611, Val MAE: 0.7343\n",
      "Epoch: 042, Train loss: 0.8926, Train RMSE: 0.9328, Train MAE: 0.7206, Val RMSE: 0.9508, Val MAE: 0.7322\n",
      "Epoch: 043, Train loss: 0.8712, Train RMSE: 0.9278, Train MAE: 0.7266, Val RMSE: 0.9469, Val MAE: 0.7403\n",
      "Epoch: 044, Train loss: 0.8613, Train RMSE: 0.9338, Train MAE: 0.7386, Val RMSE: 0.9535, Val MAE: 0.7527\n",
      "Epoch: 045, Train loss: 0.8723, Train RMSE: 0.9327, Train MAE: 0.7377, Val RMSE: 0.9527, Val MAE: 0.7520\n",
      "Epoch: 046, Train loss: 0.8703, Train RMSE: 0.9242, Train MAE: 0.7241, Val RMSE: 0.9441, Val MAE: 0.7386\n",
      "Epoch: 047, Train loss: 0.8546, Train RMSE: 0.9231, Train MAE: 0.7146, Val RMSE: 0.9428, Val MAE: 0.7281\n",
      "Epoch: 048, Train loss: 0.8531, Train RMSE: 0.9266, Train MAE: 0.7128, Val RMSE: 0.9461, Val MAE: 0.7258\n",
      "Epoch: 049, Train loss: 0.8600, Train RMSE: 0.9221, Train MAE: 0.7115, Val RMSE: 0.9421, Val MAE: 0.7251\n",
      "Epoch: 050, Train loss: 0.8515, Train RMSE: 0.9175, Train MAE: 0.7145, Val RMSE: 0.9383, Val MAE: 0.7293\n",
      "Epoch: 051, Train loss: 0.8425, Train RMSE: 0.9196, Train MAE: 0.7221, Val RMSE: 0.9410, Val MAE: 0.7375\n",
      "Epoch: 052, Train loss: 0.8462, Train RMSE: 0.9194, Train MAE: 0.7226, Val RMSE: 0.9411, Val MAE: 0.7383\n",
      "Epoch: 053, Train loss: 0.8458, Train RMSE: 0.9143, Train MAE: 0.7140, Val RMSE: 0.9361, Val MAE: 0.7294\n",
      "Epoch: 054, Train loss: 0.8368, Train RMSE: 0.9129, Train MAE: 0.7066, Val RMSE: 0.9344, Val MAE: 0.7215\n",
      "Epoch: 055, Train loss: 0.8345, Train RMSE: 0.9141, Train MAE: 0.7042, Val RMSE: 0.9356, Val MAE: 0.7186\n",
      "Epoch: 056, Train loss: 0.8371, Train RMSE: 0.9111, Train MAE: 0.7036, Val RMSE: 0.9332, Val MAE: 0.7184\n",
      "Epoch: 057, Train loss: 0.8316, Train RMSE: 0.9085, Train MAE: 0.7064, Val RMSE: 0.9313, Val MAE: 0.7222\n",
      "Epoch: 058, Train loss: 0.8264, Train RMSE: 0.9093, Train MAE: 0.7111, Val RMSE: 0.9327, Val MAE: 0.7274\n",
      "Epoch: 059, Train loss: 0.8277, Train RMSE: 0.9082, Train MAE: 0.7102, Val RMSE: 0.9319, Val MAE: 0.7267\n",
      "Epoch: 060, Train loss: 0.8256, Train RMSE: 0.9050, Train MAE: 0.7038, Val RMSE: 0.9288, Val MAE: 0.7200\n",
      "Epoch: 061, Train loss: 0.8201, Train RMSE: 0.9044, Train MAE: 0.6990, Val RMSE: 0.9282, Val MAE: 0.7146\n",
      "Epoch: 062, Train loss: 0.8194, Train RMSE: 0.9042, Train MAE: 0.6973, Val RMSE: 0.9281, Val MAE: 0.7128\n",
      "Epoch: 063, Train loss: 0.8190, Train RMSE: 0.9018, Train MAE: 0.6977, Val RMSE: 0.9263, Val MAE: 0.7137\n",
      "Epoch: 064, Train loss: 0.8145, Train RMSE: 0.9008, Train MAE: 0.7007, Val RMSE: 0.9260, Val MAE: 0.7176\n",
      "Epoch: 065, Train loss: 0.8124, Train RMSE: 0.9008, Train MAE: 0.7027, Val RMSE: 0.9264, Val MAE: 0.7201\n",
      "Epoch: 066, Train loss: 0.8123, Train RMSE: 0.8989, Train MAE: 0.6997, Val RMSE: 0.9249, Val MAE: 0.7171\n",
      "Epoch: 067, Train loss: 0.8091, Train RMSE: 0.8973, Train MAE: 0.6949, Val RMSE: 0.9235, Val MAE: 0.7120\n",
      "Epoch: 068, Train loss: 0.8064, Train RMSE: 0.8970, Train MAE: 0.6922, Val RMSE: 0.9233, Val MAE: 0.7090\n",
      "Epoch: 069, Train loss: 0.8059, Train RMSE: 0.8956, Train MAE: 0.6918, Val RMSE: 0.9224, Val MAE: 0.7089\n",
      "Epoch: 070, Train loss: 0.8034, Train RMSE: 0.8942, Train MAE: 0.6934, Val RMSE: 0.9215, Val MAE: 0.7113\n",
      "Epoch: 071, Train loss: 0.8007, Train RMSE: 0.8938, Train MAE: 0.6953, Val RMSE: 0.9217, Val MAE: 0.7138\n",
      "Epoch: 072, Train loss: 0.7998, Train RMSE: 0.8927, Train MAE: 0.6941, Val RMSE: 0.9209, Val MAE: 0.7126\n",
      "Epoch: 073, Train loss: 0.7978, Train RMSE: 0.8912, Train MAE: 0.6904, Val RMSE: 0.9197, Val MAE: 0.7089\n",
      "Epoch: 074, Train loss: 0.7954, Train RMSE: 0.8906, Train MAE: 0.6878, Val RMSE: 0.9193, Val MAE: 0.7062\n",
      "Epoch: 075, Train loss: 0.7944, Train RMSE: 0.8895, Train MAE: 0.6871, Val RMSE: 0.9186, Val MAE: 0.7058\n",
      "Epoch: 076, Train loss: 0.7925, Train RMSE: 0.8884, Train MAE: 0.6882, Val RMSE: 0.9179, Val MAE: 0.7072\n",
      "Epoch: 077, Train loss: 0.7903, Train RMSE: 0.8878, Train MAE: 0.6894, Val RMSE: 0.9177, Val MAE: 0.7088\n",
      "Epoch: 078, Train loss: 0.7892, Train RMSE: 0.8869, Train MAE: 0.6883, Val RMSE: 0.9170, Val MAE: 0.7079\n",
      "Epoch: 079, Train loss: 0.7875, Train RMSE: 0.8857, Train MAE: 0.6855, Val RMSE: 0.9161, Val MAE: 0.7052\n",
      "Epoch: 080, Train loss: 0.7855, Train RMSE: 0.8850, Train MAE: 0.6833, Val RMSE: 0.9157, Val MAE: 0.7032\n",
      "Epoch: 081, Train loss: 0.7843, Train RMSE: 0.8840, Train MAE: 0.6828, Val RMSE: 0.9151, Val MAE: 0.7029\n",
      "Epoch: 082, Train loss: 0.7826, Train RMSE: 0.8831, Train MAE: 0.6837, Val RMSE: 0.9146, Val MAE: 0.7042\n",
      "Epoch: 083, Train loss: 0.7808, Train RMSE: 0.8824, Train MAE: 0.6843, Val RMSE: 0.9144, Val MAE: 0.7052\n",
      "Epoch: 084, Train loss: 0.7796, Train RMSE: 0.8815, Train MAE: 0.6829, Val RMSE: 0.9138, Val MAE: 0.7041\n",
      "Epoch: 085, Train loss: 0.7779, Train RMSE: 0.8806, Train MAE: 0.6806, Val RMSE: 0.9132, Val MAE: 0.7019\n",
      "Epoch: 086, Train loss: 0.7764, Train RMSE: 0.8799, Train MAE: 0.6793, Val RMSE: 0.9128, Val MAE: 0.7007\n",
      "Epoch: 087, Train loss: 0.7752, Train RMSE: 0.8790, Train MAE: 0.6794, Val RMSE: 0.9122, Val MAE: 0.7010\n",
      "Epoch: 088, Train loss: 0.7735, Train RMSE: 0.8783, Train MAE: 0.6799, Val RMSE: 0.9118, Val MAE: 0.7019\n",
      "Epoch: 089, Train loss: 0.7722, Train RMSE: 0.8784, Train MAE: 0.6824, Val RMSE: 0.9121, Val MAE: 0.7046\n",
      "Epoch: 090, Train loss: 0.7722, Train RMSE: 0.8771, Train MAE: 0.6757, Val RMSE: 0.9111, Val MAE: 0.6977\n",
      "Epoch: 091, Train loss: 0.7703, Train RMSE: 0.8764, Train MAE: 0.6749, Val RMSE: 0.9107, Val MAE: 0.6971\n",
      "Epoch: 092, Train loss: 0.7691, Train RMSE: 0.8752, Train MAE: 0.6768, Val RMSE: 0.9100, Val MAE: 0.6995\n",
      "Epoch: 093, Train loss: 0.7669, Train RMSE: 0.8750, Train MAE: 0.6788, Val RMSE: 0.9103, Val MAE: 0.7020\n",
      "Epoch: 094, Train loss: 0.7664, Train RMSE: 0.8740, Train MAE: 0.6769, Val RMSE: 0.9095, Val MAE: 0.7003\n",
      "Epoch: 095, Train loss: 0.7646, Train RMSE: 0.8732, Train MAE: 0.6735, Val RMSE: 0.9088, Val MAE: 0.6970\n",
      "Epoch: 096, Train loss: 0.7635, Train RMSE: 0.8727, Train MAE: 0.6723, Val RMSE: 0.9085, Val MAE: 0.6958\n",
      "Epoch: 097, Train loss: 0.7625, Train RMSE: 0.8717, Train MAE: 0.6733, Val RMSE: 0.9079, Val MAE: 0.6971\n",
      "Epoch: 098, Train loss: 0.7608, Train RMSE: 0.8714, Train MAE: 0.6747, Val RMSE: 0.9078, Val MAE: 0.6987\n",
      "Epoch: 099, Train loss: 0.7601, Train RMSE: 0.8707, Train MAE: 0.6737, Val RMSE: 0.9074, Val MAE: 0.6978\n",
      "Epoch: 100, Train loss: 0.7589, Train RMSE: 0.8699, Train MAE: 0.6712, Val RMSE: 0.9070, Val MAE: 0.6956\n",
      "Epoch: 101, Train loss: 0.7576, Train RMSE: 0.8694, Train MAE: 0.6700, Val RMSE: 0.9069, Val MAE: 0.6947\n",
      "Epoch: 102, Train loss: 0.7569, Train RMSE: 0.8687, Train MAE: 0.6708, Val RMSE: 0.9065, Val MAE: 0.6958\n",
      "Epoch: 103, Train loss: 0.7555, Train RMSE: 0.8683, Train MAE: 0.6720, Val RMSE: 0.9065, Val MAE: 0.6974\n",
      "Epoch: 104, Train loss: 0.7547, Train RMSE: 0.8676, Train MAE: 0.6710, Val RMSE: 0.9062, Val MAE: 0.6966\n",
      "Epoch: 105, Train loss: 0.7536, Train RMSE: 0.8670, Train MAE: 0.6688, Val RMSE: 0.9058, Val MAE: 0.6944\n",
      "Epoch: 106, Train loss: 0.7525, Train RMSE: 0.8665, Train MAE: 0.6679, Val RMSE: 0.9055, Val MAE: 0.6935\n",
      "Epoch: 107, Train loss: 0.7516, Train RMSE: 0.8658, Train MAE: 0.6685, Val RMSE: 0.9051, Val MAE: 0.6943\n",
      "Epoch: 108, Train loss: 0.7505, Train RMSE: 0.8654, Train MAE: 0.6691, Val RMSE: 0.9049, Val MAE: 0.6952\n",
      "Epoch: 109, Train loss: 0.7497, Train RMSE: 0.8648, Train MAE: 0.6680, Val RMSE: 0.9046, Val MAE: 0.6942\n",
      "Epoch: 110, Train loss: 0.7486, Train RMSE: 0.8642, Train MAE: 0.6664, Val RMSE: 0.9042, Val MAE: 0.6927\n",
      "Epoch: 111, Train loss: 0.7477, Train RMSE: 0.8637, Train MAE: 0.6661, Val RMSE: 0.9039, Val MAE: 0.6925\n",
      "Epoch: 112, Train loss: 0.7467, Train RMSE: 0.8632, Train MAE: 0.6665, Val RMSE: 0.9035, Val MAE: 0.6931\n",
      "Epoch: 113, Train loss: 0.7458, Train RMSE: 0.8627, Train MAE: 0.6662, Val RMSE: 0.9032, Val MAE: 0.6930\n",
      "Epoch: 114, Train loss: 0.7449, Train RMSE: 0.8621, Train MAE: 0.6649, Val RMSE: 0.9028, Val MAE: 0.6918\n",
      "Epoch: 115, Train loss: 0.7440, Train RMSE: 0.8616, Train MAE: 0.6641, Val RMSE: 0.9025, Val MAE: 0.6911\n",
      "Epoch: 116, Train loss: 0.7432, Train RMSE: 0.8611, Train MAE: 0.6643, Val RMSE: 0.9023, Val MAE: 0.6917\n",
      "Epoch: 117, Train loss: 0.7423, Train RMSE: 0.8606, Train MAE: 0.6643, Val RMSE: 0.9022, Val MAE: 0.6921\n",
      "Epoch: 118, Train loss: 0.7414, Train RMSE: 0.8601, Train MAE: 0.6634, Val RMSE: 0.9021, Val MAE: 0.6916\n",
      "Epoch: 119, Train loss: 0.7405, Train RMSE: 0.8596, Train MAE: 0.6626, Val RMSE: 0.9020, Val MAE: 0.6910\n",
      "Epoch: 120, Train loss: 0.7397, Train RMSE: 0.8591, Train MAE: 0.6624, Val RMSE: 0.9018, Val MAE: 0.6912\n",
      "Epoch: 121, Train loss: 0.7388, Train RMSE: 0.8586, Train MAE: 0.6623, Val RMSE: 0.9016, Val MAE: 0.6915\n",
      "Epoch: 122, Train loss: 0.7379, Train RMSE: 0.8581, Train MAE: 0.6617, Val RMSE: 0.9015, Val MAE: 0.6912\n",
      "Epoch: 123, Train loss: 0.7371, Train RMSE: 0.8576, Train MAE: 0.6609, Val RMSE: 0.9013, Val MAE: 0.6906\n",
      "Epoch: 124, Train loss: 0.7363, Train RMSE: 0.8572, Train MAE: 0.6607, Val RMSE: 0.9012, Val MAE: 0.6908\n",
      "Epoch: 125, Train loss: 0.7355, Train RMSE: 0.8567, Train MAE: 0.6606, Val RMSE: 0.9011, Val MAE: 0.6911\n",
      "Epoch: 126, Train loss: 0.7347, Train RMSE: 0.8563, Train MAE: 0.6601, Val RMSE: 0.9011, Val MAE: 0.6908\n",
      "Epoch: 127, Train loss: 0.7339, Train RMSE: 0.8558, Train MAE: 0.6594, Val RMSE: 0.9010, Val MAE: 0.6904\n",
      "Epoch: 128, Train loss: 0.7331, Train RMSE: 0.8554, Train MAE: 0.6592, Val RMSE: 0.9008, Val MAE: 0.6904\n",
      "Epoch: 129, Train loss: 0.7323, Train RMSE: 0.8549, Train MAE: 0.6591, Val RMSE: 0.9006, Val MAE: 0.6905\n",
      "Epoch: 130, Train loss: 0.7315, Train RMSE: 0.8545, Train MAE: 0.6585, Val RMSE: 0.9004, Val MAE: 0.6901\n",
      "Epoch: 131, Train loss: 0.7307, Train RMSE: 0.8540, Train MAE: 0.6580, Val RMSE: 0.9003, Val MAE: 0.6898\n",
      "Epoch: 132, Train loss: 0.7300, Train RMSE: 0.8536, Train MAE: 0.6577, Val RMSE: 0.9001, Val MAE: 0.6897\n",
      "Epoch: 133, Train loss: 0.7292, Train RMSE: 0.8531, Train MAE: 0.6575, Val RMSE: 0.9000, Val MAE: 0.6898\n",
      "Epoch: 134, Train loss: 0.7285, Train RMSE: 0.8527, Train MAE: 0.6571, Val RMSE: 0.8999, Val MAE: 0.6896\n",
      "Epoch: 135, Train loss: 0.7278, Train RMSE: 0.8523, Train MAE: 0.6567, Val RMSE: 0.8996, Val MAE: 0.6893\n",
      "Epoch: 136, Train loss: 0.7270, Train RMSE: 0.8519, Train MAE: 0.6562, Val RMSE: 0.8994, Val MAE: 0.6889\n",
      "Epoch: 137, Train loss: 0.7263, Train RMSE: 0.8514, Train MAE: 0.6560, Val RMSE: 0.8994, Val MAE: 0.6889\n",
      "Epoch: 138, Train loss: 0.7256, Train RMSE: 0.8510, Train MAE: 0.6558, Val RMSE: 0.8993, Val MAE: 0.6890\n",
      "Epoch: 139, Train loss: 0.7249, Train RMSE: 0.8506, Train MAE: 0.6553, Val RMSE: 0.8993, Val MAE: 0.6889\n",
      "Epoch: 140, Train loss: 0.7241, Train RMSE: 0.8501, Train MAE: 0.6549, Val RMSE: 0.8992, Val MAE: 0.6887\n",
      "Epoch: 141, Train loss: 0.7233, Train RMSE: 0.8497, Train MAE: 0.6546, Val RMSE: 0.8989, Val MAE: 0.6886\n",
      "Epoch: 142, Train loss: 0.7225, Train RMSE: 0.8492, Train MAE: 0.6543, Val RMSE: 0.8987, Val MAE: 0.6885\n",
      "Epoch: 143, Train loss: 0.7218, Train RMSE: 0.8488, Train MAE: 0.6539, Val RMSE: 0.8985, Val MAE: 0.6882\n",
      "Epoch: 144, Train loss: 0.7211, Train RMSE: 0.8484, Train MAE: 0.6535, Val RMSE: 0.8983, Val MAE: 0.6880\n",
      "Epoch: 145, Train loss: 0.7203, Train RMSE: 0.8480, Train MAE: 0.6532, Val RMSE: 0.8983, Val MAE: 0.6879\n",
      "Epoch: 146, Train loss: 0.7196, Train RMSE: 0.8476, Train MAE: 0.6529, Val RMSE: 0.8982, Val MAE: 0.6879\n",
      "Epoch: 147, Train loss: 0.7189, Train RMSE: 0.8472, Train MAE: 0.6525, Val RMSE: 0.8981, Val MAE: 0.6878\n",
      "Epoch: 148, Train loss: 0.7183, Train RMSE: 0.8468, Train MAE: 0.6522, Val RMSE: 0.8980, Val MAE: 0.6876\n",
      "Epoch: 149, Train loss: 0.7176, Train RMSE: 0.8464, Train MAE: 0.6518, Val RMSE: 0.8979, Val MAE: 0.6875\n",
      "Epoch: 150, Train loss: 0.7169, Train RMSE: 0.8460, Train MAE: 0.6515, Val RMSE: 0.8979, Val MAE: 0.6875\n",
      "Epoch: 151, Train loss: 0.7162, Train RMSE: 0.8456, Train MAE: 0.6514, Val RMSE: 0.8979, Val MAE: 0.6878\n",
      "Epoch: 152, Train loss: 0.7156, Train RMSE: 0.8452, Train MAE: 0.6509, Val RMSE: 0.8977, Val MAE: 0.6875\n",
      "Epoch: 153, Train loss: 0.7149, Train RMSE: 0.8448, Train MAE: 0.6505, Val RMSE: 0.8976, Val MAE: 0.6873\n",
      "Epoch: 154, Train loss: 0.7142, Train RMSE: 0.8444, Train MAE: 0.6505, Val RMSE: 0.8977, Val MAE: 0.6875\n",
      "Epoch: 155, Train loss: 0.7136, Train RMSE: 0.8440, Train MAE: 0.6501, Val RMSE: 0.8977, Val MAE: 0.6874\n",
      "Epoch: 156, Train loss: 0.7130, Train RMSE: 0.8437, Train MAE: 0.6500, Val RMSE: 0.8976, Val MAE: 0.6876\n",
      "Epoch: 157, Train loss: 0.7123, Train RMSE: 0.8433, Train MAE: 0.6493, Val RMSE: 0.8976, Val MAE: 0.6870\n",
      "Epoch: 158, Train loss: 0.7117, Train RMSE: 0.8429, Train MAE: 0.6491, Val RMSE: 0.8976, Val MAE: 0.6871\n",
      "Epoch: 159, Train loss: 0.7111, Train RMSE: 0.8426, Train MAE: 0.6491, Val RMSE: 0.8976, Val MAE: 0.6875\n",
      "Epoch: 160, Train loss: 0.7105, Train RMSE: 0.8422, Train MAE: 0.6486, Val RMSE: 0.8975, Val MAE: 0.6871\n",
      "Epoch: 161, Train loss: 0.7099, Train RMSE: 0.8419, Train MAE: 0.6482, Val RMSE: 0.8976, Val MAE: 0.6870\n",
      "Epoch: 162, Train loss: 0.7093, Train RMSE: 0.8415, Train MAE: 0.6482, Val RMSE: 0.8977, Val MAE: 0.6873\n",
      "Epoch: 163, Train loss: 0.7087, Train RMSE: 0.8412, Train MAE: 0.6478, Val RMSE: 0.8978, Val MAE: 0.6873\n",
      "Epoch: 164, Train loss: 0.7081, Train RMSE: 0.8408, Train MAE: 0.6476, Val RMSE: 0.8978, Val MAE: 0.6875\n",
      "Epoch: 165, Train loss: 0.7075, Train RMSE: 0.8405, Train MAE: 0.6473, Val RMSE: 0.8979, Val MAE: 0.6874\n",
      "Epoch: 166, Train loss: 0.7070, Train RMSE: 0.8401, Train MAE: 0.6469, Val RMSE: 0.8979, Val MAE: 0.6874\n",
      "Epoch: 167, Train loss: 0.7064, Train RMSE: 0.8398, Train MAE: 0.6470, Val RMSE: 0.8978, Val MAE: 0.6878\n",
      "Epoch: 168, Train loss: 0.7058, Train RMSE: 0.8395, Train MAE: 0.6462, Val RMSE: 0.8980, Val MAE: 0.6874\n",
      "Epoch: 169, Train loss: 0.7053, Train RMSE: 0.8392, Train MAE: 0.6466, Val RMSE: 0.8978, Val MAE: 0.6880\n",
      "Epoch: 170, Train loss: 0.7048, Train RMSE: 0.8388, Train MAE: 0.6458, Val RMSE: 0.8979, Val MAE: 0.6875\n",
      "Epoch: 171, Train loss: 0.7042, Train RMSE: 0.8385, Train MAE: 0.6460, Val RMSE: 0.8978, Val MAE: 0.6879\n",
      "Epoch: 172, Train loss: 0.7037, Train RMSE: 0.8382, Train MAE: 0.6457, Val RMSE: 0.8977, Val MAE: 0.6878\n",
      "Epoch: 173, Train loss: 0.7032, Train RMSE: 0.8379, Train MAE: 0.6451, Val RMSE: 0.8977, Val MAE: 0.6874\n",
      "Epoch: 174, Train loss: 0.7027, Train RMSE: 0.8376, Train MAE: 0.6455, Val RMSE: 0.8976, Val MAE: 0.6880\n",
      "Epoch: 175, Train loss: 0.7021, Train RMSE: 0.8373, Train MAE: 0.6445, Val RMSE: 0.8977, Val MAE: 0.6872\n",
      "Epoch: 176, Train loss: 0.7017, Train RMSE: 0.8370, Train MAE: 0.6449, Val RMSE: 0.8975, Val MAE: 0.6877\n",
      "Epoch: 177, Train loss: 0.7011, Train RMSE: 0.8375, Train MAE: 0.6418, Val RMSE: 0.8984, Val MAE: 0.6844\n",
      "Epoch: 178, Train loss: 0.7023, Train RMSE: 0.8449, Train MAE: 0.6604, Val RMSE: 0.9044, Val MAE: 0.7042\n",
      "Epoch: 179, Train loss: 0.7141, Train RMSE: 0.8414, Train MAE: 0.6419, Val RMSE: 0.9027, Val MAE: 0.6837\n",
      "Epoch: 180, Train loss: 0.7091, Train RMSE: 0.8359, Train MAE: 0.6435, Val RMSE: 0.8975, Val MAE: 0.6871\n",
      "Epoch: 181, Train loss: 0.6993, Train RMSE: 0.8396, Train MAE: 0.6527, Val RMSE: 0.9001, Val MAE: 0.6966\n",
      "Epoch: 182, Train loss: 0.7053, Train RMSE: 0.8362, Train MAE: 0.6414, Val RMSE: 0.8979, Val MAE: 0.6848\n",
      "Epoch: 183, Train loss: 0.6999, Train RMSE: 0.8369, Train MAE: 0.6406, Val RMSE: 0.8995, Val MAE: 0.6842\n",
      "Epoch: 184, Train loss: 0.7013, Train RMSE: 0.8369, Train MAE: 0.6489, Val RMSE: 0.8996, Val MAE: 0.6945\n",
      "Epoch: 185, Train loss: 0.7008, Train RMSE: 0.8355, Train MAE: 0.6460, Val RMSE: 0.8987, Val MAE: 0.6914\n",
      "Epoch: 186, Train loss: 0.6985, Train RMSE: 0.8366, Train MAE: 0.6403, Val RMSE: 0.8996, Val MAE: 0.6841\n",
      "Epoch: 187, Train loss: 0.7007, Train RMSE: 0.8343, Train MAE: 0.6427, Val RMSE: 0.8970, Val MAE: 0.6871\n",
      "Epoch: 188, Train loss: 0.6966, Train RMSE: 0.8359, Train MAE: 0.6476, Val RMSE: 0.8981, Val MAE: 0.6924\n",
      "Epoch: 189, Train loss: 0.6990, Train RMSE: 0.8342, Train MAE: 0.6406, Val RMSE: 0.8975, Val MAE: 0.6852\n",
      "Epoch: 190, Train loss: 0.6965, Train RMSE: 0.8342, Train MAE: 0.6398, Val RMSE: 0.8981, Val MAE: 0.6847\n",
      "Epoch: 191, Train loss: 0.6965, Train RMSE: 0.8342, Train MAE: 0.6454, Val RMSE: 0.8982, Val MAE: 0.6917\n",
      "Epoch: 192, Train loss: 0.6963, Train RMSE: 0.8334, Train MAE: 0.6431, Val RMSE: 0.8977, Val MAE: 0.6891\n",
      "Epoch: 193, Train loss: 0.6949, Train RMSE: 0.8337, Train MAE: 0.6392, Val RMSE: 0.8983, Val MAE: 0.6845\n",
      "Epoch: 194, Train loss: 0.6958, Train RMSE: 0.8326, Train MAE: 0.6417, Val RMSE: 0.8971, Val MAE: 0.6879\n",
      "Epoch: 195, Train loss: 0.6937, Train RMSE: 0.8330, Train MAE: 0.6435, Val RMSE: 0.8975, Val MAE: 0.6899\n",
      "Epoch: 196, Train loss: 0.6944, Train RMSE: 0.8324, Train MAE: 0.6390, Val RMSE: 0.8974, Val MAE: 0.6849\n",
      "Epoch: 197, Train loss: 0.6936, Train RMSE: 0.8319, Train MAE: 0.6393, Val RMSE: 0.8972, Val MAE: 0.6856\n",
      "Epoch: 198, Train loss: 0.6926, Train RMSE: 0.8322, Train MAE: 0.6429, Val RMSE: 0.8976, Val MAE: 0.6900\n",
      "Epoch: 199, Train loss: 0.6929, Train RMSE: 0.8315, Train MAE: 0.6400, Val RMSE: 0.8976, Val MAE: 0.6869\n",
      "Epoch: 200, Train loss: 0.6920, Train RMSE: 0.8314, Train MAE: 0.6385, Val RMSE: 0.8979, Val MAE: 0.6854\n",
      "Epoch: 201, Train loss: 0.6918, Train RMSE: 0.8311, Train MAE: 0.6411, Val RMSE: 0.8976, Val MAE: 0.6887\n",
      "Epoch: 202, Train loss: 0.6913, Train RMSE: 0.8309, Train MAE: 0.6401, Val RMSE: 0.8975, Val MAE: 0.6876\n",
      "Epoch: 203, Train loss: 0.6908, Train RMSE: 0.8307, Train MAE: 0.6378, Val RMSE: 0.8977, Val MAE: 0.6850\n",
      "Epoch: 204, Train loss: 0.6908, Train RMSE: 0.8303, Train MAE: 0.6397, Val RMSE: 0.8974, Val MAE: 0.6874\n",
      "Epoch: 205, Train loss: 0.6899, Train RMSE: 0.8303, Train MAE: 0.6403, Val RMSE: 0.8977, Val MAE: 0.6883\n",
      "Epoch: 206, Train loss: 0.6898, Train RMSE: 0.8300, Train MAE: 0.6379, Val RMSE: 0.8979, Val MAE: 0.6856\n",
      "Epoch: 207, Train loss: 0.6896, Train RMSE: 0.8296, Train MAE: 0.6386, Val RMSE: 0.8975, Val MAE: 0.6866\n",
      "Epoch: 208, Train loss: 0.6888, Train RMSE: 0.8296, Train MAE: 0.6395, Val RMSE: 0.8974, Val MAE: 0.6877\n",
      "Epoch: 209, Train loss: 0.6888, Train RMSE: 0.8294, Train MAE: 0.6374, Val RMSE: 0.8975, Val MAE: 0.6854\n",
      "Epoch: 210, Train loss: 0.6884, Train RMSE: 0.8291, Train MAE: 0.6378, Val RMSE: 0.8974, Val MAE: 0.6861\n",
      "Epoch: 211, Train loss: 0.6879, Train RMSE: 0.8290, Train MAE: 0.6391, Val RMSE: 0.8976, Val MAE: 0.6878\n",
      "Epoch: 212, Train loss: 0.6878, Train RMSE: 0.8288, Train MAE: 0.6374, Val RMSE: 0.8977, Val MAE: 0.6861\n",
      "Epoch: 213, Train loss: 0.6874, Train RMSE: 0.8285, Train MAE: 0.6374, Val RMSE: 0.8975, Val MAE: 0.6862\n",
      "Epoch: 214, Train loss: 0.6870, Train RMSE: 0.8284, Train MAE: 0.6383, Val RMSE: 0.8974, Val MAE: 0.6873\n",
      "Epoch: 215, Train loss: 0.6868, Train RMSE: 0.8282, Train MAE: 0.6368, Val RMSE: 0.8974, Val MAE: 0.6859\n",
      "Epoch: 216, Train loss: 0.6865, Train RMSE: 0.8280, Train MAE: 0.6369, Val RMSE: 0.8974, Val MAE: 0.6862\n",
      "Epoch: 217, Train loss: 0.6861, Train RMSE: 0.8279, Train MAE: 0.6378, Val RMSE: 0.8975, Val MAE: 0.6873\n",
      "Epoch: 218, Train loss: 0.6859, Train RMSE: 0.8277, Train MAE: 0.6366, Val RMSE: 0.8976, Val MAE: 0.6861\n",
      "Epoch: 219, Train loss: 0.6856, Train RMSE: 0.8275, Train MAE: 0.6367, Val RMSE: 0.8974, Val MAE: 0.6864\n",
      "Epoch: 220, Train loss: 0.6852, Train RMSE: 0.8273, Train MAE: 0.6370, Val RMSE: 0.8973, Val MAE: 0.6868\n",
      "Epoch: 221, Train loss: 0.6850, Train RMSE: 0.8272, Train MAE: 0.6360, Val RMSE: 0.8974, Val MAE: 0.6858\n",
      "Epoch: 222, Train loss: 0.6847, Train RMSE: 0.8270, Train MAE: 0.6364, Val RMSE: 0.8973, Val MAE: 0.6864\n",
      "Epoch: 223, Train loss: 0.6844, Train RMSE: 0.8268, Train MAE: 0.6365, Val RMSE: 0.8974, Val MAE: 0.6866\n",
      "Epoch: 224, Train loss: 0.6842, Train RMSE: 0.8267, Train MAE: 0.6357, Val RMSE: 0.8975, Val MAE: 0.6860\n",
      "Epoch: 225, Train loss: 0.6839, Train RMSE: 0.8265, Train MAE: 0.6361, Val RMSE: 0.8974, Val MAE: 0.6866\n",
      "Epoch: 226, Train loss: 0.6836, Train RMSE: 0.8264, Train MAE: 0.6356, Val RMSE: 0.8974, Val MAE: 0.6861\n",
      "Epoch: 227, Train loss: 0.6834, Train RMSE: 0.8262, Train MAE: 0.6353, Val RMSE: 0.8974, Val MAE: 0.6859\n",
      "Epoch: 228, Train loss: 0.6831, Train RMSE: 0.8261, Train MAE: 0.6357, Val RMSE: 0.8974, Val MAE: 0.6865\n",
      "Epoch: 229, Train loss: 0.6829, Train RMSE: 0.8259, Train MAE: 0.6352, Val RMSE: 0.8975, Val MAE: 0.6860\n",
      "Epoch: 230, Train loss: 0.6827, Train RMSE: 0.8258, Train MAE: 0.6352, Val RMSE: 0.8974, Val MAE: 0.6861\n",
      "Epoch: 231, Train loss: 0.6824, Train RMSE: 0.8256, Train MAE: 0.6351, Val RMSE: 0.8975, Val MAE: 0.6862\n",
      "Epoch: 232, Train loss: 0.6822, Train RMSE: 0.8255, Train MAE: 0.6346, Val RMSE: 0.8975, Val MAE: 0.6857\n",
      "Epoch: 233, Train loss: 0.6820, Train RMSE: 0.8254, Train MAE: 0.6352, Val RMSE: 0.8974, Val MAE: 0.6865\n",
      "Epoch: 234, Train loss: 0.6817, Train RMSE: 0.8252, Train MAE: 0.6344, Val RMSE: 0.8975, Val MAE: 0.6857\n",
      "Epoch: 235, Train loss: 0.6815, Train RMSE: 0.8251, Train MAE: 0.6347, Val RMSE: 0.8974, Val MAE: 0.6861\n",
      "Epoch: 236, Train loss: 0.6813, Train RMSE: 0.8249, Train MAE: 0.6344, Val RMSE: 0.8975, Val MAE: 0.6860\n",
      "Epoch: 237, Train loss: 0.6810, Train RMSE: 0.8248, Train MAE: 0.6340, Val RMSE: 0.8975, Val MAE: 0.6857\n",
      "Epoch: 238, Train loss: 0.6808, Train RMSE: 0.8247, Train MAE: 0.6344, Val RMSE: 0.8975, Val MAE: 0.6863\n",
      "Epoch: 239, Train loss: 0.6806, Train RMSE: 0.8245, Train MAE: 0.6337, Val RMSE: 0.8977, Val MAE: 0.6857\n",
      "Epoch: 240, Train loss: 0.6804, Train RMSE: 0.8244, Train MAE: 0.6341, Val RMSE: 0.8978, Val MAE: 0.6866\n",
      "Epoch: 241, Train loss: 0.6801, Train RMSE: 0.8242, Train MAE: 0.6332, Val RMSE: 0.8986, Val MAE: 0.6862\n",
      "Epoch: 242, Train loss: 0.6798, Train RMSE: 0.8240, Train MAE: 0.6334, Val RMSE: 0.8999, Val MAE: 0.6877\n",
      "Epoch: 243, Train loss: 0.6795, Train RMSE: 0.8237, Train MAE: 0.6324, Val RMSE: 0.8997, Val MAE: 0.6866\n",
      "Epoch: 244, Train loss: 0.6790, Train RMSE: 0.8235, Train MAE: 0.6335, Val RMSE: 0.8996, Val MAE: 0.6883\n",
      "Epoch: 245, Train loss: 0.6786, Train RMSE: 0.8232, Train MAE: 0.6317, Val RMSE: 0.8992, Val MAE: 0.6857\n",
      "Epoch: 246, Train loss: 0.6782, Train RMSE: 0.8243, Train MAE: 0.6362, Val RMSE: 0.9021, Val MAE: 0.6929\n",
      "Epoch: 247, Train loss: 0.6800, Train RMSE: 0.8313, Train MAE: 0.6316, Val RMSE: 0.9059, Val MAE: 0.6825\n",
      "Epoch: 248, Train loss: 0.6924, Train RMSE: 0.8452, Train MAE: 0.6663, Val RMSE: 0.9162, Val MAE: 0.7210\n",
      "Epoch: 249, Train loss: 0.7145, Train RMSE: 0.8342, Train MAE: 0.6330, Val RMSE: 0.9068, Val MAE: 0.6824\n",
      "Epoch: 250, Train loss: 0.6972, Train RMSE: 0.8238, Train MAE: 0.6339, Val RMSE: 0.8969, Val MAE: 0.6861\n",
      "Epoch: 251, Train loss: 0.6791, Train RMSE: 0.8320, Train MAE: 0.6492, Val RMSE: 0.9040, Val MAE: 0.7037\n",
      "Epoch: 252, Train loss: 0.6924, Train RMSE: 0.8313, Train MAE: 0.6323, Val RMSE: 0.9043, Val MAE: 0.6820\n",
      "Epoch: 253, Train loss: 0.6922, Train RMSE: 0.8238, Train MAE: 0.6353, Val RMSE: 0.8970, Val MAE: 0.6883\n",
      "Epoch: 254, Train loss: 0.6791, Train RMSE: 0.8269, Train MAE: 0.6414, Val RMSE: 0.8995, Val MAE: 0.6952\n",
      "Epoch: 255, Train loss: 0.6840, Train RMSE: 0.8281, Train MAE: 0.6298, Val RMSE: 0.9021, Val MAE: 0.6811\n",
      "Epoch: 256, Train loss: 0.6869, Train RMSE: 0.8231, Train MAE: 0.6347, Val RMSE: 0.8985, Val MAE: 0.6897\n",
      "Epoch: 257, Train loss: 0.6779, Train RMSE: 0.8240, Train MAE: 0.6371, Val RMSE: 0.9010, Val MAE: 0.6941\n",
      "Epoch: 258, Train loss: 0.6793, Train RMSE: 0.8263, Train MAE: 0.6292, Val RMSE: 0.9041, Val MAE: 0.6832\n",
      "Epoch: 259, Train loss: 0.6839, Train RMSE: 0.8242, Train MAE: 0.6377, Val RMSE: 0.9039, Val MAE: 0.6967\n",
      "Epoch: 260, Train loss: 0.6797, Train RMSE: 0.8213, Train MAE: 0.6298, Val RMSE: 0.9000, Val MAE: 0.6861\n",
      "Epoch: 261, Train loss: 0.6751, Train RMSE: 0.8217, Train MAE: 0.6293, Val RMSE: 0.8997, Val MAE: 0.6844\n",
      "Epoch: 262, Train loss: 0.6758, Train RMSE: 0.8230, Train MAE: 0.6373, Val RMSE: 0.9013, Val MAE: 0.6951\n",
      "Epoch: 263, Train loss: 0.6776, Train RMSE: 0.8215, Train MAE: 0.6286, Val RMSE: 0.9000, Val MAE: 0.6835\n",
      "Epoch: 264, Train loss: 0.6755, Train RMSE: 0.8200, Train MAE: 0.6308, Val RMSE: 0.9000, Val MAE: 0.6883\n",
      "Epoch: 265, Train loss: 0.6728, Train RMSE: 0.8203, Train MAE: 0.6319, Val RMSE: 0.9010, Val MAE: 0.6903\n",
      "Epoch: 266, Train loss: 0.6732, Train RMSE: 0.8217, Train MAE: 0.6271, Val RMSE: 0.9008, Val MAE: 0.6817\n",
      "Epoch: 267, Train loss: 0.6759, Train RMSE: 0.8228, Train MAE: 0.6380, Val RMSE: 0.9025, Val MAE: 0.6966\n",
      "Epoch: 268, Train loss: 0.6772, Train RMSE: 0.8220, Train MAE: 0.6274, Val RMSE: 0.8993, Val MAE: 0.6805\n",
      "Epoch: 269, Train loss: 0.6764, Train RMSE: 0.8192, Train MAE: 0.6321, Val RMSE: 0.8977, Val MAE: 0.6887\n",
      "Epoch: 270, Train loss: 0.6713, Train RMSE: 0.8183, Train MAE: 0.6309, Val RMSE: 0.8985, Val MAE: 0.6888\n",
      "Epoch: 271, Train loss: 0.6700, Train RMSE: 0.8203, Train MAE: 0.6255, Val RMSE: 0.9009, Val MAE: 0.6812\n",
      "Epoch: 272, Train loss: 0.6735, Train RMSE: 0.8247, Train MAE: 0.6394, Val RMSE: 0.9084, Val MAE: 0.7012\n",
      "Epoch: 273, Train loss: 0.6804, Train RMSE: 0.8347, Train MAE: 0.6320, Val RMSE: 0.9098, Val MAE: 0.6818\n",
      "Epoch: 274, Train loss: 0.6979, Train RMSE: 0.8335, Train MAE: 0.6541, Val RMSE: 0.9071, Val MAE: 0.7102\n",
      "Epoch: 275, Train loss: 0.6948, Train RMSE: 0.8196, Train MAE: 0.6318, Val RMSE: 0.8947, Val MAE: 0.6855\n",
      "Epoch: 276, Train loss: 0.6719, Train RMSE: 0.8276, Train MAE: 0.6278, Val RMSE: 0.9047, Val MAE: 0.6800\n",
      "Epoch: 277, Train loss: 0.6860, Train RMSE: 0.8373, Train MAE: 0.6550, Val RMSE: 0.9212, Val MAE: 0.7186\n",
      "Epoch: 278, Train loss: 0.7013, Train RMSE: 0.8362, Train MAE: 0.6319, Val RMSE: 0.9130, Val MAE: 0.6830\n",
      "Epoch: 279, Train loss: 0.7012, Train RMSE: 0.8201, Train MAE: 0.6347, Val RMSE: 0.8976, Val MAE: 0.6918\n",
      "Epoch: 280, Train loss: 0.6727, Train RMSE: 0.8260, Train MAE: 0.6438, Val RMSE: 0.9023, Val MAE: 0.7011\n",
      "Epoch: 281, Train loss: 0.6824, Train RMSE: 0.8289, Train MAE: 0.6284, Val RMSE: 0.9043, Val MAE: 0.6793\n",
      "Epoch: 282, Train loss: 0.6881, Train RMSE: 0.8161, Train MAE: 0.6279, Val RMSE: 0.8957, Val MAE: 0.6856\n",
      "Epoch: 283, Train loss: 0.6663, Train RMSE: 0.8240, Train MAE: 0.6410, Val RMSE: 0.9073, Val MAE: 0.7038\n",
      "Epoch: 284, Train loss: 0.6792, Train RMSE: 0.8271, Train MAE: 0.6262, Val RMSE: 0.9082, Val MAE: 0.6813\n",
      "Epoch: 285, Train loss: 0.6853, Train RMSE: 0.8155, Train MAE: 0.6288, Val RMSE: 0.9012, Val MAE: 0.6923\n",
      "Epoch: 286, Train loss: 0.6653, Train RMSE: 0.8155, Train MAE: 0.6304, Val RMSE: 0.9001, Val MAE: 0.6934\n",
      "Epoch: 287, Train loss: 0.6652, Train RMSE: 0.8210, Train MAE: 0.6240, Val RMSE: 0.9011, Val MAE: 0.6791\n",
      "Epoch: 288, Train loss: 0.6745, Train RMSE: 0.8148, Train MAE: 0.6308, Val RMSE: 0.8972, Val MAE: 0.6918\n",
      "Epoch: 289, Train loss: 0.6640, Train RMSE: 0.8132, Train MAE: 0.6283, Val RMSE: 0.8976, Val MAE: 0.6908\n",
      "Epoch: 290, Train loss: 0.6614, Train RMSE: 0.8190, Train MAE: 0.6212, Val RMSE: 0.9030, Val MAE: 0.6796\n",
      "Epoch: 291, Train loss: 0.6713, Train RMSE: 0.8192, Train MAE: 0.6346, Val RMSE: 0.9061, Val MAE: 0.6997\n",
      "Epoch: 292, Train loss: 0.6713, Train RMSE: 0.8152, Train MAE: 0.6212, Val RMSE: 0.8964, Val MAE: 0.6778\n",
      "Epoch: 293, Train loss: 0.6649, Train RMSE: 0.8126, Train MAE: 0.6271, Val RMSE: 0.8927, Val MAE: 0.6860\n",
      "Epoch: 294, Train loss: 0.6604, Train RMSE: 0.8119, Train MAE: 0.6282, Val RMSE: 0.8956, Val MAE: 0.6909\n",
      "Epoch: 295, Train loss: 0.6592, Train RMSE: 0.8123, Train MAE: 0.6173, Val RMSE: 0.8982, Val MAE: 0.6780\n",
      "Epoch: 296, Train loss: 0.6605, Train RMSE: 0.8123, Train MAE: 0.6235, Val RMSE: 0.9017, Val MAE: 0.6889\n",
      "Epoch: 297, Train loss: 0.6601, Train RMSE: 0.8080, Train MAE: 0.6171, Val RMSE: 0.8932, Val MAE: 0.6782\n",
      "Epoch: 298, Train loss: 0.6532, Train RMSE: 0.8092, Train MAE: 0.6235, Val RMSE: 0.8918, Val MAE: 0.6843\n",
      "Epoch: 299, Train loss: 0.6548, Train RMSE: 0.8077, Train MAE: 0.6219, Val RMSE: 0.8926, Val MAE: 0.6845\n",
      "Epoch: 300, Train loss: 0.6525, Train RMSE: 0.8064, Train MAE: 0.6154, Val RMSE: 0.8959, Val MAE: 0.6797\n",
      "Epoch: 301, Train loss: 0.6507, Train RMSE: 0.8081, Train MAE: 0.6186, Val RMSE: 0.9008, Val MAE: 0.6857\n",
      "Epoch: 302, Train loss: 0.6533, Train RMSE: 0.8057, Train MAE: 0.6145, Val RMSE: 0.8945, Val MAE: 0.6781\n",
      "Epoch: 303, Train loss: 0.6494, Train RMSE: 0.8068, Train MAE: 0.6231, Val RMSE: 0.8944, Val MAE: 0.6884\n",
      "Epoch: 304, Train loss: 0.6511, Train RMSE: 0.8043, Train MAE: 0.6168, Val RMSE: 0.8923, Val MAE: 0.6807\n",
      "Epoch: 305, Train loss: 0.6470, Train RMSE: 0.8038, Train MAE: 0.6136, Val RMSE: 0.8968, Val MAE: 0.6805\n",
      "Epoch: 306, Train loss: 0.6463, Train RMSE: 0.8047, Train MAE: 0.6162, Val RMSE: 0.8995, Val MAE: 0.6851\n",
      "Epoch: 307, Train loss: 0.6477, Train RMSE: 0.8054, Train MAE: 0.6143, Val RMSE: 0.8926, Val MAE: 0.6759\n",
      "Epoch: 308, Train loss: 0.6489, Train RMSE: 0.8074, Train MAE: 0.6259, Val RMSE: 0.8978, Val MAE: 0.6943\n",
      "Epoch: 309, Train loss: 0.6519, Train RMSE: 0.8031, Train MAE: 0.6119, Val RMSE: 0.8930, Val MAE: 0.6755\n",
      "Epoch: 310, Train loss: 0.6452, Train RMSE: 0.8032, Train MAE: 0.6145, Val RMSE: 0.8995, Val MAE: 0.6845\n",
      "Epoch: 311, Train loss: 0.6453, Train RMSE: 0.8011, Train MAE: 0.6110, Val RMSE: 0.8926, Val MAE: 0.6762\n",
      "Epoch: 312, Train loss: 0.6419, Train RMSE: 0.8022, Train MAE: 0.6190, Val RMSE: 0.8946, Val MAE: 0.6878\n",
      "Epoch: 313, Train loss: 0.6436, Train RMSE: 0.8000, Train MAE: 0.6111, Val RMSE: 0.8922, Val MAE: 0.6769\n",
      "Epoch: 314, Train loss: 0.6401, Train RMSE: 0.8008, Train MAE: 0.6127, Val RMSE: 0.8996, Val MAE: 0.6842\n",
      "Epoch: 315, Train loss: 0.6415, Train RMSE: 0.8006, Train MAE: 0.6095, Val RMSE: 0.8939, Val MAE: 0.6751\n",
      "Epoch: 316, Train loss: 0.6412, Train RMSE: 0.8042, Train MAE: 0.6225, Val RMSE: 0.9008, Val MAE: 0.6950\n",
      "Epoch: 317, Train loss: 0.6468, Train RMSE: 0.8081, Train MAE: 0.6142, Val RMSE: 0.8946, Val MAE: 0.6734\n",
      "Epoch: 318, Train loss: 0.6532, Train RMSE: 0.8030, Train MAE: 0.6195, Val RMSE: 0.9022, Val MAE: 0.6935\n",
      "Epoch: 319, Train loss: 0.6450, Train RMSE: 0.8028, Train MAE: 0.6103, Val RMSE: 0.8930, Val MAE: 0.6728\n",
      "Epoch: 320, Train loss: 0.6447, Train RMSE: 0.7993, Train MAE: 0.6159, Val RMSE: 0.8971, Val MAE: 0.6889\n",
      "Epoch: 321, Train loss: 0.6390, Train RMSE: 0.7968, Train MAE: 0.6083, Val RMSE: 0.8917, Val MAE: 0.6765\n",
      "Epoch: 322, Train loss: 0.6350, Train RMSE: 0.7957, Train MAE: 0.6079, Val RMSE: 0.8942, Val MAE: 0.6794\n",
      "Epoch: 323, Train loss: 0.6333, Train RMSE: 0.7959, Train MAE: 0.6103, Val RMSE: 0.8960, Val MAE: 0.6839\n",
      "Epoch: 324, Train loss: 0.6336, Train RMSE: 0.7985, Train MAE: 0.6087, Val RMSE: 0.8913, Val MAE: 0.6742\n",
      "Epoch: 325, Train loss: 0.6377, Train RMSE: 0.7990, Train MAE: 0.6159, Val RMSE: 0.9013, Val MAE: 0.6923\n",
      "Epoch: 326, Train loss: 0.6385, Train RMSE: 0.8029, Train MAE: 0.6096, Val RMSE: 0.8954, Val MAE: 0.6728\n",
      "Epoch: 327, Train loss: 0.6450, Train RMSE: 0.8021, Train MAE: 0.6199, Val RMSE: 0.9063, Val MAE: 0.6983\n",
      "Epoch: 328, Train loss: 0.6434, Train RMSE: 0.8053, Train MAE: 0.6128, Val RMSE: 0.8941, Val MAE: 0.6730\n",
      "Epoch: 329, Train loss: 0.6488, Train RMSE: 0.7950, Train MAE: 0.6123, Val RMSE: 0.8965, Val MAE: 0.6880\n",
      "Epoch: 330, Train loss: 0.6322, Train RMSE: 0.7963, Train MAE: 0.6105, Val RMSE: 0.9022, Val MAE: 0.6885\n",
      "Epoch: 331, Train loss: 0.6343, Train RMSE: 0.8080, Train MAE: 0.6123, Val RMSE: 0.8991, Val MAE: 0.6733\n",
      "Epoch: 332, Train loss: 0.6532, Train RMSE: 0.8090, Train MAE: 0.6319, Val RMSE: 0.9101, Val MAE: 0.7094\n",
      "Epoch: 333, Train loss: 0.6545, Train RMSE: 0.7934, Train MAE: 0.6039, Val RMSE: 0.8965, Val MAE: 0.6778\n",
      "Epoch: 334, Train loss: 0.6297, Train RMSE: 0.7970, Train MAE: 0.6040, Val RMSE: 0.9023, Val MAE: 0.6788\n",
      "Epoch: 335, Train loss: 0.6357, Train RMSE: 0.8030, Train MAE: 0.6233, Val RMSE: 0.9104, Val MAE: 0.7049\n",
      "Epoch: 336, Train loss: 0.6450, Train RMSE: 0.8101, Train MAE: 0.6186, Val RMSE: 0.8959, Val MAE: 0.6773\n",
      "Epoch: 337, Train loss: 0.6564, Train RMSE: 0.7924, Train MAE: 0.6051, Val RMSE: 0.8932, Val MAE: 0.6772\n",
      "Epoch: 338, Train loss: 0.6280, Train RMSE: 0.8325, Train MAE: 0.6467, Val RMSE: 0.9432, Val MAE: 0.7285\n",
      "Epoch: 339, Train loss: 0.6933, Train RMSE: 0.8663, Train MAE: 0.6530, Val RMSE: 0.9341, Val MAE: 0.6946\n",
      "Epoch: 340, Train loss: 0.7512, Train RMSE: 0.9163, Train MAE: 0.7400, Val RMSE: 0.9690, Val MAE: 0.7799\n",
      "Epoch: 341, Train loss: 0.8397, Train RMSE: 0.8296, Train MAE: 0.6261, Val RMSE: 0.9063, Val MAE: 0.6769\n",
      "Epoch: 342, Train loss: 0.6890, Train RMSE: 0.8203, Train MAE: 0.6317, Val RMSE: 0.9183, Val MAE: 0.7031\n",
      "Epoch: 343, Train loss: 0.6748, Train RMSE: 0.8555, Train MAE: 0.6679, Val RMSE: 0.9607, Val MAE: 0.7440\n",
      "Epoch: 344, Train loss: 0.7344, Train RMSE: 0.8594, Train MAE: 0.6426, Val RMSE: 0.9486, Val MAE: 0.7018\n",
      "Epoch: 345, Train loss: 0.7571, Train RMSE: 0.8203, Train MAE: 0.6316, Val RMSE: 0.9109, Val MAE: 0.6987\n",
      "Epoch: 346, Train loss: 0.6744, Train RMSE: 0.8490, Train MAE: 0.6700, Val RMSE: 0.9348, Val MAE: 0.7367\n",
      "Epoch: 347, Train loss: 0.7209, Train RMSE: 0.8254, Train MAE: 0.6263, Val RMSE: 0.9081, Val MAE: 0.6832\n",
      "Epoch: 348, Train loss: 0.6831, Train RMSE: 0.8315, Train MAE: 0.6284, Val RMSE: 0.9133, Val MAE: 0.6833\n",
      "Epoch: 349, Train loss: 0.6934, Train RMSE: 0.8318, Train MAE: 0.6520, Val RMSE: 0.9201, Val MAE: 0.7188\n",
      "Epoch: 350, Train loss: 0.6920, Train RMSE: 0.8151, Train MAE: 0.6309, Val RMSE: 0.9092, Val MAE: 0.7001\n",
      "Epoch: 351, Train loss: 0.6648, Train RMSE: 0.8330, Train MAE: 0.6265, Val RMSE: 0.9271, Val MAE: 0.6909\n",
      "Epoch: 352, Train loss: 0.6972, Train RMSE: 0.8169, Train MAE: 0.6296, Val RMSE: 0.9218, Val MAE: 0.7059\n",
      "Epoch: 353, Train loss: 0.6678, Train RMSE: 0.8102, Train MAE: 0.6234, Val RMSE: 0.9128, Val MAE: 0.6977\n",
      "Epoch: 354, Train loss: 0.6569, Train RMSE: 0.8180, Train MAE: 0.6192, Val RMSE: 0.9099, Val MAE: 0.6816\n",
      "Epoch: 355, Train loss: 0.6705, Train RMSE: 0.8085, Train MAE: 0.6236, Val RMSE: 0.8997, Val MAE: 0.6895\n",
      "Epoch: 356, Train loss: 0.6539, Train RMSE: 0.8146, Train MAE: 0.6339, Val RMSE: 0.9052, Val MAE: 0.7010\n",
      "Epoch: 357, Train loss: 0.6636, Train RMSE: 0.8080, Train MAE: 0.6151, Val RMSE: 0.8989, Val MAE: 0.6774\n",
      "Epoch: 358, Train loss: 0.6534, Train RMSE: 0.8035, Train MAE: 0.6120, Val RMSE: 0.9001, Val MAE: 0.6797\n",
      "Epoch: 359, Train loss: 0.6461, Train RMSE: 0.8144, Train MAE: 0.6299, Val RMSE: 0.9153, Val MAE: 0.7060\n",
      "Early stopping triggered at epoch 359. Best validation RMSE: 0.8913 at epoch 324.\n",
      "Best model with lowest validation RMSE restored from epoch 324.\n",
      "\n",
      "Trained model init_GNN_model saved at path: D:\\Internship\\recsys\\data\\temp\\init\n",
      "\n",
      "[LOG] Deploying the pre-trained GNN model on MinIO database\n",
      "[LOG] Initial pre-trained model 'init_model.pth' uploaded.\n",
      "[LOG] Offline updated model '2025-04-07_offline_model.pth' uploaded.\n"
     ]
    }
   ],
   "source": [
    "# Branch 2\n",
    "debug_cuda()\n",
    "build_graph_dataset()\n",
    "train_gnn_model()\n",
    "deploy_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Building Neo4j knowledge graph\n",
      "[\u001b[34m2025-04-07T19:03:30.168+0200\u001b[0m] {\u001b[34mresult.py:\u001b[0m332} INFO\u001b[0m - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Movie) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_2c627a06 FOR (e:Movie) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (m:Movie) REQUIRE m.id IS UNIQUE;'\u001b[0m\n",
      "[\u001b[34m2025-04-07T19:03:30.173+0200\u001b[0m] {\u001b[34mresult.py:\u001b[0m332} INFO\u001b[0m - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Person) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_a831e4ce FOR (e:Person) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (p:Person) REQUIRE p.name IS UNIQUE;'\u001b[0m\n",
      "[\u001b[34m2025-04-07T19:03:30.177+0200\u001b[0m] {\u001b[34mresult.py:\u001b[0m332} INFO\u001b[0m - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Genre) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_b3c936b8 FOR (e:Genre) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (g:Genre) REQUIRE g.name IS UNIQUE;'\u001b[0m\n",
      "[\u001b[34m2025-04-07T19:03:30.181+0200\u001b[0m] {\u001b[34mresult.py:\u001b[0m332} INFO\u001b[0m - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:ProductionCompany) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_1eb06cbe FOR (e:ProductionCompany) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (pc:ProductionCompany) REQUIRE pc.name IS UNIQUE;'\u001b[0m\n",
      "[\u001b[34m2025-04-07T19:03:30.185+0200\u001b[0m] {\u001b[34mresult.py:\u001b[0m332} INFO\u001b[0m - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Country) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_a540be84 FOR (e:Country) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (c:Country) REQUIRE c.name IS UNIQUE;'\u001b[0m\n",
      "[\u001b[34m2025-04-07T19:03:30.189+0200\u001b[0m] {\u001b[34mresult.py:\u001b[0m332} INFO\u001b[0m - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Language) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_77b2f083 FOR (e:Language) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (l:Language) REQUIRE l.name IS UNIQUE;'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ingesting batches: 100%|██████████| 6/6 [01:11<00:00, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2025-04-07T19:04:41.488+0200\u001b[0m] {\u001b[34mresult.py:\u001b[0m332} INFO\u001b[0m - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE FULLTEXT INDEX IF NOT EXISTS FOR (e:Movie) ON EACH [e.title]` has no effect.} {description: `FULLTEXT INDEX movie FOR (e:Movie) ON EACH [e.title]` already exists.} {position: None} for query: 'CREATE FULLTEXT INDEX IF NOT EXISTS FOR (m:Movie) ON EACH [m.title]'\u001b[0m\n",
      "[\u001b[34m2025-04-07T19:04:41.494+0200\u001b[0m] {\u001b[34mresult.py:\u001b[0m332} INFO\u001b[0m - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE FULLTEXT INDEX IF NOT EXISTS FOR (e:Person) ON EACH [e.name]` has no effect.} {description: `FULLTEXT INDEX person FOR (e:Person) ON EACH [e.name]` already exists.} {position: None} for query: 'CREATE FULLTEXT INDEX IF NOT EXISTS FOR (p:Person) ON EACH [p.name]'\u001b[0m\n",
      "[LOG] Ingested 45477 movies into the knowledge graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Branch 3\n",
    "build_neo4j_knowledge_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
